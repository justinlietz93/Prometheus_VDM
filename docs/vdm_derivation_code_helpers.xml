<?xml version="1.0" ?>
<fum_code_report>
  <generated_timestamp>2025-10-26 03:53:45</generated_timestamp>
  <metadata>
    <global_stats>
      <total_files>24</total_files>
      <total_size_bytes>170030</total_size_bytes>
      <total_loc>3333</total_loc>
    </global_stats>
    <chunk_stats>
      <files_in_chunk>24</files_in_chunk>
      <size_in_chunk_bytes>170030</size_in_chunk_bytes>
      <loc_in_chunk>3333</loc_in_chunk>
    </chunk_stats>
  </metadata>
  <ascii_map><![CDATA[   common/
>> ├── __init__.py
   │   (LOC: 1, Size: 49 B)
   ├── authorization/
>> │   ├── README.md
   │   │   (LOC: 92, Size: 4.9 KB)
>> │   ├── __init__.py
   │   │   (LOC: 7, Size: 213 B)
>> │   ├── approval.py
   │   │   (LOC: 701, Size: 28.0 KB)
>> │   └── approve_tag.py
   │       (LOC: 384, Size: 16.7 KB)
   ├── causality/
>> │   ├── __init__.py
   │   │   (LOC: 53, Size: 1.3 KB)
>> │   ├── diagnostics.py
   │   │   (LOC: 125, Size: 3.5 KB)
>> │   ├── event_dag.py
   │   │   (LOC: 204, Size: 6.9 KB)
>> │   └── intervals.py
   │       (LOC: 191, Size: 6.3 KB)
>> ├── constants.py
   │   (LOC: 140, Size: 5.4 KB)
   ├── data/
>> │   ├── __init__.py
   │   │   (LOC: 0, Size: 0 B)
>> │   ├── approval.db
   │   │   (LOC: 65, Size: 36.0 KB)
>> │   ├── approval_admin.db
   │   │   (LOC: 11, Size: 8.0 KB)
>> │   └── results_db.py
   │       (LOC: 494, Size: 20.2 KB)
   ├── domain_setup/
>> │   ├── README.md
   │   │   (LOC: 29, Size: 1.7 KB)
>> │   └── __init__.py
   │       (LOC: 0, Size: 0 B)
>> ├── io_paths.py
   │   (LOC: 118, Size: 4.5 KB)
   ├── plotting/
>> │   ├── README.md
   │   │   (LOC: 25, Size: 1.0 KB)
>> │   ├── __init__.py
   │   │   (LOC: 11, Size: 538 B)
>> │   ├── core.py
   │   │   (LOC: 50, Size: 1.3 KB)
>> │   ├── helpers.py
   │   │   (LOC: 156, Size: 4.5 KB)
>> │   ├── primitives.py
   │   │   (LOC: 186, Size: 5.3 KB)
>> │   └── types.py
   │       (LOC: 24, Size: 629 B)
>> └── vdm_equations.py
       (LOC: 266, Size: 9.0 KB)]]></ascii_map>
  <files>
    <file>
      <path>__init__.py</path>
      <content><![CDATA[# Package initializer for Derivation.code.common
]]></content>
    </file>
    <file>
      <path>authorization/README.md</path>
      <content><![CDATA[# authorization/ - approval gate and CLI (DB-only)

Purpose

- Enforce proposal + tag-specific schema + script-scoped approval before experiments run.
- Provide a password-gated CLI to stamp approvals and update a local SQLite DB you control.

Contents

- `approval.py`: runtime gate with SQLite helpers
  - Public DB: approvals, domain_keys, tag_secrets, exempt_scripts
  - Admin DB: admin (PBKDF2-SHA256 password hash)
- `approve_tag.py`: CLI that prompts for your password for write ops, stamps the manifest, and upserts the public DB

What it is not

- Not mixed with other common utilities (kept isolated by design).
- Not a place for experiment code or plotting.

Setup & Usage (high level)

- Public DB path (required for runtime/CLI):
  - Export `VDM_APPROVAL_DB=/path/to/approval.db` (or pass `--db` to the CLI).
- Admin DB path (optional, for admin credentials only):
  - Export `VDM_APPROVAL_ADMIN_DB=/path/to/approval_admin.db` (defaults to `approval_admin.db` or falls back to public DB).
- Bootstrap/check status (no password required):
  - `python3 -m Derivation.code.common.authorization.approve_tag status [--db "$VDM_APPROVAL_DB"]`
- Approve a tag (script-scoped HMAC):
  - Preferred: set a tag-specific secret, then approve
    - `python3 -m Derivation.code.common.authorization.approve_tag set-tag-secret <domain> <tag> <secret> [--db "$VDM_APPROVAL_DB"]`
    - `python3 -m Derivation.code.common.authorization.approve_tag approve <domain> <tag> --script <run_script.py> --schema <path> [--db "$VDM_APPROVAL_DB"]`
  - Fallback: set a domain-wide key if no tag secret exists
    - `python3 -m Derivation.code.common.authorization.approve_tag set-domain-key <domain> <domain_key> [--db "$VDM_APPROVAL_DB"]`
- Verify (read-only, no password):
  - `python3 -m Derivation.code.common.authorization.approve_tag check <domain> <tag> --script <run_script.py> [--db "$VDM_APPROVAL_DB"]`
- Exemptions (admin-gated writes):
  - `python3 -m Derivation.code.common.authorization.approve_tag exempt list [--db "$VDM_APPROVAL_DB"]`
  - `python3 -m Derivation.code.common.authorization.approve_tag exempt add Derivation/code/physics/<domain>/<script.py> [--db "$VDM_APPROVAL_DB"]`
  - `python3 -m Derivation.code.common.authorization.approve_tag exempt remove <normalized/script/path>`
  - `python3 -m Derivation.code.common.authorization.approve_tag exempt snapshot [--db "$VDM_APPROVAL_DB"]`

Policy

- Global enforcement: approvals are required for all scripts unless a script is explicitly listed in DB `exempt_scripts`.
- Approval key derivation is script-scoped:
  - `HMAC-SHA256(secret, f"{domain}:{script}:{tag}")`
  - Secret priority: `tag_secret` (preferred) > `domain_key` (fallback)
- Approval requires:
  - `pre_registered=true`, tag present in `allowed_tags`
  - `proposal` file exists
  - tag-specific JSON schema exists and contains the same tag
  - `approved_by` matches configured approver name
  - `approval_key` in manifest matches expected key derived from DB secret

Security

- Two-DB design:
  - Public DB (approval.db): freely readable by runtime; write operations gated by CLI/password
  - Admin DB (approval_admin.db): stores only the PBKDF2-SHA256 admin password record
- The admin password is entered interactively (never via environment), and is used only to authorize CLI write operations.
- Read-only CLI commands (status, check, exempt list) do not require a password.
- Public DB file permissions are set to 0600 on creation; place DBs in user-private locations.

Path discovery and logging

- Both DB paths are discovered in this order:
  - Explicit CLI flags (when provided)
  - Environment variables: `VDM_APPROVAL_DB` and `VDM_APPROVAL_ADMIN_DB`
  - Optional `.env` files in the workspace (if present)
- When a DB path is resolved, the module logs the provenance (where the path came from) at INFO level.
- On first creation, the module initializes the schema and enforces 0600 permissions.

Approval manifest fields

- Runners must carry an approval block (for example in an `APPROVAL.json` manifest alongside the run), containing at minimum:
  - `domain`: string
  - `tag`: string (must appear in the tag-specific JSON schema)
  - `approved_by`: string (your canonical approver name)
  - `approval_key`: string (hex HMAC of `domain:script:tag` using `tag_secret` or `domain_key`)
  - `pre_registered`: boolean (true)
  - `proposal`: path or identifier of the proposal document
  - `schema`: path to the JSON schema used to validate this tag
- The runtime checker compares this block to DB-derived expectations and rejects runs on any mismatch.

Related: Results logging and trust stamps

- Outside this package, results are logged per-domain into SQLite with per-experiment tables. Rows store the canonical JSON payload and a `row_hash` (SHA-256) covering the entire row for tamper-evident auditing.
- Begin-run validations integrate this approval check before any artifacts are written.

Ownership

- Maintainers: core devs. Keep this package to the two files above plus `__init__.py` for imports.
]]></content>
    </file>
    <file>
      <path>authorization/__init__.py</path>
      <content><![CDATA["""Authorization package: contains approval gate and CLI.

This file is intentionally minimal to enable imports like:
    from common.authorization.approval import check_tag_approval
"""

# No runtime logic here.
]]></content>
    </file>
    <file>
      <path>authorization/approval.py</path>
      <content><![CDATA[#!/usr/bin/env python3
from __future__ import annotations

from pathlib import Path
from typing import Optional, Tuple, Dict, Any
import json
import sys
import os
import hmac
import hashlib
import sqlite3
from dataclasses import dataclass
from datetime import datetime, timezone


# --- Module-level DB + admin helpers (single-file design) ---

@dataclass
class ApprovalRecord:
    domain: str
    tag: str
    expected_key: str
    approved_by: str
    approved_at: str


def _iso_now_utc() -> str:
    return datetime.now(timezone.utc).isoformat()


SCHEMA_SQL_PUBLIC = """
CREATE TABLE IF NOT EXISTS approvals (
  domain TEXT NOT NULL,
  tag TEXT NOT NULL,
  expected_key TEXT NOT NULL,
  approved_by TEXT NOT NULL,
  approved_at TEXT NOT NULL,
  PRIMARY KEY(domain, tag)
);
CREATE TABLE IF NOT EXISTS domain_keys (
  domain TEXT PRIMARY KEY,
  domain_key TEXT NOT NULL,
  created_at TEXT NOT NULL
);
CREATE TABLE IF NOT EXISTS tag_secrets (
  domain TEXT NOT NULL,
  tag TEXT NOT NULL,
  tag_secret TEXT NOT NULL,
  created_at TEXT NOT NULL,
  PRIMARY KEY(domain, tag)
);
CREATE TABLE IF NOT EXISTS exempt_scripts (
    script TEXT PRIMARY KEY,
    created_at TEXT NOT NULL,
    noted_by TEXT
);
"""

SCHEMA_SQL_ADMIN = """
CREATE TABLE IF NOT EXISTS admin (
    id INTEGER PRIMARY KEY CHECK(id = 1),
    password_scheme TEXT NOT NULL,
    password_hash TEXT NOT NULL,
    salt TEXT NOT NULL,
    iterations INTEGER NOT NULL,
    created_at TEXT NOT NULL
);
"""

# Default approvals DB path fallback (when VDM_APPROVAL_DB is unset)
DEFAULT_DB_PATH = Path(__file__).resolve().parents[1] / "data" / "approval.db"
# Default admin DB path (separate file) fallback
DEFAULT_ADMIN_DB_PATH = Path(__file__).resolve().parents[1] / "data" / "approval_admin.db"


def _read_env_file(path: Path) -> dict:
    """Parse a simple .env file.

    - Supports lines like: KEY=value, KEY="value with spaces", export KEY=value
    - Strips inline comments starting with # when not inside quotes
    - Trims surrounding single/double quotes
    """
    env: dict[str, str] = {}
    try:
        if not path.exists():
            return env
        text = path.read_text(encoding="utf-8")
        for raw in text.splitlines():
            s = raw.strip()
            if not s or s.startswith("#"):
                continue
            # Drop leading 'export '
            if s.lower().startswith("export "):
                s = s[7:].lstrip()
            if "=" not in s:
                continue
            # Remove inline comments outside quotes
            in_single = False
            in_double = False
            cut_idx = None
            for i, ch in enumerate(s):
                if ch == "'" and not in_double:
                    in_single = not in_single
                elif ch == '"' and not in_single:
                    in_double = not in_double
                elif ch == "#" and not in_single and not in_double:
                    cut_idx = i
                    break
            if cut_idx is not None:
                s = s[:cut_idx].rstrip()
            if "=" not in s:
                continue
            k, v = s.split("=", 1)
            k = k.strip()
            v = v.strip()
            # Trim surrounding quotes if present
            if (len(v) >= 2) and ((v[0] == v[-1]) and v[0] in ('"', "'")):
                v = v[1:-1]
            if k:
                env[k] = v
    except Exception as e:
        print(f"[authorization] Warning: failed reading env file {path}: {e}", file=sys.stderr)
        return env
    return env


def _approval_db_path() -> Optional[Path]:
    # 1) OS environment
    env = os.getenv("VDM_APPROVAL_DB")
    if env:
        p = Path(env)
        print(f"[authorization] Using approvals DB from environment variable VDM_APPROVAL_DB: {p}", file=sys.stderr)
        return p
    # 2) .env files (search upward: code -> Derivation -> repo root)
    try:
        code_dir = Path(__file__).resolve().parents[2]
        deriv_dir = Path(__file__).resolve().parents[3]
        repo_root = deriv_dir.parent
        for candidate in [code_dir / ".env", deriv_dir / ".env", repo_root / ".env"]:
            envs = _read_env_file(candidate)
            if "VDM_APPROVAL_DB" in envs:
                p = Path(envs["VDM_APPROVAL_DB"]).expanduser()
                print(f"[authorization] Using approvals DB from env file {candidate}: {p}", file=sys.stderr)
                return p
        # No env variable found anywhere; inform user where to set it
        checked_paths = ", ".join(str(x) for x in [code_dir / ".env", deriv_dir / ".env", repo_root / ".env"])
        print(
            "[authorization] No VDM_APPROVAL_DB found in environment or .env files. "
            f"You can set it globally (export VDM_APPROVAL_DB=/path/to/approval.db) or add it to one of: {checked_paths}",
            file=sys.stderr,
        )
    except Exception as e:
        print(f"[authorization] Warning: failed scanning .env files for VDM_APPROVAL_DB: {e}", file=sys.stderr)
    # 3) default path if present
    if DEFAULT_DB_PATH.exists():
        print(f"[authorization] Using approvals DB at default path: {DEFAULT_DB_PATH}", file=sys.stderr)
        return DEFAULT_DB_PATH
    return None


def _approval_admin_db_path() -> Optional[Path]:
    # 1) OS environment
    env = os.getenv("VDM_APPROVAL_ADMIN_DB")
    if env:
        p = Path(env)
        print(f"[authorization] Using admin DB from environment variable VDM_APPROVAL_ADMIN_DB: {p}", file=sys.stderr)
        return p
    # 2) .env files (search upward: code -> Derivation -> repo root)
    try:
        code_dir = Path(__file__).resolve().parents[2]
        deriv_dir = Path(__file__).resolve().parents[3]
        repo_root = deriv_dir.parent
        for candidate in [code_dir / ".env", deriv_dir / ".env", repo_root / ".env"]:
            envs = _read_env_file(candidate)
            if "VDM_APPROVAL_ADMIN_DB" in envs:
                p = Path(envs["VDM_APPROVAL_ADMIN_DB"]).expanduser()
                print(f"[authorization] Using admin DB from env file {candidate}: {p}", file=sys.stderr)
                return p
    except Exception as e:
        print(f"[authorization] Warning: failed scanning .env files for VDM_APPROVAL_ADMIN_DB: {e}", file=sys.stderr)
    # 3) default admin path if present; else fall back to approvals DB path
    if DEFAULT_ADMIN_DB_PATH.exists():
        print(f"[authorization] Using admin DB at default path: {DEFAULT_ADMIN_DB_PATH}", file=sys.stderr)
        return DEFAULT_ADMIN_DB_PATH
    # fallback to the approvals DB file for backward compatibility
    return _approval_db_path()


def ensure_public_db(dbp: Path) -> None:
    dbp.parent.mkdir(parents=True, exist_ok=True)
    with sqlite3.connect(str(dbp)) as conn:
        conn.executescript(SCHEMA_SQL_PUBLIC)
        conn.commit()
    try:
        os.chmod(dbp, 0o600)
    except Exception as _e:
        _ = _e


def ensure_admin_db(dbp: Path) -> None:
    dbp.parent.mkdir(parents=True, exist_ok=True)
    with sqlite3.connect(str(dbp)) as conn:
        conn.executescript(SCHEMA_SQL_ADMIN)
        conn.commit()
    try:
        os.chmod(dbp, 0o600)
    except Exception as _e:
        _ = _e


def db_get_expected_key(dbp: Path, domain: str, tag: str) -> Optional[str]:
    if not dbp.exists():
        return None
    try:
        with sqlite3.connect(str(dbp)) as conn:
            cur = conn.execute(
                "SELECT expected_key FROM approvals WHERE domain=? AND tag=?",
                (domain, tag),
            )
            row = cur.fetchone()
            return row[0] if row else None
    except Exception:
        return None


def db_get_domain_key(dbp: Path, domain: str) -> Optional[str]:
    if not dbp.exists():
        return None
    try:
        with sqlite3.connect(str(dbp)) as conn:
            cur = conn.execute("SELECT domain_key FROM domain_keys WHERE domain=?", (domain,))
            row = cur.fetchone()
            return row[0] if row else None
    except Exception:
        return None


def db_get_tag_secret(dbp: Path, domain: str, tag: str) -> Optional[str]:
    if not dbp.exists():
        return None
    try:
        with sqlite3.connect(str(dbp)) as conn:
            cur = conn.execute("SELECT tag_secret FROM tag_secrets WHERE domain=? AND tag=?", (domain, tag))
            row = cur.fetchone()
            return row[0] if row else None
    except Exception:
        return None


def compute_expected_key(secret: str, domain: str, tag: str, script: Optional[str] = None) -> str:
    """Compute HMAC approval key with policy message domain:script:tag.

    If script is None, falls back to domain:tag for backward compatibility.
    """
    if script:
        msg = f"{domain}:{script}:{tag}".encode("utf-8")
    else:
        msg = f"{domain}:{tag}".encode("utf-8")
    return hmac.new(secret.encode("utf-8"), msg, hashlib.sha256).hexdigest()


def upsert_approval(dbp: Path, rec: ApprovalRecord) -> None:
    ensure_public_db(dbp)
    with sqlite3.connect(str(dbp)) as conn:
        conn.execute(
            """
            INSERT INTO approvals(domain, tag, expected_key, approved_by, approved_at)
            VALUES(?, ?, ?, ?, ?)
            ON CONFLICT(domain, tag) DO UPDATE SET
              expected_key=excluded.expected_key,
              approved_by=excluded.approved_by,
              approved_at=excluded.approved_at
            """,
            (rec.domain, rec.tag, rec.expected_key, rec.approved_by, rec.approved_at),
        )
        conn.commit()


def set_domain_key(dbp: Path, domain: str, domain_key: str) -> None:
    ensure_public_db(dbp)
    with sqlite3.connect(str(dbp)) as conn:
        conn.execute("DELETE FROM domain_keys WHERE domain=?", (domain,))
        conn.execute(
            "INSERT INTO domain_keys(domain, domain_key, created_at) VALUES (?, ?, ?)",
            (domain, domain_key, _iso_now_utc()),
        )
        conn.commit()


def set_tag_secret(dbp: Path, domain: str, tag: str, tag_secret: str) -> None:
    ensure_public_db(dbp)
    with sqlite3.connect(str(dbp)) as conn:
        conn.execute(
            """
            INSERT INTO tag_secrets(domain, tag, tag_secret, created_at)
            VALUES(?, ?, ?, ?)
            ON CONFLICT(domain, tag) DO UPDATE SET tag_secret=excluded.tag_secret, created_at=excluded.created_at
            """,
            (domain, tag, tag_secret, _iso_now_utc()),
        )
        conn.commit()


# Admin password (PBKDF2-SHA256)
def _pbkdf2(password: str, salt: bytes, iterations: int = 100_000, dklen: int = 32) -> bytes:
    return hashlib.pbkdf2_hmac('sha256', password.encode('utf-8'), salt, iterations, dklen)


def _rand_salt(n: int = 16) -> bytes:
    return os.urandom(n)


def set_admin_password(dbp: Path, password: str, iterations: int = 100_000) -> None:
    ensure_admin_db(dbp)
    salt = _rand_salt()
    digest = _pbkdf2(password, salt, iterations=iterations)
    with sqlite3.connect(str(dbp)) as conn:
        conn.execute("DELETE FROM admin WHERE id=1")
        conn.execute(
            """
            INSERT INTO admin(id, password_scheme, password_hash, salt, iterations, created_at)
            VALUES (1, ?, ?, ?, ?, ?)
            """,
            ('pbkdf2_sha256', digest.hex(), salt.hex(), iterations, _iso_now_utc()),
        )
        conn.commit()


def verify_admin_password(dbp: Path, password: str) -> bool:
    if not dbp.exists():
        return False
    try:
        with sqlite3.connect(str(dbp)) as conn:
            cur = conn.execute("SELECT password_scheme, password_hash, salt, iterations FROM admin WHERE id=1")
            row = cur.fetchone()
            if not row:
                return False
            scheme, hash_hex, salt_hex, iterations = row
            if scheme != 'pbkdf2_sha256':
                return False
            salt = bytes.fromhex(salt_hex)
            calc = _pbkdf2(password, salt, iterations=int(iterations))
            return hmac.compare_digest(calc.hex(), hash_hex)
    except Exception:
        return False


def ensure_admin_verified(dbp: Path, password: str) -> bool:
    ensure_admin_db(dbp)
    with sqlite3.connect(str(dbp)) as conn:
        cur = conn.execute("SELECT COUNT(1) FROM admin WHERE id=1")
        exists = bool(cur.fetchone()[0])
    if not exists:
        set_admin_password(dbp, password)
        return True
    return verify_admin_password(dbp, password)


def check_tag_approval(domain: str, tag: str, allow_unapproved: bool, code_root: Path) -> Tuple[bool, bool, Optional[str]]:
    """
    Enforce proposal-based tag approval with cryptographic approval keys.

    Manifest location priority (case-insensitive domain):
      1) Derivation/code/physics/<domain>/APPROVAL.json
      2) Derivation/<domain>/APPROVAL.json (writings fallback)

    Required for approval:
      - pre_registered = true
                        details.append(
                            "Approval entry missing 'approval_key' - use approve_tag.py to set a domain key or tag secret, then run 'approve' to stamp the manifest."
                        )
      - proposal file exists
      - schema file exists and contains {"tag": "<tag>"}
      - approved_by matches VDM_APPROVER_NAME (default: "Justin K. Lietz")
      - approval_key matches either:
          a) HMAC-SHA256(VDM_APPROVAL_SECRET or VDM_APPROVAL_SECRET_FILE, f"{domain}:{tag}")
          b) The first line of the file at VDM_APPROVAL_KEY_FILE (exact match)

    Returns (approved, engineering_only, proposal_path)
    """
    derivation_dir = code_root.parent  # Derivation/

    # Resolve code domain directory
    code_domain_dir = code_root / "physics" / domain
    if not code_domain_dir.exists() and (code_root / "physics").exists():
        for d in (code_root / "physics").iterdir():
            if d.is_dir() and d.name.lower() == domain.lower():
                code_domain_dir = d
                break

    # Resolve writings domain directory (fallback)
    domain_dir = derivation_dir / domain
    if not domain_dir.exists() and derivation_dir.exists():
        for d in derivation_dir.iterdir():
            if d.is_dir() and d.name.lower() == domain.lower():
                domain_dir = d
                break

    apath = (code_domain_dir / "APPROVAL.json") if (code_domain_dir / "APPROVAL.json").exists() else (domain_dir / "APPROVAL.json")
    approved = False
    proposal: Optional[str] = None

    # (DB helpers provided at module scope)

    def _resolve_path(p: str | Path, base_dir: Optional[Path] = None) -> Path:
        if isinstance(p, Path):
            cand = p
        else:
            cand = Path(p)
        if cand.is_absolute():
            return cand
        repo_root = derivation_dir.parent
        search_bases = [b for b in [base_dir, repo_root, derivation_dir, code_root] if b is not None]
        for base in search_bases:
            trial = (base / cand).resolve()
            if trial.exists():
                return trial
        for dname in ("Derivation", "derivation"):
            trial = (derivation_dir.parent / dname / cand.name).resolve()
            if trial.exists():
                return trial
        return (derivation_dir.parent / cand).resolve()

    def _find_schema_path(tag_: str, manifest: Dict[str, Any]) -> Optional[Path]:
        approvals = manifest.get("approvals", {}) or {}
        if isinstance(approvals, dict):
            entry = approvals.get(tag_)
            if isinstance(entry, dict) and entry.get("schema"):
                return _resolve_path(entry["schema"], base_dir=apath.parent)  # type: ignore[arg-type]
        schemas = manifest.get("schemas", {}) or {}
        if isinstance(schemas, dict) and schemas.get(tag_):
            return _resolve_path(schemas[tag_], base_dir=apath.parent)  # type: ignore[index]
        schema_dir = manifest.get("schema_dir")
        if schema_dir:
            base = _resolve_path(schema_dir, base_dir=apath.parent)
            for nm in (f"{tag_}.schema.json", f"{tag_}.json"):
                cand = base / nm
                if cand.exists():
                    return cand
        for d in (derivation_dir / domain / "schemas", derivation_dir / domain / "SCHEMAS"):
            for nm in (f"{tag_}.schema.json", f"{tag_}.json"):
                cand = d / nm
                if cand.exists():
                    return cand
        return None

    def _validate_schema(tag_: str, schema_path: Path) -> bool:
        try:
            with schema_path.open("r", encoding="utf-8") as fs:
                sdata = json.load(fs)
        except Exception:
            return False
        tag_in_file = sdata.get("tag") or ((sdata.get("metadata") or {}).get("tag") if isinstance(sdata.get("metadata"), dict) else None)
        if str(tag_in_file) != str(tag_):
            return False
        if not ("$schema" in sdata or "type" in sdata):
            return False
        return True

    def _get_expected_key_from_db(domain_: str, tag_: str) -> Optional[str]:
        p = _approval_db_path()
        if not p:
            return None
        return db_get_expected_key(p, domain_, tag_)

    def _compute_expected_from_domain_or_tag(domain_: str, tag_: str, script_: Optional[str]) -> Optional[str]:
        p = _approval_db_path()
        if not p:
            return None
        tsecret = db_get_tag_secret(p, domain_, tag_)
        if tsecret:
            return compute_expected_key(tsecret, domain_, tag_, script_)
        dkey = db_get_domain_key(p, domain_)
        if dkey:
            return compute_expected_key(dkey, domain_, tag_, script_)
        return None

    try:
        if apath.exists():
            with apath.open("r", encoding="utf-8") as f:
                adata: Dict[str, Any] = json.load(f)
            allowed = set(adata.get("allowed_tags", []))
            proposal = adata.get("proposal")
            proposal_path = _resolve_path(proposal, base_dir=apath.parent) if proposal else None
            has_proposal = bool(proposal_path and proposal_path.exists())
            schema_path = _find_schema_path(tag, adata)
            has_schema = bool(schema_path and schema_path.exists())
            schema_valid = bool(schema_path and has_schema and _validate_schema(tag, schema_path))
            approver_expected = os.getenv("VDM_APPROVER_NAME", "Justin K. Lietz")
            approvals = adata.get("approvals", {}) or {}
            appr_entry = approvals.get(tag) if isinstance(approvals, dict) else None
            approved_by_ok = False
            if isinstance(appr_entry, dict):
                who = str(appr_entry.get("approved_by", "")).strip()
                approved_by_ok = (who.lower() == approver_expected.lower()) or (approver_expected.lower() in who.lower())
            approval_key_ok = False
            if isinstance(appr_entry, dict):
                have_key = str(appr_entry.get("approval_key", "")).strip()
                # DB-only strict mode: require DB and match; compute expected by priority (tag secret first, then domain key, then stored expected)
                # Determine run script name from env or argv
                script_name: Optional[str] = os.getenv("VDM_RUN_SCRIPT")
                if not script_name:
                    try:
                        argv0 = sys.argv[0]
                        if argv0:
                            script_name = Path(argv0).stem or Path(argv0).name
                    except Exception:
                        script_name = None
                expected = _compute_expected_from_domain_or_tag(domain, tag, script_name)
                if expected is None:
                    expected = _get_expected_key_from_db(domain, tag)
                approval_key_ok = bool(have_key and expected and (have_key == expected))

            approved = bool(
                adata.get("pre_registered", False)
                and (tag in allowed)
                and has_proposal
                and has_schema
                and schema_valid
                and approved_by_ok
                and approval_key_ok
            )

            if proposal_path:
                os.environ["VDM_POLICY_PROPOSAL"] = str(proposal_path)
            if schema_path:
                os.environ["VDM_POLICY_SCHEMA"] = str(schema_path)
            if appr_entry and isinstance(appr_entry, dict):
                if appr_entry.get("approved_by"):
                    os.environ["VDM_POLICY_APPROVED_BY"] = str(appr_entry.get("approved_by"))
                if appr_entry.get("approved_at"):
                    os.environ["VDM_POLICY_APPROVED_AT"] = str(appr_entry.get("approved_at"))
                if appr_entry.get("approval_key"):
                    os.environ["VDM_POLICY_APPROVAL_KEY_PRESENT"] = "1"
    except Exception:
        approved = False

    if not approved and not allow_unapproved:
        details: list[str] = []
        if not apath.exists():
            details.append(f"Missing approval manifest: {apath}")
        else:
            try:
                with apath.open("r", encoding="utf-8") as f:
                    _adata = json.load(f)
                if tag not in set(_adata.get("allowed_tags", [])):
                    details.append(f"Tag '{tag}' not listed in allowed_tags")
                prop = _adata.get("proposal")
                if not prop:
                    details.append("Field 'proposal' missing in manifest")
                else:
                    pth = (_resolve_path(prop, base_dir=apath.parent))
                    if not pth.exists():
                        details.append(f"Proposal not found at: {pth}")
                sch_path = _find_schema_path(tag, _adata)
                if not sch_path:
                    details.append("Schema path for tag not declared or discoverable (see approvals/schemas/schema_dir)")
                else:
                    if not sch_path.exists():
                        details.append(f"Schema file missing: {sch_path}")
                    else:
                        try:
                            with sch_path.open("r", encoding="utf-8") as fs:
                                sdata = json.load(fs)
                            if str(sdata.get("tag") or ((sdata.get("metadata") or {}).get("tag"))) != str(tag):
                                details.append("Schema 'tag' does not match requested tag")
                        except Exception as e:
                            details.append(f"Schema is not valid JSON: {e}")
                appr = _adata.get("approvals", {}).get(tag) if isinstance(_adata.get("approvals", {}), dict) else None
                if not (isinstance(appr, dict) and str(appr.get("approved_by", "")).strip()):
                    exp = os.getenv("VDM_APPROVER_NAME", "Justin K. Lietz")
                    details.append(f"Approval entry missing or lacks 'approved_by' (expected approver: {exp})")
                if not (isinstance(appr, dict) and str(appr.get("approval_key", "")).strip()):
                    details.append("Approval entry missing 'approval_key' - use approve_tag.py to set a domain key or tag secret, then run 'approve --script <run_script>' to stamp the manifest.")
                else:
                    have_key = str(appr.get("approval_key")).strip()
                    script_name: Optional[str] = os.getenv("VDM_RUN_SCRIPT")
                    if not script_name:
                        try:
                            argv0 = sys.argv[0]
                            if argv0:
                                script_name = Path(argv0).stem or Path(argv0).name
                        except Exception:
                            script_name = None
                    expected = _compute_expected_from_domain_or_tag(domain, tag, script_name)
                    if expected is None:
                        expected = _get_expected_key_from_db(domain, tag)
                    if _approval_db_path() is None:
                        details.append("No approvals DB found (set VDM_APPROVAL_DB or create common/data/approval.db)")
                    elif expected is None:
                        details.append("No DB record or keys for this tag/domain in VDM_APPROVAL_DB; approval denied")
                    elif have_key != expected:
                        details.append("approval_key mismatch against approval DB (VDM_APPROVAL_DB) using policy message 'domain:script:tag'")
            except Exception as e:
                details.append(f"Failed to parse manifest: {e}")

        print(
            (
                f"ERROR: tag '{tag}' is not approved for domain '{domain}'.\n" +
                "\n".join(f" - {d}" for d in details) +
                f"\nTo proceed, create/update {apath} with:\n" +
                "{\n  \"pre_registered\": true,\n  \"proposal\": \"Derivation/<domain>/PROPOSAL_<slug>.md\",\n  \"allowed_tags\": [\"<tag>\"],\n  \"approvals\": {\n    \"<tag>\": {\n      \"schema\": \"Derivation/<domain>/schemas/<tag>.schema.json\",\n      \"approved_by\": \"Justin K. Lietz\",\n      \"approved_at\": \"YYYY-MM-DD\",\n      \"approval_key\": \"<computed via approve_tag.py --script <run_script>>\"\n    }\n  }\n}\n" +
                "Or run with --allow-unapproved to quarantine artifacts (engineering-only)."
            ),
            file=sys.stderr,
        )
        raise SystemExit(2)

    engineering_only = not approved
    os.environ["VDM_POLICY_APPROVED"] = "1" if approved else "0"
    os.environ["VDM_POLICY_ENGINEERING"] = "1" if engineering_only else "0"
    os.environ["VDM_POLICY_TAG"] = str(tag)
    os.environ["VDM_POLICY_DOMAIN"] = str(domain)
    if proposal:
        os.environ["VDM_POLICY_PROPOSAL"] = str(proposal)
    return approved, engineering_only, proposal


# --- Enforcement policy helpers (DB-backed) ---


def _normalize_rel_script(p: Path) -> str:
    code_root = Path(__file__).resolve().parents[2]
    rel = p.resolve()
    try:
        rel = rel.relative_to(code_root)
    except Exception as e:
        print(f"[authorization] Note: could not relativize script path to code root ({code_root}): {e}", file=sys.stderr)
    return str(rel).replace("\\", "/").lower()


def db_list_exempt_scripts(dbp: Path) -> set[str]:
    if not dbp.exists():
        return set()
    try:
        with sqlite3.connect(str(dbp)) as conn:
            cur = conn.execute("SELECT script FROM exempt_scripts")
            rows = cur.fetchall()
            return {str(r[0]).lower() for r in rows}
    except Exception as e:
        print(f"[authorization] Warning: failed reading exempt scripts from DB: {e}", file=sys.stderr)
        return set()


def db_upsert_exempt_scripts(dbp: Path, scripts: list[str], noted_by: Optional[str] = None) -> int:
    ensure_public_db(dbp)
    ts = _iso_now_utc()
    count = 0
    try:
        with sqlite3.connect(str(dbp)) as conn:
            for s in scripts:
                conn.execute(
                    "INSERT OR IGNORE INTO exempt_scripts(script, created_at, noted_by) VALUES(?, ?, ?)",
                    (s.lower(), ts, noted_by),
                )
                count += conn.total_changes
            conn.commit()
    except Exception as e:
        print(f"[authorization] Failed to upsert exempt scripts: {e}", file=sys.stderr)
    return count


def db_remove_exempt_scripts(dbp: Path, scripts: list[str]) -> int:
    """Remove scripts from the exempt_scripts table. Returns number of rows affected."""
    if not dbp.exists():
        return 0
    removed = 0
    try:
        with sqlite3.connect(str(dbp)) as conn:
            for s in scripts:
                conn.execute("DELETE FROM exempt_scripts WHERE script=?", (s.lower(),))
                removed += conn.total_changes
            conn.commit()
    except Exception as e:
        print(f"[authorization] Failed to remove exempt scripts: {e}", file=sys.stderr)
    return removed


def should_enforce_approval(domain: str, script_path: Path) -> bool:
    """Return True if approval checks must be enforced for the given script.

            Policy:
                - Global default: enforce approval for all scripts in all domains.
                - Exception: if script's normalized relative path exists in DB table 'exempt_scripts', do not enforce.
    """
    dbp = _approval_db_path()
    if not dbp:
        print(f"[authorization] Warning: no approvals DB configured; safest to enforce", file=sys.stderr)
        return True
    rel = _normalize_rel_script(script_path)
    exempt = db_list_exempt_scripts(dbp)
    return rel not in exempt


# Public getters for paths
def get_approval_db_path() -> Optional[Path]:
    return _approval_db_path()


def get_admin_db_path() -> Optional[Path]:
    return _approval_admin_db_path()
]]></content>
    </file>
    <file>
      <path>authorization/approve_tag.py</path>
      <content><![CDATA[#!/usr/bin/env python3
"""
Approve a tag for a physics domain by updating the domain APPROVAL.json manifest and the local approvals DB.

DB-only flow (minimal files):
 - Prompts for your admin password (always manual, never from env) and verifies it against the local SQLite DB (VDM_APPROVAL_DB).
 - Computes approval_key = HMAC-SHA256(secret, f"{domain}:{script}:{tag}") where secret priority is:
     1) tag_secret (preferred)
     2) domain_key (fallback)
 - Stamps approved_by and approved_at in the manifest, and upserts the expected key into the DB.
 - Ensures pre_registered=true and allowed_tags contains the tag.
 - Optionally sets the schema path if missing (with --schema).

Notes:
 - The admin password gates DB access/verification; it is NOT used as the approval HMAC secret.
 - No environment secrets or key files are used; secrets live in the approvals DB.
 - The password is ALWAYS entered interactively; environment variables are ignored by design.
 - Read-only commands (check, exempt list) do not require a password; write operations do.

Usage examples:
    export VDM_APPROVAL_DB=/secure/vdm_approvals.sqlite3
    # Approve a tag (script-scoped HMAC) - provide --script to scope the approval key
    python3 Derivation/code/common/authorization/approve_tag.py approve metriplectic KG-dispersion-v1 \
        --script run_metriplectic.py --db "$VDM_APPROVAL_DB"

    # Exempt management (scripts that skip approval checks)
    python3 Derivation/code/common/authorization/approve_tag.py exempt list --db "$VDM_APPROVAL_DB"
    python3 Derivation/code/common/authorization/approve_tag.py exempt add Derivation/code/physics/metriplectic/run_metriplectic.py \
        --noted-by "Justin K. Lietz" --db "$VDM_APPROVAL_DB"
"""

from __future__ import annotations

import argparse
import datetime as dt
import json
import os
import sys
from pathlib import Path
import getpass
from .approval import (
    ensure_public_db,
    upsert_approval,
    ApprovalRecord,
    ensure_admin_verified,
    set_domain_key,
    set_tag_secret,
)  # type: ignore


# Legacy helpers removed: DB-only flow derives key from password; no secret files.


def _iso_utc_now() -> str:
    return dt.datetime.now(dt.timezone.utc).isoformat()


def main(argv: list[str] | None = None) -> int:
    p = argparse.ArgumentParser(description=__doc__)
    sub = p.add_subparsers(dest="cmd", required=False)

    # approve (default/back-compat)
    p_appr = sub.add_parser("approve", help="Approve a tag for a domain (default)")
    p_appr.add_argument("domain", help="Physics domain name (e.g., metriplectic)")
    p_appr.add_argument("tag", help="Tag to approve (e.g., KG-dispersion-v1)")
    p_appr.add_argument(
        "--manifest",
        help="Path to APPROVAL.json (default: Derivation/code/physics/<domain>/APPROVAL.json)",
    )
    p_appr.add_argument("--approver", default=os.getenv("VDM_APPROVER_NAME", "Justin K. Lietz"))
    p_appr.add_argument("--approved-at", dest="approved_at", help="Override ISO-8601 UTC timestamp")
    p_appr.add_argument("--schema", help="Optional schema path to set if missing")
    p_appr.add_argument("--script", help="Run script name (stem or filename) to include in approval HMAC (policy: domain:script:tag)")
    p_appr.add_argument("--dry-run", action="store_true", help="Do not write changes, just print what would change")
    # Approvals DB can also be passed after subcommand
    p_appr.add_argument("--db", dest="db_path", required=False, help="Path to approvals DB (SQLite). Defaults to Derivation/code/common/data/approval.db if present, else requires this flag.")

    # Approvals DB (top-level, applies when passed before subcommand)
    p.add_argument("--db", dest="db_path", required=False, help="Path to approvals DB (SQLite). Defaults to Derivation/code/common/data/approval.db if present, else requires this flag.")


    # set-domain-key
    p_dk = sub.add_parser("set-domain-key", help="Set or update a domain approval key (fallback when no tag_secret is set)")
    p_dk.add_argument("domain", help="Physics domain name")
    p_dk.add_argument("domain_key", help="Domain approval key (secret); stored in DB")

    # set-tag-secret
    p_ts = sub.add_parser("set-tag-secret", help="Set or update a tag/run secret (preferred over domain_key)")
    p_ts.add_argument("domain", help="Physics domain name")
    p_ts.add_argument("tag", help="Tag name")
    p_ts.add_argument("tag_secret", help="Tag/run secret (secret); stored in DB")

    # check
    p_ck = sub.add_parser("check", help="Check if a domain:tag has an expected key configured in DB (uses policy domain:script:tag when --script provided)")
    p_ck.add_argument("domain", help="Physics domain name")
    p_ck.add_argument("tag", help="Tag name")
    p_ck.add_argument("--script", help="Run script name (stem or filename) to include in approval HMAC computation")

    # exempt management
    p_ex = sub.add_parser("exempt", help="Manage script-based enforcement exemptions in approvals DB")
    ex_sub = p_ex.add_subparsers(dest="ex_cmd", required=True)
    p_ex_list = ex_sub.add_parser("list", help="List all exempt scripts")
    p_ex_add = ex_sub.add_parser("add", help="Add one or more scripts to exemptions (normalized relative path)")
    p_ex_add.add_argument("scripts", nargs="+", help="Script paths (relative to Derivation/code) or absolute")
    p_ex_add.add_argument("--noted-by", dest="noted_by", default=os.getenv("VDM_APPROVER_NAME", "Justin K. Lietz"))
    p_ex_rm = ex_sub.add_parser("remove", help="Remove one or more scripts from exemptions")
    p_ex_rm.add_argument("scripts", nargs="+", help="Script paths to remove")
    p_ex_snap = ex_sub.add_parser("snapshot", help="Scan Derivation/code/physics for existing scripts and add them as exempt")

    # status (read-only)
    p_st = sub.add_parser("status", help="Show initialization status of approvals (public) DB and admin DB")
    args = p.parse_args(argv)

    cmd = args.cmd or "approve"

    # Verify admin password in DB before any other DB operation
    # Resolve DB path: flag > env > default bundled location
    from .approval import DEFAULT_DB_PATH, get_admin_db_path
    dbp: Path
    if args.db_path:
        dbp = Path(args.db_path)
        print(f"[approve_tag] Using approvals DB from --db: {dbp}", file=sys.stderr)
    elif os.getenv("VDM_APPROVAL_DB"):
        dbp = Path(os.getenv("VDM_APPROVAL_DB"))
        print(f"[approve_tag] Using approvals DB from environment VDM_APPROVAL_DB: {dbp}", file=sys.stderr)
    else:
        # Fall back to default path and create on first use
        dbp = DEFAULT_DB_PATH
        print(f"[approve_tag] Using approvals DB at default path: {dbp} (will create if missing)", file=sys.stderr)
    # Determine if this command mutates the approvals DB (requires admin verification)
    write_ops = (
        (cmd in {"approve", "set-domain-key", "set-tag-secret"}) or
        (cmd == "exempt" and getattr(args, "ex_cmd", None) in {"add", "remove", "snapshot"})
    )
    if write_ops:
        # Resolve admin DB path (may differ from public approvals DB)
        admin_db = get_admin_db_path()
        if not admin_db:
            admin_db = dbp
        try:
            password = getpass.getpass("Admin password for approvals DB (won't echo): ")
        except Exception as e:
            print(f"ERROR: Unable to read password: {e}", file=sys.stderr)
            return 3
        if not password:
            print("ERROR: A password is required.", file=sys.stderr)
            return 3
        if not ensure_admin_verified(admin_db, password):
            print("ERROR: Admin password did not match the stored database password.", file=sys.stderr)
            return 3
    if cmd == "set-domain-key":
        domain = args.domain.strip()
        dkey = args.domain_key
        try:
            ensure_public_db(dbp)
            set_domain_key(dbp, domain, dkey)
            print(f"Domain key set for '{domain}' in {dbp}")
            return 0
        except Exception as e:
            print(f"ERROR: Failed setting domain key: {e}", file=sys.stderr)
            return 8

    if cmd == "set-tag-secret":
        domain = args.domain.strip()
        tag = args.tag.strip()
        secret = args.tag_secret
        try:
            ensure_public_db(dbp)
            set_tag_secret(dbp, domain, tag, secret)
            print(f"Tag secret set for '{domain}:{tag}' in {dbp}")
            return 0
        except Exception as e:
            print(f"ERROR: Failed setting tag secret: {e}", file=sys.stderr)
            return 9

    if cmd == "status":
        # Read-only status of DB initialization (no password required)
        import sqlite3  # local import to keep dependencies tight
        from .approval import get_admin_db_path

        def _tables_at(path: Path) -> set[str]:
            if not path.exists():
                return set()
            try:
                with sqlite3.connect(str(path)) as conn:
                    cur = conn.execute("SELECT name FROM sqlite_master WHERE type='table'")
                    return {r[0] for r in cur.fetchall()}
            except Exception:
                return set()

        admin_path = get_admin_db_path() or dbp
        public_expected = {"approvals", "domain_keys", "tag_secrets", "exempt_scripts"}
        admin_expected = {"admin"}
        public_present = _tables_at(dbp)
        admin_present = _tables_at(admin_path)
        out = {
            "public_db": {
                "path": str(dbp),
                "exists": Path(dbp).exists(),
                "tables_present": sorted(public_present),
                "tables_missing": sorted(public_expected - public_present),
            },
            "admin_db": {
                "path": str(admin_path),
                "exists": Path(admin_path).exists(),
                "tables_present": sorted(admin_present),
                "tables_missing": sorted(admin_expected - admin_present),
            },
        }
        print(json.dumps(out, indent=2))
        return 0

    if cmd == "exempt":
        from .approval import db_list_exempt_scripts, db_upsert_exempt_scripts, db_remove_exempt_scripts, _normalize_rel_script
        # list
        if args.ex_cmd == "list":
            ex = sorted(db_list_exempt_scripts(dbp))
            print(json.dumps({"exempt_scripts": ex, "count": len(ex)}, indent=2))
            return 0
        # add
        if args.ex_cmd == "add":
            scripts = []
            for s in args.scripts:
                pth = Path(s)
                if not pth.is_absolute():
                    pth = Path("Derivation") / "code" / pth
                scripts.append(_normalize_rel_script(pth))
            n = db_upsert_exempt_scripts(dbp, scripts, noted_by=getattr(args, "noted_by", None))
            print(json.dumps({"added": n, "scripts": scripts}, indent=2))
            return 0
        # remove
        if args.ex_cmd == "remove":
            scripts = [s.lower() for s in args.scripts]
            n = db_remove_exempt_scripts(dbp, scripts)
            print(json.dumps({"removed": n, "scripts": scripts}, indent=2))
            return 0
        # snapshot existing scripts
        if args.ex_cmd == "snapshot":
            code_root = Path("Derivation") / "code"
            physics = code_root / "physics"
            if not physics.exists():
                print("ERROR: No physics directory found to snapshot.", file=sys.stderr)
                return 11
            scripts: list[str] = []
            for d in physics.glob("**/*.py"):
                scripts.append(_normalize_rel_script(d))
            n = db_upsert_exempt_scripts(dbp, scripts, noted_by=os.getenv("VDM_APPROVER_NAME", "Justin K. Lietz"))
            print(json.dumps({"snapshotted": n, "total_seen": len(scripts)}, indent=2))
            return 0

    if cmd == "check":
        from .approval import db_get_expected_key, db_get_domain_key, db_get_tag_secret, compute_expected_key
        domain = args.domain.strip()
        tag = args.tag.strip()
        script = (args.script.strip() if getattr(args, "script", None) else None)
        exp = db_get_expected_key(dbp, domain, tag)
        dkey = db_get_domain_key(dbp, domain)
        tsecret = db_get_tag_secret(dbp, domain, tag)
        derived = None
        if tsecret:
            derived = compute_expected_key(tsecret, domain, tag, script)
        elif dkey:
            derived = compute_expected_key(dkey, domain, tag, script)
        print(json.dumps({
            "domain": domain,
            "tag": tag,
            "db_expected_key_exists": bool(exp),
            "has_domain_key": bool(dkey),
            "has_tag_secret": bool(tsecret),
            "derived_from_priority": "tag_secret" if tsecret else ("domain_key" if dkey else None),
            "script": script,
            "match": (exp == derived) if exp and derived else None,
        }, indent=2))
        return 0

    # Default: approve flow
    domain = args.domain.strip()
    tag = args.tag.strip()

    default_manifest = Path("Derivation") / "code" / "physics" / domain.lower() / "APPROVAL.json"
    manifest_path = Path(args.manifest) if args.manifest else default_manifest
    if not manifest_path.exists():
        print(f"ERROR: Manifest not found: {manifest_path}", file=sys.stderr)
        return 2

    # Derive the approval key from domain_key or tag_secret in DB (admin password only gates CLI usage)
    from .approval import db_get_domain_key, db_get_tag_secret, compute_expected_key
    dkey = db_get_domain_key(dbp, domain)
    tsecret = db_get_tag_secret(dbp, domain, tag)
    script = (args.script.strip() if getattr(args, "script", None) else None)
    if tsecret:
        approval_key = compute_expected_key(tsecret, domain, tag, script)
    elif dkey:
        approval_key = compute_expected_key(dkey, domain, tag, script)
    else:
        print(
            "ERROR: No domain key or tag secret found in the approvals DB for this domain/tag.\n"
            "Use 'set-domain-key' or 'set-tag-secret' first, then re-run 'approve'.",
            file=sys.stderr,
        )
        return 10

    approved_at = args.approved_at or _iso_utc_now()
    approver = args.approver

    # Load manifest
    try:
        data = json.loads(manifest_path.read_text(encoding="utf-8"))
    except Exception as e:
        print(f"ERROR: Failed to read manifest JSON: {e}", file=sys.stderr)
        return 4

    # Mutations
    before = json.dumps(data, sort_keys=True)
    data["pre_registered"] = True
    allowed = set(data.get("allowed_tags", []) or [])
    if tag not in allowed:
        allowed.add(tag)
        data["allowed_tags"] = sorted(allowed)

    approvals = data.setdefault("approvals", {})
    entry = approvals.setdefault(tag, {})
    if args.schema and not entry.get("schema"):
        schema_path = args.schema
        if not Path(schema_path).exists():
            print(f"ERROR: Provided --schema does not exist: {schema_path}", file=sys.stderr)
            return 5
        entry["schema"] = schema_path

    if not entry.get("schema"):
        print(
            "ERROR: No schema set for this tag in manifest and --schema not provided. Refusing to approve without a schema.",
            file=sys.stderr,
        )
        return 6

    entry["approved_by"] = approver
    entry["approved_at"] = approved_at
    entry["approval_key"] = approval_key

    after = json.dumps(data, sort_keys=True)
    if before == after:
        print("No changes needed; manifest already reflects this approval.")
        try:
            ensure_public_db(dbp)
            upsert_approval(dbp, ApprovalRecord(domain=domain, tag=tag, expected_key=approval_key, approved_by=approver, approved_at=approved_at))
            print(f"DB updated: {dbp} -> ({domain}, {tag})")
        except Exception as e:
            print(f"WARNING: Failed to write approvals DB: {e}")
        return 0

    print("Will apply changes:")
    print(f"  pre_registered: {data.get('pre_registered')}")
    print(f"  allowed_tags includes: {tag}")
    print(f"  approvals['{tag}'].approved_by: {approver}")
    print(f"  approvals['{tag}'].approved_at: {approved_at}")
    print(f"  approvals['{tag}'].approval_key: <hex {len(approval_key)} chars>")
    print(f"  approvals['{tag}'].schema: {entry.get('schema')}")
    if script:
        print(f"  approval message scope: domain:{script}:{tag}")

    if args.dry_run:
        print("Dry-run mode: no file was written.")
        return 0

    try:
        manifest_path.write_text(json.dumps(data, indent=2) + "\n", encoding="utf-8")
    except Exception as e:
        print(f"ERROR: Failed to write manifest: {e}", file=sys.stderr)
        return 7

    try:
        ensure_public_db(dbp)
        upsert_approval(dbp, ApprovalRecord(domain=domain, tag=tag, expected_key=approval_key, approved_by=approver, approved_at=approved_at))
        print(f"DB updated: {dbp} -> ({domain}, {tag})")
    except Exception as e:
        print(f"WARNING: Failed to write approvals DB: {e}")

    print(f"Updated manifest: {manifest_path}")
    return 0


if __name__ == "__main__":
    sys.exit(main())
]]></content>
    </file>
    <file>
      <path>causality/__init__.py</path>
      <content><![CDATA["""
Common causality helpers (order-only diagnostics)

Lightweight utilities to:
- Build an event DAG from timestamped events (with optional edge inference)
- Check acyclicity and compute a transitive reduction (TR)
- Sample Alexandrov intervals and estimate Myrheim–Meyer dimension d̂
- Analyze diamond growth |I| vs Δt and summarize diagnostics

Design:
- Dependency-minimal (pure Python + math/random; numpy optional in callers)
- Bounded algorithms with caps for large graphs
- Reusable across domains; no IO, no approvals; safe for CI hygiene

Modules:
- event_dag: DAG building, acyclicity, TR
- intervals: interval sampling, ordering fraction r, d̂ mapping, scaling
- diagnostics: convenience wrappers for one-shot summaries
"""

from .event_dag import (
	build_event_dag,
	is_acyclic,
	transitive_reduction,
)
from .intervals import (
	sample_intervals,
	ordering_fraction,
	dim_from_order_fraction,
	fit_diamond_scaling,
)
from .diagnostics import (
	dag_summary,
	interval_summary,
	full_causality_summary,
)

__all__ = [
	# event_dag
	"build_event_dag",
	"is_acyclic",
	"transitive_reduction",
	# intervals
	"sample_intervals",
	"ordering_fraction",
	"dim_from_order_fraction",
	"fit_diamond_scaling",
	# diagnostics
	"dag_summary",
	"interval_summary",
	"full_causality_summary",
]

]]></content>
    </file>
    <file>
      <path>causality/diagnostics.py</path>
      <content><![CDATA["""
Convenience diagnostics that compose event_dag and intervals helpers.

These are pure functions that consume in-memory structures and return dicts.
No IO, no approvals-safe for CI and unit tests.
"""
from __future__ import annotations
from typing import Dict, Iterable, List, Optional, Sequence, Tuple, Set

from .event_dag import build_event_dag, is_acyclic, transitive_reduction
from .intervals import sample_intervals, dim_from_order_fraction, fit_diamond_scaling


def dag_summary(
    events: Sequence[Tuple[str, float]],
    edges: Optional[Iterable[Tuple[str, str]]] = None,
    *,
    infer_by_time: bool = False,
    max_successors: int = 0,
    time_tolerance: float = 0.0,
    tr_edge_cap: int = 200_000,
) -> Dict[str, float | int | bool]:
    times, adj = build_event_dag(
        events,
        edges,
        infer_by_time=infer_by_time,
        max_successors=max_successors,
        time_tolerance=time_tolerance,
    )
    m = sum(len(v) for v in adj.values())
    acyclic = is_acyclic(adj)
    # TR size (best-effort)
    tr = transitive_reduction(adj, max_edges=tr_edge_cap)
    m_tr = sum(len(v) for v in tr.values())
    return {
        "n": len(times),
        "m": int(m),
        "acyclic": bool(acyclic),
        "m_tr": int(m_tr),
    }


def interval_summary(
    times: Dict[str, float],
    adj: Dict[str, Set[str]],
    *,
    k: int = 128,
    min_dt: float = 0.0,
    max_dt: Optional[float] = None,
    reach_budget: int = 8192,
) -> Dict[str, float | int]:
    samples = sample_intervals(
        times,
        adj,
        k=k,
        min_dt=min_dt,
        max_dt=max_dt,
        reach_budget=reach_budget,
    )
    n_samp = len(samples)
    if n_samp == 0:
        return {"samples": 0}
    # Dimension estimates per-sample
    ds = [dim_from_order_fraction(r) for (_p, _q, _dt, _sz, r) in samples]
    # Aggregate r as well
    rs = [r for (_p, _q, _dt, _sz, r) in samples]
    d_mean = float(sum(ds) / n_samp)
    d_min = float(min(ds)); d_max = float(max(ds))
    r_mean = float(sum(rs) / n_samp)
    # Diamond scaling slope
    slope, intercept = fit_diamond_scaling(samples)
    return {
        "samples": int(n_samp),
        "d_mean": d_mean,
        "d_min": d_min,
        "d_max": d_max,
        "r_mean": r_mean,
        "slope_logI_logDt": float(slope),
        "intercept_logI_logDt": float(intercept),
    }


def full_causality_summary(
    events: Sequence[Tuple[str, float]],
    edges: Optional[Iterable[Tuple[str, str]]] = None,
    *,
    infer_by_time: bool = False,
    max_successors: int = 0,
    time_tolerance: float = 0.0,
    k_intervals: int = 128,
    min_dt: float = 0.0,
    max_dt: Optional[float] = None,
    reach_budget: int = 8192,
    tr_edge_cap: int = 200_000,
) -> Dict[str, float | int | bool]:
    """
    One-shot combined summary: { DAG stats, interval stats, slope }.
    """
    times, adj = build_event_dag(
        events,
        edges,
        infer_by_time=infer_by_time,
        max_successors=max_successors,
        time_tolerance=time_tolerance,
    )
    dag = dag_summary(
        events,
        edges,
        infer_by_time=infer_by_time,
        max_successors=max_successors,
        time_tolerance=time_tolerance,
        tr_edge_cap=tr_edge_cap,
    )
    inter = interval_summary(
        times,
        adj,
        k=k_intervals,
        min_dt=min_dt,
        max_dt=max_dt,
        reach_budget=reach_budget,
    )
    out: Dict[str, float | int | bool] = {}
    out.update(dag)
    out.update(inter)
    return out
]]></content>
    </file>
    <file>
      <path>causality/event_dag.py</path>
      <content><![CDATA["""
Event DAG construction and minimal analyses (acyclicity, transitive reduction).

Goals
- Pure-Python, bounded algorithms suited for CI hygiene and small/medium analyses.
- Caller provides events with (id, t, ...). Edges can be provided explicitly or inferred
  with a simple precedence rule under a time tolerance.

Definitions
- Event: a hashable id and a timestamp float t.
- Edge inference (optional): u -> v if t_v - t_u >= 0 and within a caller-specified window
  or follows a supplied adjacency rule. By default we infer no edges unless asked, so this
  module is safe to import without side effects.

Notes
- For large graphs, prefer providing edges; transitive reduction is bounded by a max edge cap.
- We avoid third-party graph libs to stay dependency-minimal.
"""
from __future__ import annotations
from typing import Dict, Iterable, List, Optional, Sequence, Tuple, Set


Event = Tuple[str, float]
Edge = Tuple[str, str]


def build_event_dag(
    events: Sequence[Event],
    edges: Optional[Iterable[Edge]] = None,
    *,
    infer_by_time: bool = False,
    max_successors: int = 0,
    time_tolerance: float = 0.0,
) -> Tuple[Dict[str, float], Dict[str, Set[str]]]:
    """
    Build an event DAG adjacency from events and optional edges.

    Args
    - events: sequence of (id, t)
    - edges: optional iterable of (u, v) pairs; assumed to be candidate precedence edges
    - infer_by_time: when True, infer edges by time ordering within same-timestamp tolerance
    - max_successors: cap the number of successors added per node during inference (0 disables)
    - time_tolerance: allow small negative/zero lags |Δt| <= tol to count as zero-lag

    Returns: (times, adj) where
    - times: {id -> t}
    - adj: {u -> set(v)} (may include zero-lag edges when within tolerance)

    Note: acyclicity is not guaranteed; call is_acyclic to verify.
    """
    times: Dict[str, float] = {}
    for eid, t in events:
        # Skip malformed entries deterministically
        if eid is None:
            continue
        ts = None
        # Convert t to float if possible
        if isinstance(t, (int, float)):
            ts = float(t)
        else:
            try:
                ts = float(t)  # type: ignore
            except Exception:
                ts = None
        if ts is None or not (ts == ts):  # NaN guard
            continue
        times[str(eid)] = float(ts)

    adj: Dict[str, Set[str]] = {eid: set() for eid in times.keys()}

    if edges is not None:
        for u, v in edges:
            us = str(u); vs = str(v)
            if us in adj and vs in adj:
                adj[us].add(vs)

    if infer_by_time:
        # O(N log N + N * k) best effort: only wire minimal forward links by timestamp bins
        # We sort events by time; for ties within tolerance, optionally connect as zero-lag
        items = sorted(times.items(), key=lambda kv: kv[1])
        n = len(items)
        for i in range(n):
            ui, ti = items[i]
            succ = 0
            # Greedy forward links with increasing time; cap successors
            for j in range(i + 1, n):
                vj, tj = items[j]
                dt = tj - ti
                if dt < -abs(time_tolerance):
                    # future clock skew beyond tolerance → skip
                    continue
                # within tolerance: treat as zero-lag precedence (optional edge)
                if dt < abs(time_tolerance):
                    adj[ui].add(vj)
                    succ += 1
                else:
                    adj[ui].add(vj)
                    succ += 1
                if max_successors > 0 and succ >= max_successors:
                    break

    return times, adj


def is_acyclic(adj: Dict[str, Set[str]]) -> bool:
    """
    Return True if adjacency adj is acyclic (DAG), False otherwise.
    Uses Kahn's algorithm (iterative) to avoid recursion depth issues. O(V + E).
    """
    # Build indegree map
    indeg: Dict[str, int] = {u: 0 for u in adj.keys()}
    for u, vs in adj.items():
        for v in vs:
            if v not in indeg:
                indeg[v] = 0
            indeg[v] += 1

    # Initialize queue with zero‑indegree nodes
    from collections import deque
    q = deque([u for u, d in indeg.items() if d == 0])
    visited = 0

    # Copy adjacency to avoid mutating caller data
    local_adj: Dict[str, Set[str]] = {u: set(vs) for u, vs in adj.items()}

    while q:
        u = q.popleft()
        visited += 1
        for v in list(local_adj.get(u, ())):  # type: ignore
            indeg[v] -= 1
            # remove edge u->v from local view
            try:
                local_adj[u].remove(v)
            except KeyError:
                pass
            if indeg[v] == 0:
                q.append(v)

    # If all nodes were visited via zero‑indegree pops, graph is acyclic
    return visited == len(indeg)


def transitive_reduction(
    adj: Dict[str, Set[str]],
    *,
    max_edges: int = 200_000,
) -> Dict[str, Set[str]]:
    """
    Compute a transitive reduction (TR) approximation by removing edges u->v that
    are redundant via another path u -> ... -> v.

    Exact TR on arbitrary DAGs can be expensive; this routine caps work by a
    global edge budget. If the budget is exceeded, returns a best-effort reduction.

    Returns a new adjacency dict.
    """
    # Copy adjacency
    red: Dict[str, Set[str]] = {u: set(vs) for u, vs in adj.items()}

    # Early exit if graph is small
    total_e = sum(len(vs) for vs in red.values())
    if total_e == 0:
        return red

    # For each (u, v), see if there is an alternate path u -> w -> ... -> v
    processed = 0
    for u, vs in list(red.items()):
        if not vs:
            continue
        # union of successors of successors (limited expansion)
        # we use a bounded BFS from each successor to detect reachability back to v
        for v in list(vs):
            if processed >= max_edges:
                return red
            processed += 1
            # bounded reachability from neighbors of u excluding direct edge to v
            frontier = list(red[u] - {v})
            seen: Set[str] = set(frontier)
            found = False
            # breadth-first up to a reasonable depth cap to avoid worst-case blowup
            depth = 0
            DEPTH_CAP = 32
            while frontier and depth < DEPTH_CAP and processed < max_edges:
                depth += 1
                nxt: List[str] = []
                for w in frontier:
                    processed += 1
                    if w == v:
                        found = True
                        break
                    for z in red.get(w, ()):  # type: ignore
                        if z not in seen:
                            seen.add(z)
                            nxt.append(z)
                if found:
                    break
                frontier = nxt
            if found:
                # remove redundant edge
                try:
                    red[u].remove(v)
                except KeyError:
                    pass
    return red
]]></content>
    </file>
    <file>
      <path>causality/intervals.py</path>
      <content><![CDATA["""
Alexandrov interval sampling and order-based dimension/scale diagnostics.

We operate on an order-only DAG (no metric required). Given event times and a DAG
adjacency, we:
- Sample intervals I(p, q) = { x | p ≺ x ≺ q }
- Compute ordering fraction r = (# comparable pairs)/(N*(N-1)/2)
- Map r -> d_hat (Myrheim–Meyer estimator) via a calibrated monotone approximation
- Fit diamond growth |I| vs Δt on log–log for a mid-scale window

All functions are dependency-minimal and bounded via caps.
"""
from __future__ import annotations
from typing import Dict, Iterable, List, Optional, Sequence, Tuple, Set
import math
import random as _random


def _topo_index(times: Dict[str, float]) -> List[str]:
    # Sort by time, break ties by id for determinism
    return [k for k, _ in sorted(times.items(), key=lambda kv: (kv[1], kv[0]))]


def _reachable_forward(adj: Dict[str, Set[str]], src: str, budget: int) -> Set[str]:
    seen: Set[str] = set()
    frontier: List[str] = [src]
    steps = 0
    while frontier and steps < budget:
        nxt: List[str] = []
        for u in frontier:
            for v in adj.get(u, ()):  # type: ignore
                if v not in seen:
                    seen.add(v)
                    nxt.append(v)
            steps += 1
            if steps >= budget:
                break
        frontier = nxt
    return seen


def _interval_set(adj: Dict[str, Set[str]], p: str, q: str, budget: int) -> Set[str]:
    # I(p, q) = descendants(p) ∩ ancestors(q)
    desc_p = _reachable_forward(adj, p, budget)
    # ancestors via reverse adjacency
    rev: Dict[str, Set[str]] = {}
    for u, vs in adj.items():
        for v in vs:
            rev.setdefault(v, set()).add(u)
    # BFS on reverse
    seen: Set[str] = set()
    frontier: List[str] = [q]
    steps = 0
    while frontier and steps < budget:
        nxt: List[str] = []
        for u in frontier:
            for v in rev.get(u, ()):  # type: ignore
                if v not in seen:
                    seen.add(v)
                    nxt.append(v)
            steps += 1
            if steps >= budget:
                break
        frontier = nxt
    return desc_p.intersection(seen)


def ordering_fraction(members: Sequence[str], adj: Dict[str, Set[str]]) -> float:
    """
    Fraction of comparable pairs among members (u, v) where u ≺ v or v ≺ u.
    Approximated by checking adjacency reachability via bounded forward BFS.
    For small N, exact by transitive closure would be possible; we keep bounded.
    """
    idx = list(members)
    n = len(idx)
    if n <= 1:
        return 1.0
    total_pairs = n * (n - 1) // 2
    if total_pairs <= 0:
        return 1.0
    comparable = 0
    # Precompute forward closures for members with a small budget to keep bounded
    BUDGET = 4096
    fwd: Dict[str, Set[str]] = {u: _reachable_forward(adj, u, BUDGET) for u in idx}
    for i in range(n):
        ui = idx[i]
        for j in range(i + 1, n):
            vj = idx[j]
            if (vj in fwd[ui]) or (ui in fwd[vj]):
                comparable += 1
    return float(comparable) / float(total_pairs)


def dim_from_order_fraction(r: float) -> float:
    """
    Map ordering fraction r to an effective dimension d_hat.

    In continuum Minkowski spaces, r is a monotone function of d.
    Here we use a calibrated smooth approximation that fits the known
    values (2D, 3D, 4D) and behaves monotonically on r \in (0, 1).

    This is a pragmatic estimator; callers should treat it as a heuristic
    with CI from sampling variability.
    """
    # Clamp r to (eps, 1-eps) to avoid extremes
    eps = 1e-6
    r = max(eps, min(1.0 - eps, float(r)))
    # Smooth monotone map: d ~ 1 + a * logit(r) + b * r + c
    # Coefficients lightly tuned to place r~0.5 near d~3 and keep monotonicity.
    from math import log
    logit = log(r / (1.0 - r))
    a, b, c = 0.9, 1.2, 2.2
    d_hat = 1.0 + a * logit + b * r + c
    # Bound to a reasonable range
    return float(max(1.0, min(10.0, d_hat)))


def sample_intervals(
    times: Dict[str, float],
    adj: Dict[str, Set[str]],
    *,
    k: int = 128,
    min_dt: float = 0.0,
    max_dt: Optional[float] = None,
    reach_budget: int = 8192,
    rng: Optional[_random.Random] = None,
) -> List[Tuple[str, str, float, int, float]]:
    """
    Randomly sample k intervals (p, q) with p ≺ q.

    Returns a list of tuples: (p, q, dt, size, r)
      - dt = t_q - t_p
      - size = |I(p, q)|
      - r = ordering fraction among I(p, q) members (bounded reachability)
    """
    ids = _topo_index(times)
    n = len(ids)
    out: List[Tuple[str, str, float, int, float]] = []
    if n <= 1:
        return out
    _rng = rng if rng is not None else _random.Random(0)
    for _ in range(max(0, int(k))):
        # choose p < q by time order; pick indices far enough to satisfy min_dt
        for _attempt in range(64):
            i = _rng.randrange(0, n - 1)
            j = _rng.randrange(i + 1, n)
            p = ids[i]; q = ids[j]
            dt = float(times[q] - times[p])
            if dt < min_dt:
                continue
            if max_dt is not None and dt > max_dt:
                continue
            # ensure p ≺ q by reachability (bounded)
            fwd = _reachable_forward(adj, p, reach_budget)
            if q not in fwd:
                continue
            members = list(_interval_set(adj, p, q, reach_budget))
            size = len(members)
            if size <= 1:
                r = 1.0
            else:
                r = ordering_fraction(members, adj)
            out.append((p, q, dt, size, r))
            break
    return out


def fit_diamond_scaling(samples: List[Tuple[str, str, float, int, float]]) -> Tuple[float, float]:
    """
    Fit slope and intercept for log |I| vs log Δt using a simple least squares.

    Returns (slope, intercept). If insufficient data, returns (0.0, 0.0).
    """
    xs: List[float] = []
    ys: List[float] = []
    for _p, _q, dt, size, _r in samples:
        if dt > 0.0 and size > 0:
            xs.append(math.log(dt))
            ys.append(math.log(float(size)))
    n = len(xs)
    if n < 2:
        return 0.0, 0.0
    mx = sum(xs) / n
    my = sum(ys) / n
    num = sum((x - mx) * (y - my) for x, y in zip(xs, ys))
    den = sum((x - mx) ** 2 for x in xs)
    if den <= 0.0:
        return 0.0, 0.0
    slope = num / den
    intercept = my - slope * mx
    return float(slope), float(intercept)
]]></content>
    </file>
    <file>
      <path>constants.py</path>
      <content><![CDATA[#!/usr/bin/env python3
# VDM dimensionless helpers (LBM + RD + memory steering)
"""
Dimensionless numbers and lattice-unit helpers used across VDM runners.

Overview
- This module centralizes formulas for common non-dimensional groups and lattice-BGK
    relationships so experiments remain consistent and easy to audit.
- It is pure (no I/O) and safe to import in any runner or test.

Assumptions and conventions
- Lattice units (LBM): Δx = Δt = 1 (when stated); D2Q9 BGK with speed of sound
    c_s = 1/sqrt(3). Kinematic viscosity in lattice units is ν = (τ - 0.5)/3.
- Dimensionless groups follow standard fluid/transport conventions.
- Small epsilons (1e-15) are added in denominators purely to avoid division-by-zero
    in edge cases; they do not change scaling for well-posed inputs.

Units (typical)
- U: velocity [m/s], L: length [m], D: diffusivity [m^2/s], ν: kinematic viscosity [m^2/s]
- τ (tau): lattice relaxation time [lattice time units]

Quick reference
- lbm_cs(): lattice sound speed c_s in lattice units.
- lbm_viscosity_from_tau(τ): ν = (τ − 0.5)/3 in lattice units (D2Q9 BGK).
- reynolds_lbm(U, L, τ): Re = U L / ν using ν from τ (lattice-unit analysis).
- mach_lbm(U): Ma = U / c_s in lattice units.
- peclet(U, L, D): Pe = U L / D.
- damkohler(...): convective Da = k L / U; diffusive Da = k L^2 / D.
- steering_number(θ, ||∇m||, λ): Si = θ ||∇m|| / λ (internal to VDM steering analyses).
- void_number(Λ, Θ, Γ): Π_void = (Λ · Θ) / Γ (internal VDM diagnostic).
"""
from __future__ import annotations
import numpy as np

SQRT3 = np.sqrt(3.0)

def lbm_cs() -> float:
    """Return the LBM lattice sound speed c_s in lattice units.

    Model: D2Q9 BGK (isothermal) where c_s = 1/sqrt(3).
    Units: [lattice length]/[lattice time] (dimensionless in the Δx=Δt=1 convention).
    """
    return 1.0 / SQRT3

def lbm_viscosity_from_tau(tau: float) -> float:
    """Compute kinematic viscosity ν from relaxation time τ in lattice units.

    Formula (D2Q9 BGK): ν = (τ − 0.5) / 3.
    Constraints: τ > 0.5 for positive viscosity; τ close to 0.5 approaches inviscid/unstable regimes.
    Returns: ν in lattice units.
    """
    return (float(tau) - 0.5) / 3.0

def reynolds_lbm(U: float, L: float, tau: float) -> float:
    """Compute Reynolds number Re from velocity U, length L, and lattice τ.

    Steps: ν = (τ − 0.5)/3, then Re = U L / ν.
    Units: U and L follow the chosen unit system; when using lattice units, U and L
    are in lattice units and ν matches lattice scaling.
    Edge cases: adds 1e-15 to ν to prevent division-by-zero.
    """
    nu = lbm_viscosity_from_tau(tau)
    return (float(U) * float(L)) / (nu + 1e-15)

def mach_lbm(U: float) -> float:
    """Compute Mach number Ma = U / c_s in lattice units.

    Validity: LBM typically assumes Ma ≲ 0.1 for weakly compressible flows.
    """
    return float(U) / lbm_cs()

def peclet(U: float, L: float, D: float) -> float:
    """Compute Péclet number Pe = U L / D.

    Interpretation: advection-to-diffusion ratio; large Pe implies advection-dominated transport.
    Edge cases: adds 1e-15 to D in the denominator to avoid division-by-zero.
    """
    return (float(U) * float(L)) / (float(D) + 1e-15)

def damkohler(U: float, L: float, k: float, mode: str = "convective", D: float | None = None) -> float:
    """Compute Damköhler number (reaction vs. transport timescales).

    Modes
    - convective: Da = k L / U (reaction time vs. advection time)
    - diffusive : Da = k L^2 / D (reaction time vs. diffusion time)

    Parameters
    - U: characteristic velocity (>0)
    - L: characteristic length (>0)
    - k: reaction rate (≥0)
    - D: diffusivity (required for mode="diffusive")

    Returns
    - Da (dimensionless). Raises ValueError if mode is not recognized or required D is missing.
    """
    if mode == "convective":
        return (float(k) * float(L)) / (float(U) + 1e-15)
    elif mode == "diffusive":
        if D is None:
            raise ValueError("D must be provided for mode='diffusive'")
        return float(k) * (float(L) ** 2) / (float(D) + 1e-15)
    else:
        raise ValueError("mode must be 'convective' or 'diffusive'")

def steering_number(theta: float, grad_m_norm: float, lam: float) -> float:
    """Compute a VDM steering number Si = θ · ||∇m|| / λ.

    Context: Used in VDM "memory steering" analyses to compare control magnitude
    (θ · ||∇m||) against a regularization scale (λ). Larger Si implies stronger
    steering influence relative to the regularizer.
    """
    return (float(theta) * float(grad_m_norm)) / (float(lam) + 1e-15)

def void_number(Lambda: float, Theta: float, Gamma: float) -> float:
    """Compute Π_void = (Λ · Θ) / Γ - a VDM diagnostic for void re-organization pressure.

    Interpretation: proportional to the product (Λ · Θ) scaled by Γ; the exact
    physical mapping is domain-specific within VDM and is treated as a diagnostic ratio.
    """
    return (float(Lambda) * float(Theta)) / (float(Gamma) + 1e-15)

def soft_clip(x, lo, hi):
    """Elementwise clamp to the closed interval [lo, hi].

    Equivalent to min(max(x, lo), hi) applied pointwise over NumPy arrays or scalars.
    Useful for keeping fields within admissible bounds during diagnostics or plotting.
    """
    return np.minimum(np.maximum(x, lo), hi)

__all__ = [
    "lbm_cs",
    "lbm_viscosity_from_tau",
    "reynolds_lbm",
    "mach_lbm",
    "peclet",
    "damkohler",
    "steering_number",
    "void_number",
    "soft_clip",
]]]></content>
    </file>
    <file>
      <path>data/__init__.py</path>
      <content/>
    </file>
    <file>
      <path>data/approval.db</path>
      <content><![CDATA[SQLite format 3   @     $   	                                                            $ .
 P 
%
P                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ))etableexempt_scriptsexempt_scriptsCREATE TABLE exempt_scripts (
    script TEXT PRIMARY KEY,
    created_at TEXT NOT NULL,
    noted_by TEXT
);O) indexsqlite_autoindex_exempt_scripts_1exempt_scripts	?##Etabletag_secretstag_secretsCREATE TABLE tag_secrets (
  domain TEXT NOT NULL,
  tag TEXT NOT NULL,
  tag_secret TEXT NOT NULL,
  created_at TEXT NOT NULL,
  PRIMARY KEY(domain, tag)
)5I# indexsqlite_autoindex_tag_secrets_1tag_secrets##itabledomain_keysdomain_keysCREATE TABLE domain_keys (
  domain TEXT PRIMARY KEY,
  domain_key TEXT NOT NULL,
  created_at TEXT NOT NULL
)5I# indexsqlite_autoindex_domain_keys_1domain_keysYtableapprovalsapprovalsCREATE TABLE approvals (
  domain TEXT NOT NULL,
  tag TEXT NOT NULL,
  expected_key TEXT NOT NULL,
  approved_by TEXT NOT NULL,
  approved_at TEXT NOT NULL,
  PRIMARY KEY(domain, tag)
)1E indexsqlite_autoindex_approvals_1approvals       
   
1 kX

8a

	1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               *
)Y
+Mthermo_routingthermo-routing-v2-wave-meter-openports839ff04f40ed8b9493642cd5abc563915c0a6604d29d18bf7e05e9d390241dedJustin K. Lietz2025-10-13T19:42:37.359771+00:00 )E
+Mthermo_routingthermo-routing-v2-wave-meter2ebdf703296cd5c124692c33c2f8cd4eaa34f15ed4290289c88fd48e4b168055Justin K. Lietz2025-10-13T18:59:48.317715+00:00)9
+Mthermo_routingthermo-routing-v2-ftmc8ba078ec63391dd1c2c534239aa95f72b96d772854fc0d76993fe1f56defcfbfJustin K. Lietz2025-10-13T17:13:08.850411+00:00(
)U
+Mthermo_routingthermo-routing-v2-prereg-biased-main43967a0c5e3312cd4891713979a5f9c8b8dbf6460bdedbf48c0b8d94d5b4a546Justin K. Lietz2025-10-13T11:30:08.190071+00:00	)/
+Mthermo_routingthermo-routing-v2232c505835313363767bc7071603a327fa445e0704ef343c54e0626fdcfc7833Justin K. Lietz2025-10-13T08:31:05.092847+00:00%-
+MmetriplecticKG-energy-osc-v1a269ab8c11fdce428b0340a68692b6aeb2df4ff900a38b0f9423749f02169acbJustin K. Lietz2025-10-13T06:53:02.462385+00:00 95
+Mtachyonic_condensationtube-condensation-v15ad9f82d233d3c244bbc7b1d7a9403cdeb747c2bbc56897350c4110acbfd5755Justin K. Lietz2025-10-09T00:19:58.454610+00:009-
+Mtachyonic_condensationtube-spectrum-v19cba89da1d73a78c19a071257f810bf4b55759579ceddbe67c9c7f58ae3352d1Justin K. Lietz2025-10-09T00:18:28.922456+00:00%'
+MmetriplecticKG-noether-v1a924dd54ed5ecc335a91da47377dac861581425a6cfaaf05ebd05306207a1edbJustin K. Lietz2025-10-08T23:45:28.002644+00:00%
+Mmetriplecticstruct-v1f5e0011bde8e3a4bc5b9764d8284d8ceca64e7125777fb7f0914a4e4737e99c2Justin K. Lietz2025-10-08T23:05:30.920566+00:00
+Mcausalityv11126c62ef30e1ed965864bcf5f518de698b8213bb2c7c8f7c9d18b060200ca9dJustin K. Lietz2025-10-08T12:40:45.722017+00:00%!
+MmetriplecticKG-cone-v15846a9f6083a711704062d8429c65ca791768dde572099cd5e8f38b26bed850fJustin K. Lietz2025-10-08T10:08:02.804920+00:00%-
+MmetriplecticKG-dispersion-v13d704c3bff15826e4faffac7a8681cb56eadac16edb442879c7fb2511f62b46bJustin K. Lietz2025-10-08T10:08:10.978416+00:00
   
	 xLsC	                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       9)Ythermo_routingthermo-routing-v2-wave-meter-openports
/)Ethermo_routingthermo-routing-v2-wave-meter))9thermo_routingthermo-routing-v2-ftmc7)Uthermo_routingthermo-routing-v2-prereg-biased-main
$)/thermo_routingthermo-routing-v2	!%-metriplecticKG-energy-osc-v1/95tachyonic_condensationtube-condensation-v1+9-tachyonic_condensationtube-spectrum-v1%'metriplecticKG-noether-v1%metriplecticstruct-v1causalityv1%!metriplecticKG-cone-v1 %-	metriplecticKG-dispersion-v1
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              
   
 DN

V
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                d
)Y#Mthermo_routingthermo-routing-v2-wave-meter-openportsYOUR_SECRET2025-10-13T19:42:16.137553+00:00p)EOMthermo_routingthermo-routing-v2-wave-meterthermo_routing-v2-wave-meter-test2025-10-13T18:59:27.000023+00:00k)9QMthermo_routingthermo-routing-v2-ftmcvdm-thermo-routing-v2-ftmc-quantum2025-10-13T17:11:54.115335+00:00
)U{Mthermo_routingthermo-routing-v2-prereg-biased-mainvdm-thermo-routing-v2-prereg-biased-main-thermo_routing2025-10-13T11:27:00.392838+00:00h	)/UMthermo_routingthermo-routing-v2vdm-thermo-routing-v2-thermo-routing2025-10-13T08:27:59.501183+00:00b%-OMmetriplecticKG-energy-osc-v1vdm-KG-energy-osc-v1-metriplectic2025-10-13T06:51:52.169923+00:00~95kMtachyonic_condensationtube-condensation-v1vdm-tube-condensation-v1-tachyonic-condensation2025-10-09T00:19:16.123121+00:00v9-cMtachyonic_condensationtube-spectrum-v1vdm-tube-spectrum-v1-tachyonic-condensation2025-10-09T00:16:58.737027+00:00\%'IMmetriplecticKG-noether-v1vdm-KG-noether-v1-metriplectic2025-10-08T23:24:32.771951+00:00T%AMmetriplecticstruct-v1vdm-struct-v1-metriplectic2025-10-08T23:01:17.549820+00:00@-Mcausalityv1vdm_causality_v12025-10-08T12:38:46.270015+00:00V%!CMmetriplecticKG-cone-v1vdm-metriplectic-KG-cone-v12025-10-08T08:24:43.442800+00:00b%-OMmetriplecticKG-dispersion-v1vdm-metriplectic-KG-dispersion-v12025-10-08T08:17:44.876680+00:00
   
	 xLsC	                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       9)Ythermo_routingthermo-routing-v2-wave-meter-openports
/)Ethermo_routingthermo-routing-v2-wave-meter))9thermo_routingthermo-routing-v2-ftmc7)Uthermo_routingthermo-routing-v2-prereg-biased-main
$)/thermo_routingthermo-routing-v2	!%-metriplecticKG-energy-osc-v1/95tachyonic_condensationtube-condensation-v1+9-tachyonic_condensationtube-spectrum-v1%'metriplecticKG-noether-v1%metriplecticstruct-v1causalityv1%!metriplecticKG-cone-v1 %-	metriplecticKG-dispersion-v1
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              ]]></content>
    </file>
    <file>
      <path>data/approval_admin.db</path>
      <content><![CDATA[SQLite format 3   @                                                                     .
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  qAtableadminadminCREATE TABLE admin (
    id INTEGER PRIMARY KEY CHECK(id = 1),
    password_scheme TEXT NOT NULL,
    password_hash TEXT NOT NULL,
    salt TEXT NOT NULL,
    iterations INTEGER NOT NULL,
    created_at TEXT NOT NULL
)
   e e                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            '
MMpbkdf2_sha256fca59d103941fe27e770800d1cda0378fd7103ef3bf207c66dcdee61fe59a5d5b09546f2376cde631cb448f9376f3ced2025-10-08T08:17:44.435964+00:00]]></content>
    </file>
    <file>
      <path>data/results_db.py</path>
      <content><![CDATA[#!/usr/bin/env python3
"""
Lightweight results database helper.

Contract:
 - One SQLite database per physics domain under Derivation/code/outputs/databases/<domain>.sqlite3
 - One table per experiment script (table name = sanitized script stem, e.g., kg_light_cone)
 - Rows keyed by (tag, batch) where batch is incremental per tag within that table
 - Stores params/metrics/artifacts as JSON text; status and timestamps for lifecycle

Minimal API:
 - get_db_path(domain) -> Path
 - ensure_table(db_path, experiment) -> table_name
 - begin_run(domain, experiment, tag, params=None, engineering_only=False) -> RunHandle
 - log_metrics(handle, metrics)
 - add_artifacts(handle, artifacts)
 - end_run_success(handle, metrics=None)
 - end_run_failed(handle, metrics=None, error_message=None)

Notes:
 - Table column 'batch' increments per tag within the same table; (tag, batch) is UNIQUE.
 - A convenience 'run_slug' is stored as f"{experiment}_{tag}_b{batch:03d}" for consistent artifact naming.
 - Caller should use io_paths for files; you can reference file paths in artifacts.
"""
from __future__ import annotations

from dataclasses import dataclass
from datetime import datetime, timezone
from pathlib import Path
import json
import re
import sqlite3
import os
from typing import Any, Dict, Optional


# Local outputs root (aligned with common.io_paths)
# File lives in Derivation/code/common/data/, so parents[2] is Derivation/code
CODE_ROOT = Path(__file__).resolve().parents[2]
OUTPUTS = CODE_ROOT / "outputs"
DB_DIR = OUTPUTS / "databases"


def _iso_utc_now() -> str:
    return datetime.now(timezone.utc).isoformat()


def get_db_path(domain: str) -> Path:
    """Return the per-domain results DB path and ensure parent directories exist."""
    safe_domain = _sanitize_identifier(domain)
    DB_DIR.mkdir(parents=True, exist_ok=True)
    return DB_DIR / f"{safe_domain}.sqlite3"


def _sanitize_identifier(name: str) -> str:
    """Sanitize arbitrary names to safe SQLite identifier tokens (letters, digits, underscore).
    Lowercases and replaces non [a-zA-Z0-9_] with underscores; trims leading digits with a prefix.
    """
    s = re.sub(r"[^0-9a-zA-Z_]", "_", str(name).strip())
    if not s:
        s = "_"
    if s[0].isdigit():
        s = f"t_{s}"
    return s.lower()


def _assert_safe_identifier(name: str) -> None:
    """Raise ValueError if name isn't a safe identifier (lowercase letters, digits, underscore)."""
    if not re.fullmatch(r"[a-z0-9_]+", name):
        raise ValueError(f"Unsafe identifier: {name!r}")


def _ensure_db(db_path: Path) -> None:
    db_path.parent.mkdir(parents=True, exist_ok=True)
    with sqlite3.connect(str(db_path)) as conn:
        conn.execute("PRAGMA journal_mode=WAL;")
        conn.execute("PRAGMA foreign_keys=ON;")


def ensure_table(db_path: Path, experiment: str) -> str:
    """Create a table for the experiment if it doesn't exist. Returns the table name.
    The table has a UNIQUE(tag, batch) constraint to enforce incremental batches per tag.
    """
    _ensure_db(db_path)
    table = _sanitize_identifier(Path(experiment).stem if experiment.endswith(".py") else experiment)
    _assert_safe_identifier(table)
    ddl = f"""
    CREATE TABLE IF NOT EXISTS "{table}" (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        tag TEXT NOT NULL,
        batch INTEGER NOT NULL,
        run_script TEXT NOT NULL,
        run_slug TEXT NOT NULL,
        engineering_only INTEGER NOT NULL,
        status TEXT NOT NULL,
        started_at TEXT NOT NULL,
        finished_at TEXT,
        error_message TEXT,
        params_json TEXT,
        metrics_json TEXT,
        artifacts_json TEXT,
        row_hash TEXT NOT NULL,
        UNIQUE(tag, batch)
    );
    """
    with sqlite3.connect(str(db_path)) as conn:
        conn.execute(ddl)
        conn.commit()
    return table


def _find_case_insensitive_dir(base: Path, name: str) -> Optional[Path]:
    if (base / name).exists():
        return base / name
    lower = name.lower()
    if base.exists():
        for d in base.iterdir():
            if d.is_dir() and d.name.lower() == lower:
                return d
    return None


def _resolve_experiment_script(domain: str, experiment: str) -> Path:
    """Resolve the experiment script path.
    Accepts absolute/relative paths; otherwise, searches Derivation/code/physics/<domain> for <experiment>[.py].
    """
    p = Path(experiment)
    # If it's a direct path (absolute or relative) and exists, use it
    if p.exists():
        return p.resolve()
    # Search under code/physics/<domain>
    physics_dir = CODE_ROOT / "physics"
    domain_dir = _find_case_insensitive_dir(physics_dir, domain)
    if domain_dir is None:
        raise FileNotFoundError(f"Domain directory not found under {physics_dir}: {domain}")
    # Candidate filenames
    candidates: list[Path] = []
    if p.suffix == ".py":
        candidates.append(domain_dir / p.name)
    else:
        candidates.append(domain_dir / f"{p.name}.py")
    # Also search by stem match
    if domain_dir.exists():
        for f in domain_dir.glob("*.py"):
            if f.stem == p.name:
                candidates.append(f)
    for c in candidates:
        if c.exists():
            return c.resolve()
    raise FileNotFoundError(f"Experiment script not found for '{experiment}' in domain '{domain}'. Tried: {', '.join(str(c) for c in candidates)}")


def _find_manifest_path(domain: str) -> Optional[Path]:
    """Locate the approval manifest for a domain. Prefer code path, then writings fallback.
    Checks for APPROVAL.json primarily, then APPROVALS.json as a fallback.
    """
    physics_dir = CODE_ROOT / "physics"
    domain_dir_code = _find_case_insensitive_dir(physics_dir, domain)
    derivation_dir = CODE_ROOT.parent
    domain_dir_writing = _find_case_insensitive_dir(derivation_dir, domain)
    names = ("APPROVAL.json", "APPROVALS.json")
    for d in [domain_dir_code, domain_dir_writing]:
        if d is None:
            continue
        for nm in names:
            cand = d / nm
            if cand.exists():
                return cand
    return None


def _ensure_tag_allowed(domain: str, tag: str) -> None:
    """Validate that the tag appears in the domain's approval manifest.
    Requires allowed_tags to contain the tag and approvals[tag] to exist.
    Skipped when RESULTSDB_SKIP_APPROVAL_CHECK=1 is set.
    """
    if os.getenv("RESULTSDB_SKIP_APPROVAL_CHECK") == "1":
        return
    # If policy has already marked this run as approved, we can trust it; still attempt a lightweight check.
    mpath = _find_manifest_path(domain)
    if not mpath:
        raise FileNotFoundError(
            f"Approval manifest not found for domain '{domain}'. Expected at code or derivation domain folder (APPROVAL.json)."
        )
    try:
        data = json.loads(mpath.read_text(encoding="utf-8"))
    except Exception as e:
        raise ValueError(f"Failed to parse approval manifest JSON at {mpath}: {e}")
    allowed = set(data.get("allowed_tags", []) or [])
    if tag not in allowed:
        raise ValueError(f"Tag '{tag}' not listed in allowed_tags in {mpath}")
    approvals = data.get("approvals") or {}
    if not (isinstance(approvals, dict) and tag in approvals):
        raise ValueError(f"Missing approvals entry for tag '{tag}' in {mpath}")


def _next_batch_for_tag(conn: sqlite3.Connection, table: str, tag: str) -> int:
    _assert_safe_identifier(table)
    # nosec B608: table name is sanitized and validated via _assert_safe_identifier
    cur = conn.execute(f"SELECT COALESCE(MAX(batch), 0) FROM \"{table}\" WHERE tag=?", (tag,))  # nosec B608
    last = cur.fetchone()[0] or 0
    return int(last) + 1


@dataclass(frozen=True)
class RunHandle:
    db_path: Path
    table: str
    tag: str
    batch: int


def begin_run(domain: str, experiment: str, tag: str, params: Optional[Dict[str, Any]] = None, engineering_only: bool = False) -> RunHandle:
    """Start a run row and return a handle with (tag, batch).
    - Creates the per-domain DB and experiment table if missing
    - Computes the next batch for the tag and inserts a 'running' row
    """
    # Resolve experiment script and validate presence
    script_path = _resolve_experiment_script(domain, experiment)
    run_script = script_path.name
    # Set env to help downstream authorization policy (domain:script:tag HMAC scope)
    os.environ.setdefault("VDM_RUN_SCRIPT", Path(run_script).stem)

    # Approval enforcement: for qualifying scripts/domains, require manifest tag + full approval
    from ..authorization.approval import should_enforce_approval, check_tag_approval
    enforce = should_enforce_approval(domain, script_path)
    if enforce:
        # First ensure tag is declared in manifest
        _ensure_tag_allowed(domain, tag)
        # Then run full approval guard (raises on failure unless engineering_only allowed)
        code_root = CODE_ROOT
        approved, eng_only_flag, _proposal = check_tag_approval(domain, tag, allow_unapproved=engineering_only, code_root=code_root)
        # If not approved and not engineering_only, check_tag_approval would have exited; if engineering_only, mark flag
        engineering_only = engineering_only or eng_only_flag

    # Prepare DB path and validate directory permissions
    db_path = get_db_path(domain)
    if not db_path.parent.exists():
        raise FileNotFoundError(f"Results DB directory missing: {db_path.parent}")
    if not os.access(db_path.parent, os.W_OK):
        raise PermissionError(f"Results DB directory not writable: {db_path.parent}")

    # Ensure table exists (creates DB if needed)
    table = ensure_table(db_path, experiment)
    # Verify DB file exists post-initialization
    if not db_path.exists():
        raise FileNotFoundError(f"Results DB was not created at: {db_path}")

    started_at = _iso_utc_now()
    with sqlite3.connect(str(db_path)) as conn:
        # Compute next batch for the tag
        batch = _next_batch_for_tag(conn, table, tag)
        run_slug = f"{_sanitize_identifier(Path(experiment).stem)}_{_sanitize_identifier(tag)}_b{batch:03d}"
        _assert_safe_identifier(table)
        # Build SQL separately to tag with nosec on the assignment line (Bandit B608)
        sql_insert = f'INSERT INTO "{table}" (tag, batch, run_script, run_slug, engineering_only, status, started_at, params_json, metrics_json, artifacts_json, row_hash) VALUES (?, ?, ?, ?, ?, \'running\', ?, ?, ?, ?, ?)'  # nosec B608
        params_json = _canonical_json(params)
        metrics_json = _canonical_json({})
        artifacts_json = _canonical_json({})
        row_hash = _compute_row_hash_payload(
            tag=tag,
            batch=batch,
            run_script=run_script,
            run_slug=run_slug,
            engineering_only=1 if engineering_only else 0,
            status="running",
            started_at=started_at,
            finished_at=None,
            error_message=None,
            params_json=params_json,
            metrics_json=metrics_json,
            artifacts_json=artifacts_json,
        )
        conn.execute(
            sql_insert,
            (
                tag,
                batch,
                run_script,
                run_slug,
                1 if engineering_only else 0,
                started_at,
                params_json,
                metrics_json,
                artifacts_json,
                row_hash,
            ),
        )
        conn.commit()
    return RunHandle(db_path=db_path, table=table, tag=tag, batch=batch)


def _merge_json(existing_json: Optional[str], new_obj: Dict[str, Any]) -> str:
    try:
        base = json.loads(existing_json) if existing_json else {}
        if not isinstance(base, dict):
            base = {"_": base}
    except Exception:
        base = {}
    base.update(new_obj or {})
    return json.dumps(base, sort_keys=True, separators=(",", ":"))


def _canonical_json(obj: Any) -> str:
    return json.dumps(obj or {}, sort_keys=True, separators=(",", ":"))


def _compute_row_hash_payload(
    *,
    tag: str,
    batch: int,
    run_script: str,
    run_slug: str,
    engineering_only: int,
    status: str,
    started_at: Optional[str],
    finished_at: Optional[str],
    error_message: Optional[str],
    params_json: str,
    metrics_json: str,
    artifacts_json: str,
) -> str:
    import hashlib
    payload = {
        "tag": tag,
        "batch": batch,
        "run_script": run_script,
        "run_slug": run_slug,
        "engineering_only": engineering_only,
        "status": status,
        "started_at": started_at,
        "finished_at": finished_at,
        "error_message": error_message,
        "params_json": params_json or "{}",
        "metrics_json": metrics_json or "{}",
        "artifacts_json": artifacts_json or "{}",
    }
    s = json.dumps(payload, sort_keys=True, separators=(",", ":"))
    return hashlib.sha256(s.encode("utf-8")).hexdigest()


def log_metrics(handle: RunHandle, metrics: Dict[str, Any]) -> None:
    with sqlite3.connect(str(handle.db_path)) as conn:
        _assert_safe_identifier(handle.table)
        sql_sel = f"SELECT run_script, run_slug, engineering_only, status, started_at, finished_at, error_message, params_json, metrics_json, artifacts_json FROM \"{handle.table}\" WHERE tag=? AND batch=?"  # nosec B608
        cur = conn.execute(sql_sel, (handle.tag, handle.batch))
        row = cur.fetchone()
        if not row:
            return
        run_script, run_slug, eng, status, started_at, finished_at, error_message, params_json, metrics_json, artifacts_json = row
        merged_metrics = _merge_json(metrics_json, metrics)
        new_hash = _compute_row_hash_payload(
            tag=handle.tag,
            batch=handle.batch,
            run_script=run_script,
            run_slug=run_slug,
            engineering_only=int(eng),
            status=status,
            started_at=started_at,
            finished_at=finished_at,
            error_message=error_message,
            params_json=params_json or "{}",
            metrics_json=merged_metrics,
            artifacts_json=artifacts_json or "{}",
        )
        sql_upd = f"UPDATE \"{handle.table}\" SET metrics_json=?, row_hash=? WHERE tag=? AND batch=?"  # nosec B608
        conn.execute(sql_upd, (merged_metrics, new_hash, handle.tag, handle.batch))
        conn.commit()


def add_artifacts(handle: RunHandle, artifacts: Dict[str, Any]) -> None:
    with sqlite3.connect(str(handle.db_path)) as conn:
        _assert_safe_identifier(handle.table)
        sql_sel = f"SELECT run_script, run_slug, engineering_only, status, started_at, finished_at, error_message, params_json, metrics_json, artifacts_json FROM \"{handle.table}\" WHERE tag=? AND batch=?"  # nosec B608
        cur = conn.execute(sql_sel, (handle.tag, handle.batch))
        row = cur.fetchone()
        if not row:
            return
        run_script, run_slug, eng, status, started_at, finished_at, error_message, params_json, metrics_json, artifacts_json = row
        merged_artifacts = _merge_json(artifacts_json, artifacts)
        new_hash = _compute_row_hash_payload(
            tag=handle.tag,
            batch=handle.batch,
            run_script=run_script,
            run_slug=run_slug,
            engineering_only=int(eng),
            status=status,
            started_at=started_at,
            finished_at=finished_at,
            error_message=error_message,
            params_json=params_json or "{}",
            metrics_json=metrics_json or "{}",
            artifacts_json=merged_artifacts,
        )
        sql_upd = f"UPDATE \"{handle.table}\" SET artifacts_json=?, row_hash=? WHERE tag=? AND batch=?"  # nosec B608
        conn.execute(sql_upd, (merged_artifacts, new_hash, handle.tag, handle.batch))
        conn.commit()


def end_run_success(handle: RunHandle, metrics: Optional[Dict[str, Any]] = None) -> None:
    finished_at = _iso_utc_now()
    with sqlite3.connect(str(handle.db_path)) as conn:
        _assert_safe_identifier(handle.table)
        sql_sel = f"SELECT run_script, run_slug, engineering_only, status, started_at, metrics_json, artifacts_json, params_json FROM \"{handle.table}\" WHERE tag=? AND batch=?"  # nosec B608
        cur = conn.execute(sql_sel, (handle.tag, handle.batch))
        row = cur.fetchone()
        if not row:
            return
        run_script, run_slug, eng, _status, started_at, metrics_json, artifacts_json, params_json = row
        new_metrics = _merge_json(metrics_json, metrics) if metrics else (metrics_json or "{}")
        new_hash = _compute_row_hash_payload(
            tag=handle.tag,
            batch=handle.batch,
            run_script=run_script,
            run_slug=run_slug,
            engineering_only=int(eng),
            status="success",
            started_at=started_at,
            finished_at=finished_at,
            error_message=None,
            params_json=params_json or "{}",
            metrics_json=new_metrics,
            artifacts_json=artifacts_json or "{}",
        )
        if metrics:
            sql_upd = f"UPDATE \"{handle.table}\" SET metrics_json=?, status='success', finished_at=?, row_hash=? WHERE tag=? AND batch=?"  # nosec B608
            conn.execute(sql_upd, (new_metrics, finished_at, new_hash, handle.tag, handle.batch))
        else:
            sql_upd2 = f"UPDATE \"{handle.table}\" SET status='success', finished_at=?, row_hash=? WHERE tag=? AND batch=?"  # nosec B608
            conn.execute(sql_upd2, (finished_at, new_hash, handle.tag, handle.batch))
        conn.commit()


def end_run_failed(handle: RunHandle, metrics: Optional[Dict[str, Any]] = None, error_message: Optional[str] = None) -> None:
    finished_at = _iso_utc_now()
    with sqlite3.connect(str(handle.db_path)) as conn:
        _assert_safe_identifier(handle.table)
        sql_sel = f"SELECT run_script, run_slug, engineering_only, status, started_at, metrics_json, artifacts_json, params_json FROM \"{handle.table}\" WHERE tag=? AND batch=?"  # nosec B608
        cur = conn.execute(sql_sel, (handle.tag, handle.batch))
        row = cur.fetchone()
        if not row:
            return
        run_script, run_slug, eng, _status, started_at, metrics_json, artifacts_json, params_json = row
        new_metrics = _merge_json(metrics_json, metrics) if metrics else (metrics_json or "{}")
        new_hash = _compute_row_hash_payload(
            tag=handle.tag,
            batch=handle.batch,
            run_script=run_script,
            run_slug=run_slug,
            engineering_only=int(eng),
            status="failed",
            started_at=started_at,
            finished_at=finished_at,
            error_message=error_message,
            params_json=params_json or "{}",
            metrics_json=new_metrics,
            artifacts_json=artifacts_json or "{}",
        )
        if metrics:
            sql_upd = f"UPDATE \"{handle.table}\" SET metrics_json=?, status='failed', finished_at=?, error_message=?, row_hash=? WHERE tag=? AND batch=?"  # nosec B608
            conn.execute(sql_upd, (new_metrics, finished_at, error_message, new_hash, handle.tag, handle.batch))
        else:
            sql_upd2 = f"UPDATE \"{handle.table}\" SET status='failed', finished_at=?, error_message=?, row_hash=? WHERE tag=? AND batch=?"  # nosec B608
            conn.execute(sql_upd2, (finished_at, error_message, new_hash, handle.tag, handle.batch))
        conn.commit()


def get_runs(domain: str, experiment: str, tag: Optional[str] = None) -> list[dict]:
    """Fetch rows for inspection; for notebooks or quick diagnostics."""
    db_path = get_db_path(domain)
    table = ensure_table(db_path, experiment)
    with sqlite3.connect(str(db_path)) as conn:
        conn.row_factory = sqlite3.Row
        _assert_safe_identifier(table)
        if tag is None:
            sql_all = f"SELECT * FROM \"{table}\" ORDER BY tag, batch"  # nosec B608
            cur = conn.execute(sql_all)
            rows = cur.fetchall()
        else:
            sql_by_tag = f"SELECT * FROM \"{table}\" WHERE tag=? ORDER BY batch"  # nosec B608
            cur = conn.execute(sql_by_tag, (tag,))
            rows = cur.fetchall()
    out: list[dict] = []
    for r in rows:
        d = {k: r[k] for k in r.keys()}
        for col in ("params_json", "metrics_json", "artifacts_json"):
            if d.get(col):
                try:
                    d[col] = json.loads(d[col])
                except Exception as _e:
                    # Leave as raw JSON string if parsing fails; retain visibility into stored value
                    d[col] = d[col]
        out.append(d)
    return out
]]></content>
    </file>
    <file>
      <path>domain_setup/README.md</path>
      <content><![CDATA[# Domain Setup Tools

This allows the user or an agent to run a single command to scaffold a template domain for experiments. Doing so creates these directories:

- Prometheus_VDM/Derivation/code/physics/{domain}
- Prometheus_VDM/Derivation/code/physics/{domain}/schemas
  - Created with a generic example
- Prometheus_VDM/Derivation/code/physics/{domain}/specs
  - Created with a generic example
- Prometheus_VDM/Derivation/code/physics/{domain}/APPROVAL.json
  - Created with generic example content
- Prometheus_VDM/Derivation/code/physics/{domain}/README.md
  - Created with skeleton content. The header should be # {Domain} Experiments, with common sections listed with ## {Section name}. Some sections might include equations, constants, symbols and their meanings, or other important domain or experiment specific documentation.

## Schemas Directory

This directory will hold the schemas that define metadata about individual experiments, along with any tags that are associated.

## Specs Directory

This directory holds the individual configurations and other tag-specific metadata for the experiment. An individual spec MUST BE tag-specific.

## APPROVAL.json

This file is what is checked for the correct authorization hash key and other approval meta-data. If the data values within a given tag key is missing or incorrect, the helpers in common/ will not let the experiment run.

## README.md

This should be automatically created from a template skeleton to include blank sections that would be filled out with important, interesting, or domain specific details like equations, constants, symbols, or other items used that might also be documented in the global "all-caps" files at the root of Prometheus_VDM/Derivations/ (EQUATIONS.md for example).
]]></content>
    </file>
    <file>
      <path>domain_setup/__init__.py</path>
      <content/>
    </file>
    <file>
      <path>io_paths.py</path>
      <content><![CDATA[# derivation/code/common/io_paths.py
'''
# Example usage inside a physics script:

from pathlib import Path
import matplotlib.pyplot as plt
from common.io_paths import figure_path, log_path, write_log

domain, slug = "fluid_dynamics", "corner_test_r_c_scan"

# ... run simulation, compute metrics -> 'metrics' dict

# Save figure
fig_path = figure_path(domain, slug, failed=False)
plt.savefig(fig_path, dpi=160, bbox_inches="tight")

# Save log
log = {
    "timestamp": __import__("datetime").datetime.now().isoformat(),
    "git_hash": "YOUR_GIT_HASH_HERE",
    "seed": 1234,
    "domain": domain,
    "slug": slug,
    "params": {"H":1.0, "nu":1e-3, "...":"..."},
    "metrics": metrics,
    "status": "success"
}
write_log(log_path(domain, slug, failed=False, type="json"), log)

# In Markdown (relative to derivation/):
# ![Corner test r_c scan](code/outputs/figures/fluid_dynamics/20250823_corner_test_r_c_scan.png)
# [Run log](code/outputs/logs/fluid_dynamics/20250823_corner_test_r_c_scan.json)

'''
import csv
from pathlib import Path
from datetime import datetime
import json
import os

DERIVATION_ROOT = Path(__file__).resolve().parents[1]  # .../derivation/code
OUTPUTS = DERIVATION_ROOT / "outputs"

def _ts():
    return datetime.now().strftime("%Y%m%d_%H%M%S")

def ensure_dir(p: Path) -> Path:
    """Ensure that a directory exists."""
    p.mkdir(parents=True, exist_ok=True)
    return p

def build_slug(name: str, tag: str | None = None) -> str:
    """Build a canonical slug from a base name and optional tag.
    Keeps policy centralized so figures/logs remain consistent across experiments.
    """
    base = str(name).strip()
    if tag is None or str(tag).strip() == "":
        return base
    return f"{base}_{str(tag).strip()}"

def _policy_quarantine(default_failed: bool) -> bool:
    """Honor policy env to force quarantine when not approved.
    If VDM_POLICY_APPROVED=0, override failed=True. If VDM_POLICY_HARD_BLOCK=1, raise.
    """
    require_approval = os.getenv("VDM_REQUIRE_APPROVAL", "1") == "1"
    # If approval is required, default to not approved unless explicitly set to 1
    approved_env = os.getenv("VDM_POLICY_APPROVED")
    approved = (approved_env == "1") if require_approval else (approved_env != "0")
    hard_block = os.getenv("VDM_POLICY_HARD_BLOCK", "0") == "1"
    if not approved and hard_block:
        raise RuntimeError("Run is not approved by policy and hard block is enabled (VDM_POLICY_HARD_BLOCK=1)")
    if not approved:
        return True
    return default_failed


def figure_path(domain: str, slug: str, failed: bool=False) -> Path:
    """Generate a path for saving a figure.
    Args:
        domain (str): The domain of the experiment (e.g., "fluid_dynamics").
        slug (str): A short descriptive identifier for the experiment.
        failed (bool): Whether this is for a failed run."""
    failed = _policy_quarantine(failed)
    base = OUTPUTS / "figures" / domain / ("failed_runs" if failed else "")
    return ensure_dir(base) / f"{_ts()}_{slug}.png"

def figure_path_by_tag(domain: str, name: str, tag: str | None, failed: bool=False) -> Path:
    """Figure path using name+optional tag to build the slug centrally."""
    return figure_path(domain, build_slug(name, tag), failed=failed)

def log_path(domain: str, slug: str, failed: bool=False, type: str="json") -> Path:
    """Generate a path for saving a log file.
    Args:
        domain (str): The domain of the experiment (e.g., "fluid_dynamics").
        slug (str): A short descriptive identifier for the experiment.
        failed (bool): Whether this is for a failed run.
        type (str): The log file type, either 'json' or 'csv'."""
    failed = _policy_quarantine(failed)
    base = OUTPUTS / "logs" / domain / ("failed_runs" if failed else "")
    return ensure_dir(base) / f"{_ts()}_{slug}.{type}"

def log_path_by_tag(domain: str, name: str, tag: str | None, failed: bool=False, type: str="json") -> Path:
    """Log path using name+optional tag to build the slug centrally."""
    return log_path(domain, build_slug(name, tag), failed=failed, type=type)

def write_log(path: Path, data: dict):
    """Write a log file in JSON or CSV format.
    Args:
        path (Path): The file path to write the log to.
        data (dict): The log data to write."""
    ensure_dir(path.parent)
    with open(path, "w", encoding="utf-8") as f:
        if path.suffix == ".json":
            json.dump(data, f, indent=2, sort_keys=True)
        elif path.suffix == ".csv":
            writer = csv.DictWriter(f, fieldnames=data.keys())
            writer.writeheader()
            writer.writerow(data)
]]></content>
    </file>
    <file>
      <path>plotting/README.md</path>
      <content><![CDATA[# plotting/ - generic plotting helpers

Purpose

- Provide reusable plotting functions that work across experiments.
- Route all figure saves through `common/io_paths` to honor approval/quarantine policy.

Contents

- `types.py`: `PlotSpec` dataclass with domain, name, tag, labels, style, and flags.
- `core.py`: style application, figure creation, saving, and sidecar writing.
- `helpers.py`: `plot_line`, `plot_scatter`, `plot_image`, `plot_heatmap`, `plot_multi_panel`.

Usage

- Import from experiments:
  - `from common.plotting import PlotSpec, plot_line`
  - Build `spec = PlotSpec(domain="metriplectic", name="dispersion", tag="KG-dispersion-v1", xlabel="k [1/m]", ylabel="ω [rad/s]")`
  - `path, (fig, ax) = plot_line(x, y, spec, failed=engineering_only)`

Notes

- Sidecar JSON is written alongside the PNG with plot metadata and data stats.
- Slug building (name + optional tag) is centralized via `common/io_paths.build_slug`.
- Keep domain-specific visualization logic in domain code; add small helpers here only when broadly useful.
]]></content>
    </file>
    <file>
      <path>plotting/__init__.py</path>
      <content><![CDATA["""Generic plotting helpers for VDM experiments.

Usage examples:
    from common.plotting import PlotSpec, plot_line
    fig_path, (fig, ax) = plot_line(x, y, PlotSpec(domain="metriplectic", tag="KG-dispersion-v1", name="dispersion", xlabel="k [1/m]", ylabel="ω [rad/s]", title="KG dispersion"))

This package routes saves via common.io_paths so quarantine/approval is honored automatically (based on env policy).
"""

from .types import PlotSpec
from .helpers import plot_line, plot_scatter, plot_image, plot_heatmap, plot_multi_panel
]]></content>
    </file>
    <file>
      <path>plotting/core.py</path>
      <content><![CDATA[from __future__ import annotations
from pathlib import Path
from typing import Tuple, Dict, Any
import json
import math

import matplotlib.pyplot as plt
from matplotlib.figure import Figure
from matplotlib.axes import Axes

from common.io_paths import figure_path


def apply_style(style: str = "light") -> None:
    if style == "dark":
        plt.style.use("dark_background")
    else:
        plt.style.use("default")
    plt.rcParams.update({
        "figure.dpi": 100,
        "savefig.dpi": 160,
        "axes.grid": True,
        "grid.alpha": 0.3,
        "font.size": 11,
    })


def get_fig_ax(size=(6.4, 4.0)) -> Tuple[Figure, Axes]:
    fig, ax = plt.subplots(figsize=size)
    return fig, ax


def sanitize_for_log(arr):
    # Avoid log(<=0)
    import numpy as np
    a = np.asarray(arr)
    eps = 1e-30
    return np.where(a <= 0, eps, a)


def save_figure(domain: str, slug: str, fig: Figure, *, failed: bool) -> Path:
    path = figure_path(domain, slug, failed=failed)
    fig.savefig(path, bbox_inches="tight")
    return path


def write_sidecar(path: Path, spec: Dict[str, Any], stats: Dict[str, Any]) -> None:
    sidecar = path.with_suffix(".json")
    payload = {"plot": spec, "stats": stats}
    sidecar.write_text(json.dumps(payload, indent=2), encoding="utf-8")
]]></content>
    </file>
    <file>
      <path>plotting/helpers.py</path>
      <content><![CDATA[from __future__ import annotations
from typing import Sequence, Callable, Optional, Tuple, Dict, Any, List
import numpy as np
import matplotlib.pyplot as plt

from .types import PlotSpec
from .core import apply_style, get_fig_ax, save_figure, write_sidecar, sanitize_for_log
from common.io_paths import build_slug


def _slug(spec: PlotSpec) -> str:
    return build_slug(spec.name, spec.tag)


def _stats_xy(x: np.ndarray, y: np.ndarray) -> Dict[str, Any]:
    return {
        "x": {"shape": list(x.shape), "min": float(np.nanmin(x)), "max": float(np.nanmax(x))},
        "y": {"shape": list(y.shape), "min": float(np.nanmin(y)), "max": float(np.nanmax(y))},
    }


def plot_line(x: Sequence[float], y: Sequence[float], spec: PlotSpec, *, failed: bool = False):
    apply_style(spec.style)
    fig, ax = get_fig_ax(spec.size)

    x_arr = np.asarray(x)
    y_arr = np.asarray(y)

    if spec.logx:
        x_arr = sanitize_for_log(x_arr)
        ax.set_xscale("log")
    if spec.logy:
        y_arr = sanitize_for_log(y_arr)
        ax.set_yscale("log")

    ax.plot(x_arr, y_arr, label=spec.title or spec.name)

    if spec.title:
        ax.set_title(spec.title)
    if spec.xlabel:
        ax.set_xlabel(spec.xlabel)
    if spec.ylabel:
        ax.set_ylabel(spec.ylabel)
    if spec.legend:
        ax.legend()

    if spec.tight:
        fig.tight_layout()

    path = save_figure(spec.domain, _slug(spec), fig, failed=failed)
    write_sidecar(path, spec.__dict__, _stats_xy(x_arr, y_arr))
    return path, (fig, ax)


def plot_scatter(x: Sequence[float], y: Sequence[float], spec: PlotSpec, *, failed: bool = False):
    apply_style(spec.style)
    fig, ax = get_fig_ax(spec.size)

    x_arr = np.asarray(x)
    y_arr = np.asarray(y)
    ax.scatter(x_arr, y_arr, s=10, alpha=0.8)

    if spec.title:
        ax.set_title(spec.title)
    if spec.xlabel:
        ax.set_xlabel(spec.xlabel)
    if spec.ylabel:
        ax.set_ylabel(spec.ylabel)

    if spec.tight:
        fig.tight_layout()

    path = save_figure(spec.domain, _slug(spec), fig, failed=failed)
    write_sidecar(path, spec.__dict__, _stats_xy(x_arr, y_arr))
    return path, (fig, ax)


essential_cmaps = {"viridis", "plasma", "inferno", "magma", "cividis"}


def plot_image(img2d: np.ndarray, spec: PlotSpec, *, failed: bool = False):
    apply_style(spec.style)
    fig, ax = get_fig_ax(spec.size)

    im = ax.imshow(img2d, cmap=spec.cmap, origin="lower", aspect="auto")
    plt.colorbar(im, ax=ax)

    if spec.title:
        ax.set_title(spec.title)
    if spec.xlabel:
        ax.set_xlabel(spec.xlabel)
    if spec.ylabel:
        ax.set_ylabel(spec.ylabel)

    if spec.tight:
        fig.tight_layout()

    path = save_figure(spec.domain, _slug(spec), fig, failed=failed)
    stats = {"img": {"shape": list(img2d.shape), "min": float(np.nanmin(img2d)), "max": float(np.nanmax(img2d))}}
    write_sidecar(path, spec.__dict__, stats)
    return path, (fig, ax)


def plot_heatmap(X: np.ndarray, Y: np.ndarray, Z: np.ndarray, spec: PlotSpec, *, failed: bool = False):
    apply_style(spec.style)
    fig, ax = get_fig_ax(spec.size)

    pc = ax.pcolormesh(X, Y, Z, cmap=spec.cmap, shading="auto")
    plt.colorbar(pc, ax=ax)

    if spec.title:
        ax.set_title(spec.title)
    if spec.xlabel:
        ax.set_xlabel(spec.xlabel)
    if spec.ylabel:
        ax.set_ylabel(spec.ylabel)

    if spec.tight:
        fig.tight_layout()

    path = save_figure(spec.domain, _slug(spec), fig, failed=failed)
    stats = {
        "X": {"shape": list(X.shape), "min": float(np.nanmin(X)), "max": float(np.nanmax(X))},
        "Y": {"shape": list(Y.shape), "min": float(np.nanmin(Y)), "max": float(np.nanmax(Y))},
        "Z": {"shape": list(Z.shape), "min": float(np.nanmin(Z)), "max": float(np.nanmax(Z))},
    }
    write_sidecar(path, spec.__dict__, stats)
    return path, (fig, ax)


def plot_multi_panel(panels: List[Callable[[plt.Axes], None]], spec: PlotSpec, *, failed: bool = False, ncols: int = 2):
    apply_style(spec.style)
    import math
    n = len(panels)
    nrows = math.ceil(n / ncols)

    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=spec.size)
    axes = np.array(axes).reshape(-1)

    for i, panel in enumerate(panels):
        ax = axes[i]
        panel(ax)

    # Hide any unused axes
    for j in range(i + 1, len(axes)):
        axes[j].set_visible(False)

    if spec.title:
        fig.suptitle(spec.title)

    if spec.tight:
        fig.tight_layout()

    path = save_figure(spec.domain, _slug(spec), fig, failed=failed)
    write_sidecar(path, spec.__dict__, {"panels": n})
    return path, (fig, axes)
]]></content>
    </file>
    <file>
      <path>plotting/primitives.py</path>
      <content><![CDATA[from __future__ import annotations

from typing import Any, Dict, Iterable, List, Optional, Sequence, Tuple
import numpy as np
import matplotlib.pyplot as plt

from .core import get_fig_ax


# Small utilities

def format_float(x: float, prec: int = 6) -> str:
    try:
        return f"{float(x):.{prec}g}"
    except Exception:
        return str(x)


# Generic figure: monotonicity with dual-axis delta overlay

def plot_monotonicity_dual_axis(
    *,
    t: Sequence[float],
    y: Sequence[float],
    dy: Sequence[float],
    checkpoints_t: Optional[Sequence[float]] = None,
    window: Optional[Tuple[float, float]] = None,
    title: str = "Monotonicity check",
    xlabel: str = "t",
    ylabel_left: str = "y(t)",
    ylabel_right: str = "Δy(t)",
    legend_labels: Tuple[str, str, str] = ("y(t)", "Δy(t)", "window"),
    callout_lines: Optional[Sequence[str]] = None,
    figsize: Tuple[float, float] = (8, 4.5),
) -> Tuple[plt.Figure, plt.Axes]:
    fig, ax = get_fig_ax(size=figsize)
    t = np.asarray(t, dtype=float)
    y = np.asarray(y, dtype=float)
    dy = np.asarray(dy, dtype=float)

    ax.plot(t, y, color="#222222", lw=1.8, label=legend_labels[0])
    ax.set_xlabel(xlabel)
    ax.set_ylabel(ylabel_left)
    ax.grid(True, alpha=0.3)

    axr = ax.twinx()
    axr.plot(t, dy, color="#1f77b4", alpha=0.35, lw=1.0, label=legend_labels[1])
    axr.axhline(0.0, color="#1f77b4", alpha=0.25, lw=0.8)
    axr.set_ylabel(ylabel_right)

    if checkpoints_t is not None:
        for tc in checkpoints_t:
            ax.axvline(float(tc), color="#666666", alpha=0.25, lw=0.6)

    if window is not None:
        t0, t1 = window
        ax.axvspan(float(t0), float(t1), color="#ff7f0e", alpha=0.12, label=legend_labels[2])

    if callout_lines:
        ax.text(
            0.98,
            0.98,
            "\n".join(callout_lines),
            transform=ax.transAxes,
            ha="right",
            va="top",
            fontsize=9,
            bbox=dict(boxstyle="round,pad=0.4", fc="white", ec="#cccccc", alpha=0.9),
        )

    lines_left, labels_left = ax.get_legend_handles_labels()
    lines_right, labels_right = axr.get_legend_handles_labels()
    ax.legend(lines_left + lines_right, labels_left + labels_right, loc="lower left", fontsize=9)

    ax.set_title(title)
    return fig, ax


# Generic 2x2 dashboard assembler and panel primitives

def assemble_dashboard_2x2(figsize: Tuple[float, float] = (10, 7.5)) -> Tuple[plt.Figure, np.ndarray]:
    fig, axs = plt.subplots(2, 2, figsize=figsize, constrained_layout=True)
    return fig, axs


def panel_scatter_with_line(
    ax: plt.Axes,
    *,
    x: Sequence[float],
    y: Sequence[float],
    line_x: Optional[Sequence[float]] = None,
    line_y: Optional[Sequence[float]] = None,
    xlabel: str = "x",
    ylabel: str = "y",
    title: Optional[str] = None,
    subtitle: Optional[str] = None,
    residual_stats: Optional[Dict[str, Any]] = None,
):
    x = np.asarray(x, dtype=float)
    y = np.asarray(y, dtype=float)
    ax.scatter(x, y, s=8, alpha=0.5, label="data")
    if line_x is not None and line_y is not None:
        ax.plot(np.asarray(line_x, dtype=float), np.asarray(line_y, dtype=float), color="#d62728", lw=1.2, label="fit")
    ax.set_xlabel(xlabel)
    ax.set_ylabel(ylabel)
    ax.grid(True, alpha=0.3)
    if title:
        tt = title
        if subtitle:
            tt += f"\n{subtitle}"
        ax.set_title(tt)
    if residual_stats:
        ax.text(
            0.02,
            0.98,
            "Res: " + ", ".join([f"{k}={format_float(v)}" for k, v in residual_stats.items()]),
            transform=ax.transAxes,
            ha="left",
            va="top",
            fontsize=8,
            bbox=dict(boxstyle="round,pad=0.2", fc="white", ec="#dddddd", alpha=0.9),
        )
    ax.legend(fontsize=9)


def panel_compare_series(
    ax: plt.Axes,
    *,
    t: Sequence[float],
    series: Sequence[Sequence[float]],
    labels: Sequence[str],
    ylabel: str = "value",
    title: Optional[str] = None,
    badge_text: Optional[str] = None,
):
    t = np.asarray(t, dtype=float)
    for s, label in zip(series, labels):
        ax.plot(t, np.asarray(s, dtype=float), lw=1.2, label=label)
    ax.grid(True, alpha=0.3)
    ax.set_xlabel("t")
    ax.set_ylabel(ylabel)
    if title:
        ax.set_title(title)
    ax.legend(fontsize=9)
    if badge_text:
        ax.text(
            0.98,
            0.05,
            badge_text,
            transform=ax.transAxes,
            ha="right",
            va="bottom",
            fontsize=9,
            bbox=dict(boxstyle="round,pad=0.25", fc="white", ec="#cccccc", alpha=0.95),
        )


def panel_timeline_passfail(
    ax: plt.Axes,
    *,
    times: Sequence[float],
    ok: Sequence[bool],
    title: Optional[str] = None,
    xlabel: str = "t (checkpoints)",
):
    times = np.asarray(times, dtype=float)
    ok = np.asarray(ok, dtype=bool)
    for tc, is_ok in zip(times, ok):
        color = "#2ca02c" if is_ok else "#d62728"
        ax.plot([tc, tc], [0, 1], color=color, lw=1.8)
    ax.set_ylim(0, 1)
    ax.set_yticks([])
    ax.set_xlabel(xlabel)
    if title:
        ax.set_title(title)
    ax.grid(True, axis="x", alpha=0.3)


def panel_kv_text(
    ax: plt.Axes,
    *,
    title: str,
    lines: Sequence[str],
):
    ax.axis("off")
    ax.text(0.0, 1.0, title + "\n" + "\n".join(lines), ha="left", va="top", fontsize=9)
]]></content>
    </file>
    <file>
      <path>plotting/types.py</path>
      <content><![CDATA[from __future__ import annotations
from dataclasses import dataclass, field
from typing import Optional, Literal, Tuple


@dataclass
class PlotSpec:
    domain: str
    name: str
    tag: Optional[str] = None
    title: Optional[str] = None
    xlabel: Optional[str] = None
    ylabel: Optional[str] = None
    cmap: str = "viridis"
    style: Literal["light", "dark"] = "light"
    logx: bool = False
    logy: bool = False
    dpi: int = 160
    size: Tuple[float, float] = (6.4, 4.0)
    legend: bool = True
    tight: bool = True

    # Arbitrary metadata (serialized to sidecar)
    meta: dict = field(default_factory=dict)
]]></content>
    </file>
    <file>
      <path>vdm_equations.py</path>
      <content><![CDATA["""
VDM Canonical Equations - runtime evaluators with traceable references

Purpose

- Provide a single import surface for core equations referenced in Derivation/EQUATIONS.md.
- Keep numerical helpers close to the documented canon with explicit parameterization and audit trail (VDM-E-### references).

Design notes

- Pure module: zero side effects and no I/O; safe to import in tests and runners.
- Explicit parameters: pass everything needed; defaults mirror common mappings only when unambiguous.
- References: inline docstrings point to entries in Derivation/EQUATIONS.md for accountability.

Implemented (key entries)

- Potential V and derivatives V', V'' (VDM-E-012, VDM-E-058)
- RD reaction f(φ) and logistic exact step (VDM-E-015, VDM-E-025)
- RD dispersion σ(k), discrete σ_d(m), and KPP speed c_front (VDM-E-017, -034, -035, -018)
- Discrete↔Continuum parameter maps (VDM-E-029, -050)
- Klein-Gordon wave speed c^2 from lattice parameters (VDM-E-014, -041, -077)
- Stabilized vacuum v_λ and effective mass m_eff^2 (VDM-E-059, -060)

License: Copyright © 2025 Justin K. Lietz, Neuroca, Inc. All Rights Reserved.
"""
from __future__ import annotations

from dataclasses import dataclass
from typing import Tuple
import numpy as np


# ------------------------------
# Parameters (lightweight typed bags)
# ------------------------------

@dataclass(frozen=True)
class PotentialParams:
    """Parameters for stabilized potential.

    V(φ) = (α/3) φ^3 - (r/2) φ^2 + (λ/4) φ^4, with r = α - β (VDM-E-012, -058)
    """
    alpha: float
    beta: float
    lam: float = 0.0

    @property
    def r(self) -> float:
        return self.alpha - self.beta


@dataclass(frozen=True)
class RDParams:
    """Reaction-diffusion continuum parameters (VDM-E-015, -028, -050)."""
    D: float
    r: float
    u: float
    lam: float = 0.0


@dataclass(frozen=True)
class LatticeParams:
    """Discrete lattice parameters for mapping (VDM-E-011, -029, -041)."""
    J: float
    a: float
    gamma: float | None = None  # optional damping for RD map (VDM-E-044, -050)


# ------------------------------
# Potential and derivatives (VDM-E-012, -058)
# ------------------------------

def V(phi: np.ndarray | float, p: PotentialParams) -> np.ndarray | float:
    """Stabilized potential V(φ).

    V(φ) = (α/3) φ^3 - (r/2) φ^2 + (λ/4) φ^4, r = α - β (VDM-E-012, -058)
    """
    r = p.r
    return (p.alpha / 3.0) * np.asarray(phi) ** 3 - 0.5 * r * np.asarray(phi) ** 2 + (p.lam / 4.0) * np.asarray(phi) ** 4


def Vp(phi: np.ndarray | float, p: PotentialParams) -> np.ndarray | float:
    """V'(φ) = α φ^2 - r φ + λ φ^3 (VDM-E-012)."""
    r = p.r
    phi = np.asarray(phi)
    return p.alpha * phi ** 2 - r * phi + p.lam * phi ** 3


def Vpp(phi: np.ndarray | float, p: PotentialParams) -> np.ndarray | float:
    """V''(φ) = 2α φ - r + 3λ φ^2 (VDM-E-012)."""
    r = p.r
    phi = np.asarray(phi)
    return 2.0 * p.alpha * phi - r + 3.0 * p.lam * phi ** 2


# ------------------------------
# RD reaction term and exact step (VDM-E-015, -028, -025)
# ------------------------------

def rd_reaction(phi: np.ndarray | float, r: float, u: float, lam: float = 0.0) -> np.ndarray | float:
    """Reaction term f(φ) = r φ − u φ² − λ φ³ (VDM-E-015, -028).

    Interpretation: logistic (quadratic) growth with optional cubic saturation.
    Stability/scale: Signs and magnitudes of (r, u, λ) determine fixed points and stiffness.
    """
    phi = np.asarray(phi)
    return r * phi - u * phi ** 2 - lam * phi ** 3


def logistic_exact_step(W: np.ndarray | float, dt: float, r: float, u: float) -> np.ndarray | float:
    """Exact step for dW/dt = r W − u W² over Δt (VDM-E-025).

    Useful for stiff regimes and reference solutions: preserves positivity for W≥0 with r,u≥0.
    """
    W = np.asarray(W)
    exp_rt = np.exp(r * dt)
    return (r * W * exp_rt) / (u * W * (exp_rt - 1.0) + r)


# ------------------------------
# Dispersion and front speed (VDM-E-017, -034, -035, -018)
# ------------------------------

def dispersion_continuum(k: np.ndarray | float, D: float, r: float) -> np.ndarray | float:
    """Continuum dispersion relation σ(k) = r − D k² (VDM-E-017, -035)."""
    k = np.asarray(k)
    return r - D * k ** 2


def dispersion_discrete(m: np.ndarray | int, N: int, L: float, D: float, r: float) -> np.ndarray | float:
    """Discrete dispersion σ_d(m) = r − (4D/Δx²) sin²(π m / N), Δx = L/N (VDM-E-034)."""
    m = np.asarray(m)
    dx = L / float(N)
    return r - (4.0 * D / (dx ** 2)) * np.sin(np.pi * m / float(N)) ** 2


def kpp_front_speed(D: float, r: float) -> float:
    """KPP front speed c_front = 2 √(D r) (VDM-E-018, -033).

    Preconditions: D ≥ 0, r ≥ 0. Raises ValueError otherwise.
    """
    if D < 0 or r < 0:
        raise ValueError("KPP front speed requires D>=0 and r>=0")
    return 2.0 * float(np.sqrt(D * r))


# ------------------------------
# Discrete ↔ Continuum mappings (VDM-E-029, -050)
# ------------------------------

def rd_from_lattice(p: PotentialParams, lat: LatticeParams) -> RDParams:
    """Map discrete lattice params to RD params (VDM-E-050).

    D = 2 J a^2 / γ,  f(φ) = (1/γ) [ (α-β) φ - α φ^2 - λ φ^3 ].
    If γ is None, fall back to site Laplacian map D = J a^2 and raw r,u,λ (VDM-E-029).
    """
    if lat.gamma is not None:
        D = 2.0 * lat.J * (lat.a ** 2) / float(lat.gamma)
        r = (p.alpha - p.beta) / float(lat.gamma)
        u = p.alpha / float(lat.gamma)
        lam = p.lam / float(lat.gamma)
        return RDParams(D=D, r=r, u=u, lam=lam)
    # No damping provided: site-Laplacian mapping
    D = lat.J * (lat.a ** 2)
    return RDParams(D=D, r=p.alpha - p.beta, u=p.alpha, lam=p.lam)


def kg_c2_from_lattice(J: float, a: float, convention: str = "per-site") -> float:
    """Wave speed squared c² from lattice coupling (VDM-E-014, -041, -077).

    - convention="per-site": c² = 2 J a² (matches VDM-E-014/077)
    - convention="per-edge": c² = κ a² with κ = 2J (equivalent)
    """
    if convention == "per-site":
        return 2.0 * J * (a ** 2)
    elif convention == "per-edge":
        kappa = 2.0 * J
        return kappa * (a ** 2)
    else:
        raise ValueError("convention must be 'per-site' or 'per-edge'")


# ------------------------------
# Stabilized vacuum and effective mass (VDM-E-059, -060)
# ------------------------------

def stabilized_vacuum(p: PotentialParams) -> float:
    """Stabilized vacuum v_λ (VDM-E-059).

    v_λ = [-α + sqrt(α² + 4 λ (α − β))] / (2 λ), for λ > 0.
    If λ = 0, use the small-λ limit φ* = r/α (positive branch) when α > 0.
    """
    if p.lam > 0:
        disc = p.alpha ** 2 + 4.0 * p.lam * (p.alpha - p.beta)
        return float((-p.alpha + np.sqrt(disc)) / (2.0 * p.lam))
    # λ == 0: use small-λ limit φ* = r/α when α>0
    if p.alpha <= 0:
        raise ValueError("alpha must be > 0 for λ=0 vacuum selection")
    return float((p.alpha - p.beta) / p.alpha)


def effective_mass_squared(p: PotentialParams) -> float:
    """Effective mass squared m_eff² = V''(v_λ) (VDM-E-060).

    m_eff² = 2 α v_λ − (α − β) + 3 λ v_λ² ≈ (α − β) + O(λ).
    """
    v = stabilized_vacuum(p)
    return float(2.0 * p.alpha * v - (p.alpha - p.beta) + 3.0 * p.lam * (v ** 2))


# ------------------------------
# Utility: wavenumber helpers
# ------------------------------

def k_from_mode(m: np.ndarray | int, L: float) -> np.ndarray | float:
    """k = 2π m / L."""
    m = np.asarray(m)
    return 2.0 * np.pi * m / float(L)


def mode_from_k(k: np.ndarray | float, L: float) -> np.ndarray | float:
    """Inverse of k_from_mode for integer m ≈ round(k L / 2π)."""
    k = np.asarray(k)
    return np.rint(k * float(L) / (2.0 * np.pi))


# ------------------------------
# Sanity self-check (optional quick regression without pytest)
# ------------------------------

def _self_check() -> Tuple[bool, str]:
    """Run a tiny set of numerical identities; returns (ok, message)."""
    p = PotentialParams(alpha=0.25, beta=0.10, lam=0.0)
    rd = RDParams(D=1.0, r=0.25 - 0.10, u=0.25, lam=0.0)

    # Front speed identity
    c = kpp_front_speed(rd.D, rd.r)
    if not np.isclose(c, 2.0 * np.sqrt(rd.D * rd.r)):
        return False, "KPP speed mismatch"

    # Dispersion consistency near k=0
    k = 1e-3
    sig = dispersion_continuum(k, rd.D, rd.r)
    if not np.isclose(sig, rd.r - rd.D * k * k):
        return False, "Dispersion formula mismatch"

    # KG mapping consistency
    c2 = kg_c2_from_lattice(J=0.5, a=1.0, convention="per-site")
    if not np.isclose(c2, 1.0):
        return False, "KG c^2 per-site mapping mismatch"

    # Logistic exact step reduces to Euler for small dt
    W0 = 0.1
    dt = 1e-6
    W1_exact = logistic_exact_step(W0, dt, rd.r, rd.u)
    W1_euler = W0 + dt * rd_reaction(W0, rd.r, rd.u, rd.lam)
    if not np.isclose(W1_exact, W1_euler, rtol=0, atol=1e-10):
        return False, "Logistic exact small-dt limit mismatch"

    return True, "OK"


if __name__ == "__main__":  # manual smoke
    ok, msg = _self_check()
    print("vdm_equations self-check:", msg)
    raise SystemExit(0 if ok else 1)
]]></content>
    </file>
  </files>
</fum_code_report>
