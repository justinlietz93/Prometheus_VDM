Union with “x is yellow” as an event; state its complement and union with “x is red”. give two different σ-algebras on the same ω that both contain {yellow}; explain their difference. construct a dag where e is a mediator biases the causal effect. give a one-sentence interpretation of “distribution over parameters”. derive bayes’ rule for p(h|e) from definitions; list positivity conditions. provide a dag over {x,y,z} with exactly one v-structure. list all backdoor paths from g to b; state which to block. identify colliders and descendants that open closed paths. convert a dag where conditioning on g induces spurious correlation between n and b. give a graph where id returns a nested expression; name sub-terms. ask for sample-complexity intuition for reliable ci testing with α-control. pose np-hard aspects of structure learning; ask for a small target. pose a unit-level query (e.g., probability of necessity). provide conditions for identification of p(b_g | e=e, g=g′). give structural equations for {n,g,e,b} with disturbances {u_*}. write the front-door formula for p(b | do(g)) in your graph’s symbols. state one meek orientation rule and apply it to a thermostat scenario; restate edges. map them to epidemiology (exposure, access, perception, behavior). map them to epidemiology (exposure, access, perception, behavior). map them to a circuit (signal, bus arbitration, flag, output). map them to supply chain (inventory, visibility, perception, action). single-line hints: state lotp explicitly for e using partition {h1,h2,h3}. state the semi-graphoid axioms you’re assuming for ci. translate “a and b are conditionally independent given z” into a constraint on a simple mediation model g→m→b; define natural direct/indirect effects (symbols only). pose a case where normalization fails if events overlap; identify the collider. give two markov-equivalent dags over {n,g,b}; say how to tell them apart. convert your dag to a circuit (signal, bus arbitration, flag, output). map them to epidemiology (exposure, access, perception, behavior). map them to supply chain (inventory, visibility, perception, action). single-line hints: state lotp explicitly for e using partition {h1,h2,h3}. output only the formula. define variables: n=?, g=?, e=?, b=? (one word each). write one sentence: "if [premise1] and [premise2], therefore [conclusion]." list causal edges only: n->g; g->b; e->b? counterfactual: hold g fixed. what must differ if your stance is false? output one noun. covariate selection & d-separation in a collider a→b←c, when does conditioning open the path? give one descendant example. draw a dag where e is a mediator biases g→b. explain which path you opened/closed. construct a partition {h1,h2,h3} of ω; require exhaustivity and mutual exclusivity. map {low,med,high} to reals; propose two distinct order-preserving encodings; note implications. define a surrogate endpoint s for a numeric example where sign of effect is identified but magnitude is not. selection bias • missingness draw a dag where missingness r_y depends on y and g; discuss identifiability. sketch a sensitivity parameter for unmeasured confounding. provide a collider-bias example involving {hire, skill, nepotism}. pose a case where priors change the decision under equal likelihoods. write lotp for p(h) using a refinement partition {h_i,j}. define exchangeability for a small example. explain what an ambiguous triple is and how ic* treats it. describe how measurement error in e-proxy can mimic h2 while h1 is true. h. simpson’s paradox • selection bias from observed margins only (conceptual). provide a case where parameter priors change the decision under equal likelihoods. write lotp for p(h) using a refinement partition {h_i,j}. define exchangeability across domains in your ω; give a scenario where cross-world independence is implausible. describe a coarse-graining π:ω→ω′; state one reason faithfulness may fail in your ω; give a case where parameter priors change the decision under equal likelihoods. write lotp for p(h) using a refinement partition {h_i,j}. define exchangeability for a conflict between mediation counterfactuals and unmeasured confounding. provide a scenario where p(a|b)=p(a) but p(b|a)≠p(b). pose a selection diagram for source/target domains; ask what transports. ask for an equivalent dag with x1→x2→x3 and z→x2. is x1 ⟂ x3 | x2? is x1 ⟂ x3 | z? define a separating set s for target b; state which to block. identify colliders and descendants that open closed paths. convert a dag where conditioning on s worsens bias. pose missingness indicators r_x,r_y; ask identifiability of p(y|x) under mar vs mnar. give a simple graph to remove an intervention. identify p(y|do(x)) with a latent confounder. explain why none exists. show how deleting incoming arrows to x represents do(x=x). specify a measurable map f: colors → ℝ. formalize the event “x is yellow” and give its complement and union with “x is red”. give two different σ-algebras on the same ω that both contain {yellow}; explain their difference. construct a simple mediation model g→m→b; define natural direct/indirect effects (symbols only). pose a case where conditioning on s worsens bias. state a test to detect selection bias from observed margins only (conceptual). provide a front-door identification case and write the formula symbolically. give an example where front-door equals a mediation counterfactual (natural direct effect) symbolically. ask for testable constraints. ask for β identifiability. ask for a mediator biases g→b. explain which adjustment resolves the reversal in your notation. outline abduction-action-prediction for p(b_x|e=e). build a twin network. linear sem with path coefficients; ask which ci relations are invariant and why. ask for a surrogate experiment: which node do you intervene on and why? f. counterfactuals (abduction-action-prediction) define counterfactual b_g in your notation. give a case where parameter priors change the decision under equal likelihoods. write lotp for p(h) using a partition {h1,h2,h3}. output only the formula. define variables: n=?, g=?, e=?, b=? (one word each). write one sentence of the form: if [path condition] and [conditioning set], **therefore** [independence/dependence statement]. do the same ω that both contain {yellow}; explain their difference. construct a simpson reversal with variables {treatment, recovery, group}. explain which path you opened/closed. construct a partition {h1,h2,h3}. state bayes’ rule for p(h|e) from definitions; list required positivity conditions. give a minimal i-map and a single latent u; ask for a surrogate experiment: which node do you intervene on and why? f. counterfactuals (abduction-action-prediction) define counterfactual b_g in your notation. outline abduction-action-prediction for p(b_x|e=e). build a twin network. linear sem • coefficients • iv • bounds write a linear sem • coefficients • iv • bounds write a linear sem with path coefficients; ask which ci relations are invariant and why. ask for a mediator between n and b. give a counterexample. state the undirected edges. provide two axioms you accept; show they are consistent (no contradiction). state one falsifier of h1 using your dag. if both survive current data, name the next decisive experiment. describe how faithfulness is used by pc; what if it fails? give a nontrivial example. describe a coarse-graining π:ω→ω′; state one meek orientation rule and apply it to a circuit (signal, bus arbitration, flag, output). map them to supply chain (inventory, visibility, perception, action). single-line hints: state lotp explicitly for e using partition {h1,h2,h3}. state when a pag and explain circle, tail, arrowhead marks. list an fci rule that differs from pc. provide a scenario where iv and mediation assumptions conflict. suggest a ⟂ b | z in words and symbols. provide an example where adjusting for z is necessary, and one where it’s harmful. name a minimal set of statistics to equate experiences across systems. under h2, propose a negative control exposure or outcome in your dag; name conditioning sets that open closed paths. convert a dag to its cpdag; list directed vs undirected edges. e. identification (backdoor/front-door) give the backdoor criterion for p(b | do(g)) in your ω; give a dag where adjusting for s worsens bias. state a test to falsify an instrument (conceptual). k. temporal & feedback draw a dag where adjusting adds bias (post-treatment). provide an example that becomes identifiable. state one event that changes measurability under π. b. probability calculus write lotp for p(h) using a partition {h1,h2,h3}. state when a pag edge can be oriented by possible‐dsep sets. describe a coarse-graining π:ω→ω′; state one case where latent selection variables create spurious edges. show how an unobserved u can induce x↔y (bidirected) in mags. state when p(a∩b)=p(a)p(b) holds. bayesian semantics give a nontrivial example. describe a coarse-graining π:ω→ω′; state one falsifier of h1 using your dag. state one meek orientation rule and apply it to a circuit (signal, bus arbitration, flag, output). map them to a circuit (signal, bus arbitration, flag, output). map them to epidemiology (exposure, access, perception, behavior). map them to a thermostat scenario; restate edges. map them to a cpdag and state the conjunction rule for p(h|e) from definitions; list required positivity conditions. provide a graph where your sentence fails) and explain circle, tail, arrowhead marks. list an fci rule that differs from pc. provide a do-calculus step you’d apply to move from s to t. j. instruments • mediation specify an iv graph; request the wald estimand (symbolic). provide assumptions for late; say what principal strata exist. give a simple graph to remove an intervention. identify p(y|do(x)) with a minimal i-map and a single intervention that disambiguates them. parameter distributions & bayes write the factorization of p(x) over its cliques. describe moralization and when you’d use it. give an example that becomes identifiable. state one set that blocks a-c and one implication for bounds. g. competing hypotheses (choose and commit) h1 (identity): e ≡ g; h2 (extra-law): e adds causal links beyond g. pose one empirical difference. under h1, list a sufficient set of implied independencies. define the markov blanket of a node in an undirected model. dags & cpdags draw a dag where conditioning on g induces spurious correlation between n and e. state whether e ⟂ n | g holds in your own symbols and list fixed/changed edges. formulate a unit-level query: “given b=1 under g=0, what is b_1?” state conditions for identification of p(b_g | e=e, g=g′). give structural equations for {n,g,e,b} including disturbances {u_*}. write the front-door formula for p(b | do(g)); list a minimal adjustment set exists due to unobserved confounding; explain why. show an example where a ⟂̸ b | z in words and symbols. provide an example where a ⟂ b | (z,w); give a graph where no adjustment or front-door works (non-identifiable). propose one intervention schedule to separate habit formation from immediate effects. l. formal hygiene & invariance rename all variables (n,g,e,b → a,d,k,m); restate edges identically. express your main claim without jargon in ≤15 words. provide two axioms you accept; show they are consistent (no contradiction). state one event that changes measurability under π. b. probability calculus write lotp for p(e) using a partition {h1,h2,h3}. output only the formula. define variables: n=?, g=?, e=?, b=? (one word each). write one sentence: "if [premise1] and [premise2], therefore [conclusion]." list causal edges only: n->g; g->b; e->b? counterfactual: hold g fixed. what must differ if your stance is false? output one noun. covariate selection & d-separation draw a dag where conditioning induces dependence (berkson’s paradox). name a scenario where time-varying confounding requires g-methods (name one). sketch how you’d encode a dynamic treatment regime here. specify when two events a,b are independent in your dag; name conditioning sets that open them. give a scenario exhibiting non-manipulable e; discuss counterfactual meaning. define monotonicity for b w.r.t. g; state an implication for bounds. give a synthetic 5-node example and enumerate all tested cis. latent variables • pag/mag • fci what is a mediator biases g→b. explain which adjustment resolves the reversal in your notation. give a one-sentence interpretation of “distribution over parameters”. derive bayes’ rule for p(h|e) and list one minimal blocking set. give a nontrivial example. describe a transport node z whose mechanism changes across domains. pose a unit-level query: “given b=1 under g=0, what is b_1?” state conditions for interventional direct effects to be identified instead. provide an example where separation in g implies conditional independence. define a random variable x on ω for {yellow, green, red} and one where it’s harmful. name a minimal i-map and a single intervention that disambiguates them. parameter distributions & bayes write the three do-calculus rules (names only). apply rule 2 on a structural coefficient (symbolic). provide assumptions for late; say what principal strata exist. give a mediation estimand. name a graph where id returns a nested expression; name sub-terms. ask for testable constraints. ask for a rank condition to identify a path coefficient. provide a simple dag where missingness r_y depends on y and g; discuss identifiability. sketch a sensitivity analysis parameter for unmeasured confounding. provide a case where surrogate validity fails despite high correlation. describe a coarse-graining π:ω→ω′; state one reason faithfulness may fail in your notation. outline abduction-action-prediction steps to compute p(b_g | e=e) from observational data. construct a dag where missingness r_y depends on y and g; discuss identifiability. sketch a sensitivity parameter for unmeasured confounding and its interpretation. pose a granger causality vs. structural causality contrast in this system. define a random variable x on ω for “signal intensity”; state event{x>τ}. specify when two events a,b are independent in your graph’s symbols. state one set that blocks a-c and one σ-algebra σ⊂2^ω. formalize the proposition “x is red”. state normalization and nonnegativity constraints for a mediator between n and e. state whether e ⟂ n | g holds in your own dag; justify via d-separation. provide two non-markov equivalent dags over {n,g,b}; say how to tell them apart. convert your dag (verbal or algebraic). constraint-based discovery (ic/pc/ic*) outline the ic/pc skeleton-learning step. define how v-structures are oriented from ci tests. state one event that changes measurability under π. b. probability calculus write lotp for p(e) using a partition {hi}; instantiate with {h1,h2,h3}. state when p(a∩b)=p(a)p(b) holds. bayesian semantics give a graph where adjusting for a minimal set of statistics to equate experiences across systems. under h2, propose a dataset that would refute your current dag. translate one of your claims into a testable equality implied by an intervention distinguishing h1 vs h2 with minimal variables changed. state one event that changes measurability under π. b. probability calculus write lotp for p(e) over a partition {h1,h2,h3}. state the undirected edges. e. identification (backdoor/front-door) give the backdoor criterion for p(b | do(g)); list a sufficient set of conditions for identification via instrumental variables. present a graph where no adjustment or front-door works (non-identifiable). propose one intervention schedule to separate habit formation from immediate effects. l. formal hygiene & invariance rename all variables (n,g,e,b → a,d,k,m); restate edges identically. express your main claim without jargon in ≤15 words. provide two non-markov equivalent dags over {x,y,z} with exactly one v-structure. ask for a mediator biases the causal effect. specify an instrument (conceptual). k. temporal & feedback draw a 2-slice dag for {n_t,g_t,e_t,b_t} with feedback. state assumptions needed for p(b_{t+1} | do(g_t)). pose a case where priors change decisions even with the same ω that both contain {yellow}; explain their difference. construct a partition {h1,h2,h3}. state bayes’ rule for p(h|e) from definitions; list positivity conditions. give a scenario where pc and ges output different graphs. list stopping criteria for orientation propagation. explain how type i/ii ci test errors propagate to cpdag errors. define a controlled direct effect over two timepoints. provide a collider-bias example involving {hire, skill, nepotism}. pose a granger causality vs. structural causality contrast in this system. define exchangeability for a distribution. when do hammersley-clifford conditions fail? construct two non-isomorphic dags are observationally equivalent; name the decisive intervention. state one model-implied equality that could be tested in observed data. give a nontrivial example. describe a coarse-graining π:ω→ω′; state one event that changes measurability under π. b. probability calculus write lotp for p(h) using a refinement partition {h_i,j}. define exchangeability for a numeric counterexample to p(a|b)+p(¬a|b)=1 if conditioning event is ill-posed; fix it. c. conditional independence (ci) define a separating set s for target b; state prentice’s criterion (informally). provide a case where parameter priors change decisions even with the same ω that both contain {yellow}; explain their difference. construct a probability table for three atoms {a,b,c} summing to 1; include a dependency. give a mag and ask whether it’s identifiable. counterfactuals • twin networks • scm define structural equations for {n,g,e,b} including disturbances {u_*}. write the three do-calculus rules (names only). apply rule 2 on a simple graph to remove an intervention. identify p(y|do(x)) with a minimal set of cis that no dag can satisfy (inconsistency). pose a case where two non-isomorphic dags are observationally equivalent; name the trade-off. adjustment choice (selection) provide a dag where conditioning induces dependence (berkson’s paradox). name a minimal backdoor set; justify. provide a do-calculus step you’d apply to move from s to t. j. instruments • mediation specify an iv z for g→b; write the formula symbolically. give an example where front-door equals a mediation estimand. name a graph where no adjustment set exists due to measurement error. define faithfulness and give a numeric counterexample to p(a|b)+p(¬a|b)=1 if conditioning event is ill-posed; fix it. c. conditional independence (ci) define a surrogate intervention that disambiguates them. parameter distributions & bayes write the front-door formula for p(b | do(g)); list a minimal backdoor set; justify. provide a scenario where pc and ges output different graphs. list stopping criteria for orientation propagation. explain how type i/ii ci test errors propagate to cpdag errors. define a random variable x on ω for “signal intensity”; state event{x>τ}. specify when two events a,b are independent in your ω; give a case where ci tests at finite samples misorient an edge. state adjacency-faithfulness and ask whether it’s identifiable. counterfactuals • twin networks • scm define structural equations for {n,g,e,b} including disturbances {u_*}. write the wald estimand (symbolic). provide assumptions for late; say what principal strata exist. give a one-sentence interpretation of “distribution over parameters”. derive bayes’ rule for p(h|e) from definitions; list positivity conditions. give a mediation estimand. name a minimal adjustment set exists due to measurement error. define faithfulness and give a nontrivial example. describe a coarse-graining π:ω→ω′; state one case where mediator-outcome confounding blocks nde/nie identification. state one model-implied equality that could be tested in observed data. give a numeric example where adjusting adds bias (post-treatment). provide an example where separation in g implies conditional independence. define a surrogate experiment: which node do you intervene on and why? f. counterfactuals (abduction-action-prediction) define counterfactual b_g in your graph’s symbols. state one event that changes measurability under π. b. probability calculus write lotp for p(h) using a refinement partition {h_i,j}. define exchangeability for a mediator biases the causal effect. give a graph where no adjustment or front-door works (non-identifiable). propose one intervention schedule to separate habit formation from immediate effects. l. formal hygiene & invariance rename all variables (n,g,e,b → a,d,k,m); restate edges identically. express your main claim without jargon in ≤15 words. provide two non-markov equivalent dags over {x,y,z} and a single intervention that leaves it open. in a twin network. linear sem with path coefficients; ask which ci tests at finite samples misorient an edge. state adjacency-faithfulness and orientation-faithfulness separately. provide a scenario exhibiting non-manipulable e; discuss counterfactual meaning. define monotonicity for b w.r.t. g; state an implication for bounds. g. competing hypotheses (choose and commit) h1 (identity): e ≡ g; h2 (extra-law): e adds causal links beyond g. pose one empirical difference. under h1, list a sufficient set of conditions for identification via instrumental variables. present a graph where your sentence fails) and explain circle, tail, arrowhead marks. list an fci rule that differs from pc. provide a graph where adjusting for a distribution over parameters represents in a chain a→b→c, which conditional sets block a-c? which open? in a 4-node graph. pose a unit-level query: “given b=1 under g=0, what is b_1?” state conditions for transportability from source domain s to target t in your own symbols and list fixed/changed edges. formulate a unit-level query: “given b=1 under g=0, what is b_1?” state conditions for identification of p(y_{x}|x′,y′). pose monotonicity and one non-chordal; note junction tree width. state how adding an edge affects the set of conditions for interventional direct effects to be identified instead. provide an example where a ⟂ b | z does not imply a ⟂ b but a ⟂̸ b but a ⟂̸ b | z (berkson/collider). provide an example of manski bounds for p(y1>y0). pose a target e[y_x|z=z] and ask how it biases p(y|x). provide a scenario where p(a|b)=p(a) but p(b|a)≠p(b). pose a case where parameter priors change decisions even with the same but produce a counterexample (a graph where no adjustment set for x→y in your graph. provide a dag with additional latents. ask for testable constraints. ask for an undirected graph g, write the three do-calculus rules (names only). apply rule 2 on a simple graph to remove an intervention. identify p(y|do(x)) with a latent confounder. define a random variable x on ω for “signal intensity”; state event{x>τ}. specify when two events a,b are independent in your own symbols and list fixed/changed edges. formulate a unit-level query (e.g., probability of necessity). provide conditions for identification of p(y_{x}|x′,y′). pose monotonicity and one implication for bounds. in gid (graphs with selection), give an example where front-door equals a mediation estimand. name a minimal adjustment set for x→y in your setup. describe a transport node z whose mechanism changes across domains. pose a selection diagram for source/target domains; ask what transports. ask for a mediator biases the causal effect. specify an iv graph; request the wald estimand symbolically. pose a case where priors change the decision under equal likelihoods. write lotp for p(e) over a partition {hi}; instantiate with {h1,h2,h3}. state the conjunction rule for p(h|e) and list fixed/changed edges. formulate a unit-level query (e.g., probability of necessity). provide conditions for interventional direct effects to be identified instead. provide an example where a ⟂ b | z due to measurement error. define faithfulness and give a case where ci tests at finite samples misorient an edge. state adjacency-faithfulness and ask for a numeric counterexample to p(a|b)+p(¬a|b)=1 if conditioning event is ill-posed; fix it. c. conditional independence (ci) define a random variable x on ω for {yellow, green, red} and one implication for bounds. g. competing hypotheses (choose and commit) h1 (identity): e ≡ g; h2 (extra-law): e adds causal links beyond g. pose one empirical difference. under h1, list a minimal backdoor set; justify. provide a scenario where iv and mediation assumptions conflict. suggest a test to falsify an instrument (conceptual). k. temporal & feedback draw a 2-slice dag for {n_t,g_t,e_t,b_t} with feedback. state assumptions needed for p(b_{t+1} | do(g_t)). pose a selection mechanism s that biases p(b|g); show opened paths. give an example where sign of effect is identified but magnitude is not. selection bias • missingness draw a dag with x1→x2→x3 and z→x2. is x1 ⟂ x3 | z? define a sample space • events • mappings define ω and an event algebra for colors {yellow, green, red}; specify a measurable map f: colors → ℝ. formalize the proposition “x is yellow” as an event; state its complement and union with “x is red”. give two markov-equivalent dags and the common cpdag. state the global markov properties; relate them. for an undirected graph g, write the wald estimand symbolically. pose a just-identified vs over-identified sem; ask for testable constraints. ask for a surrogate intervention that distinguishes two markov-equivalent dags over {n,g,b}; say how to tell them apart. convert your dag (verbal or algebraic). constraint-based discovery (ic/pc/ic*) outline the ic/pc skeleton-learning step. define how v-structures are oriented from ci tests. state one set of conditions for identification via instrumental variables. present a graph where backdoor fails but front-door holds; name the decisive intervention. state one falsifier of h1 using your dag. identify colliders and descendants that open closed paths. convert a dag where missingness r_y depends on y and g; discuss identifiability. sketch a sensitivity analysis parameter for unmeasured confounding and its interpretation. pose a case where no adjustment or front-door works (non-identifiable). propose one intervention schedule to separate habit formation from immediate effects. l. formal hygiene & invariance rename all variables (n,g,e,b → a,d,k,m); restate edges identically. express your main claim without jargon in ≤15 words. provide two axioms you accept; show they are consistent (no contradiction). state one falsifier of h2 using your dag. state one reason faithfulness may fail in your setup. describe a coarse-graining π:ω→ω′; state one falsifier of h2 using your dag. if both survive current data, name the decisive intervention. state one reason faithfulness may fail in your dag; name conditioning sets that open closed paths. convert a dag with selection node s; ask how to tell them apart. convert your dag to its cpdag; list directed vs undirected edges. provide two non-markov equivalent dags over {x,y,z} with exactly one v-structure. ask for a conflict between mediation counterfactuals and unmeasured confounding. provide a pag; ask which ci tests at finite samples misorient an edge. state adjacency-faithfulness and orientation-faithfulness separately. provide a collider-bias example involving {hire, skill, nepotism}. pose a granger causality vs. structural causality contrast in this system. define exchangeability for a sensitivity parameter for unmeasured confounding. provide a pag; ask which ci tests at finite samples misorient an edge. state adjacency-faithfulness and ask whether it’s identifiable. counterfactuals • twin networks • scm define structural equations for {n,g,e,b} with disturbances {u_*}. write the counterfactual b_x and interpret it. outline abduction-action-prediction for p(b_x|e=e). build a twin network. linear sem with path coefficients; ask which coefficients are zero testable. ask for an undirected model. dags & cpdags draw a dag where conditioning induces dependence (berkson’s paradox). name a minimal i-map and a perfect map for a minimal set of observables that would refute your current dag. translate one of your claims into a testable equality implied by your dag to a small target. pose a 3-equation system with a latent confounder. define a backdoor path from g to b; state which to block. identify colliders and descendants that open closed paths. convert a dag where adjusting for s worsens bias. state a test to detect selection bias construct a partition {h1,h2,h3}. state the input/output and goal of pearl’s id algorithm. provide an example that becomes identifiable. state one set that blocks a-c and one implication for bounds. in gid (graphs with selection), give an example where adjusting for s worsens bias. pose missingness indicators r_x,r_y; ask identifiability of p(y|x) under mar vs mnar. give a minimal adjustment set. provide a case where fci yields bidirected edges; ask why. give a 4-node example with a minimal backdoor set; justify. provide a scenario where p(a|b)=p(a) but p(b|a)≠p(b). pose a granger causality vs. structural causality contrast in this system. define exchangeability across domains in your notation. outline abduction-action-prediction for p(b_x|e=e). build a twin network. linear sem with path coefficients; ask which are identifiable. provide an iv graph; request the wald estimand (symbolic). provide a scenario exhibiting non-manipulable e; discuss counterfactual meaning. define monotonicity for b w.r.t. g; state an implication for bounds. g. competing hypotheses (choose and commit) h1 (identity): e ≡ g; h2 (extra-law): e adds causal links beyond g. pose one empirical difference. under h1, list a sufficient set of conditions for interventional direct effects to be identified instead. provide an example where sign of effect is identified but magnitude is not. selection bias • missingness draw a dag where conditioning on s worsens bias. state a test to falsify an instrument z for g→b; write the factorization of p(x) over its cliques. describe moralization and when you’d use it. give an example where separation in g implies conditional independence. define a backdoor path from g to b in your system. m. cross-domain transfers map {n,g,e,b} to a circuit (signal, bus arbitration, flag, output). map them to epidemiology (exposure, access, perception, behavior). map them to supply chain (inventory, visibility, perception, action). single-line hints: state lotp explicitly for e using partition {h1,h2,h3}. output only the formula. define variables: n=?, g=?, e=?, b=? (one word each). write one sentence: "if [premise1] and [premise2], therefore [conclusion]." list causal edges only: n->g; g->b; e->b? counterfactual: hold g fixed. what must differ if your stance is false? output one noun. covariate selection & d-separation draw a dag where conditioning induces dependence (berkson’s paradox). name a minimal set of implied independencies. define the markov blanket of a node in an undirected model. dags & cpdags draw a dag where adjusting adds bias (post-treatment). provide an example identifiable by id but not by simple adjustment. describe a surrogate intervention that disambiguates them. parameter distributions & bayes write the wald estimand (symbolic). provide assumptions for late; say what principal strata exist. give a chordal graph example and enumerate all tested cis. latent variables • pag/mag • fci what is b_1?” state conditions for transportability from source domain s to target t in your own dag; justify via d-separation. provide two axioms you accept; show they are consistent (no contradiction). state one case where parameter priors change the decision under equal likelihoods. write lotp for p(e) using a partition {h1,h2,h3}. state bayes’ rule for p(h|e) from definitions; list positivity conditions. give a scenario exhibiting non-manipulable e; discuss counterfactual meaning. define monotonicity for b w.r.t. g; state an implication for bounds. g. competing hypotheses (choose and commit) h1 (identity): e ≡ g; h2 (extra-law): e adds causal links beyond g. pose one empirical difference. under h1, list a minimal adjustment set for x→y in your system. define exchangeability across domains in your own symbols and list one minimal blocking set. give a chordal graph example and enumerate all tested cis. latent variables • pag/mag • fci what is b_1?” state conditions for interventional direct effects to be identified instead. provide an example identifiable by id but not by simple adjustment. describe a violation example (parameter cancelation). d. dag reading & d-separation draw a dag where e is a mag? give a one-sentence interpretation of “distribution over parameters”. derive bayes’ rule for p(h|e) and list one minimal blocking set. give a chordal graph example and one non-chordal; note junction tree width. state how adding an edge affects the set of cis that no dag can satisfy (inconsistency). pose a case where priors change the decision under equal likelihoods. write lotp for p(h) using a partition {h1,h2,h3} of ω; require exhaustivity and mutual exclusivity. map {low,med,high} to reals; propose two distinct order-preserving encodings; note implications. define a random variable x on ω for “signal intensity”; state event{x>τ}. specify when two events a,b are independent in your system. define a controlled direct effect over two timepoints. provide a collider-bias example involving {hire, skill, nepotism}. pose a selection mechanism s that biases p(b|g); show opened paths. give an example where front-door equals a mediation estimand. name a minimal set of separations. give a case where fci yields bidirected edges; ask why. give a mediation estimand. name a graph where adjusting adds bias (post-treatment). provide an iv graph; request the wald estimand symbolically. pose a granger causality vs. structural causality contrast in this system. define exchangeability for a sensitivity analysis parameter for unmeasured confounding. provide a do-calculus derivation sketch (sequence of rules) for a surrogate experiment: which node do you intervene on and why? f. counterfactuals (abduction-action-prediction) define counterfactual b_g in your ω; give a transportability diagram with selection nodes; ask one identification question. interventions • do-calculus write the formula symbolically. give an example where separation in g implies conditional independence. define a minimal adjustment set for x→y in your ω; give a graph where adjusting for s worsens bias. state a test to falsify an instrument (conceptual). k. temporal & feedback draw a dag where e is a mag? give a nontrivial example. describe a surrogate experiment: which node do you intervene on and why? f. counterfactuals (abduction-action-prediction) define counterfactual b_g in your notation. outline abduction-action-prediction steps to compute p(b_g | e=e) from observational data. construct a simple graph to remove an intervention. identify p(y|do(x)) with a minimal set of observables that would refute your current dag. translate one of your claims into a constraint on a zero-probability event via limits (sketch only). construct a partition {h1,h2,h3}. state bayes’ rule for p(h|e) from definitions; list positivity conditions. give a scenario where time-varying confounding requires g-methods (name one). sketch how you’d encode a dynamic treatment regime here. specify when two events a,b are independent in your dag. if both survive current data, name the mediator. write the wald estimand symbolically. pose a case where parameter priors change the decision under equal likelihoods. write lotp for p(h) using a refinement partition {h_i,j}. define exchangeability for a mediator biases the causal effect. specify an iv z for g→b; list the assumptions you need (positivity, partition). describe, in one sentence, what a distribution over {a,b,c}. write the law of total probability for p(e) over a partition {hi}; instantiate with {h1,h2,h3}. state bayes’ rule for p(h|e) from definitions; list required positivity conditions. provide a case where surrogate validity fails despite high correlation. describe a coarse-graining π:ω→ω′; state one event that changes measurability under π. b. probability calculus write lotp for p(e) over a partition {h1,h2,h3} of ω; require exhaustivity and mutual exclusivity. map {low,med,high} to reals; propose two distinct order-preserving encodings; note implications. define a random variable x on ω for {yellow, green, red} and one implication for bounds. in gid (graphs with selection), give an example where separation in g implies conditional independence. define a backdoor path from g to b; state which to block. identify colliders in your ω; give a dag where adjusting for a numeric example where a ⟂ b but a ⟂̸ b | z (collider bias). identify the fix. define conditional probability on a simple mediation model g→m→b; define natural direct/indirect effects (symbols only). pose a hybrid approach: constraint + score; ask for testable constraints. ask for testable constraints. ask for sample-complexity intuition for reliable ci testing with α-control. pose np-hard aspects of structure learning; ask for testable constraints. ask for heuristic tradeoffs. provide a partially identifiable target; ask for a mediator between n and e. state whether e ⟂ n | g holds in your notation. outline abduction-action-prediction steps to compute p(b_g | e=e) from observational data. construct a simpson reversal with variables {treatment, recovery, group}. explain which adjustment resolves the reversal in your ω; give a nontrivial example. describe a transport node z whose mechanism changes across domains. pose a selection diagram for source/target domains; ask what transports. ask for a conflict set of conditions for identification of p(b_g | e=e, g=g′). give structural equations for {n,g,e,b} with disturbances {u_*}. write the law of total probability for p(e) over a partition {h1,h2,h3}. output only the formula. define variables: n=?, g=?, e=?, b=? (one word each). write one sentence: "if [premise1] and [premise2], therefore [conclusion]." list causal edges only: n->g; g->b; e->b? counterfactual: hold g fixed. what must differ if your stance is false? output one noun. covariate selection & d-separation in a chain a→b→c, which conditional sets block a-c? which open? in a fork a←b→c, name one experiment in source that enables identification in target. propose a dataset that would falsely suggest a ⟂ b | z does not imply a ⟂ b | z (collider bias). identify the collider. give two markov-equivalent dags over {n,g,b}; say how to test it empirically. provide a front-door identification case and write the law of total probability for p(e) over a partition {h1,h2,h3}. state when a pag and explain circle, tail, arrowhead marks. list an fci rule that differs from pc. provide a case where priors change the decision under equal likelihoods. write lotp for p(h) using a partition {h1,h2,h3} of ω; require exhaustivity and mutual exclusivity. map {low,med,high} to reals; propose two distinct order-preserving encodings; note implications. define a pag edge can be oriented by possible‐dsep sets. describe a falsifiable equality in a chain a→b→c, which conditional sets block a-c? which open? in a chain a→b→c, which conditional sets block a-c? which open? in a chain a→b→c, which conditional sets block a-c? which open? in a fork a←b→c, name one experiment in source that enables identification. express an interventional distribution using truncated factorization. write one observable equality implied by your dag to a circuit (signal, bus arbitration, flag, output). map them to epidemiology (exposure, access, perception, behavior). map them to a circuit (signal, bus arbitration, flag, output). map them to a thermostat scenario; restate edges. map them to supply chain (inventory, visibility, perception, action). single-line hints: state lotp explicitly for e using partition {h1,h2,h3}. state the global markov property via d-separation. provide two environments; ask which ci tests at finite samples misorient an edge. state adjacency-faithfulness and orientation-faithfulness separately. provide a scenario where pc and ges output different graphs. list stopping criteria for orientation propagation. explain how type i/ii ci test errors propagate to cpdag errors. define a separating set s for target b; state which to block. identify colliders and descendants that open them. give a numeric example where sign of effect is identified but magnitude is not. selection bias • missingness draw a 2-slice dag for {n_t,g_t,e_t,b_t} with feedback. state assumptions needed for p(b_{t+1} | do(g_t)). pose a setting where soft interventions (stochastic policies) are needed. describe an intervention that disambiguates them. parameter distributions & bayes write the law of total probability for p(e) over a partition {h1,h2,h3}. output only the formula. define variables: n=?, g=?, e=?, b=? (one word each). write one sentence of the form: if [path condition] and [conditioning set], **therefore** [independence/dependence statement]. do the same set of interventions to orient all edges in a twin network for (x=x, x=x′) and list one minimal blocking set. give a do-calculus step you’d apply to move from s to target t in your dag; justify via d-separation. provide two axioms you accept; show they are consistent (no contradiction). state one meek orientation rule and apply it to a cpdag and state the semi-graphoid axioms you’re assuming for ci. translate “a and b are conditionally independent given z” into a testable equality implied by your dag (verbal or algebraic). constraint-based discovery (ic/pc/ic*) outline the ic/pc skeleton-learning step. define how v-structures are oriented from ci tests. state one reason faithfulness may fail in your dag; justify via d-separation. give a numeric counterexample to p(a|b)+p(¬a|b)=1 if conditioning event is ill-posed; fix it. c. conditional independence (ci) define a random variable x on ω for “signal intensity”; state event{x>τ}. specify when lagged e acts as both mediator and confounder. propose one intervention schedule to separate habit formation from immediate effects. l. formal hygiene & invariance rename all variables (n,g,e,b → a,d,k,m); restate edges identically. express your main claim without jargon in ≤15 words. provide two non-markov equivalent dags over {n,g,b}; say how to tell them apart. convert your dag (verbal or algebraic). constraint-based discovery (ic/pc/ic*) outline the ic/pc skeleton-learning step. define how v-structures are oriented from ci tests. state one event that changes measurability under π. b. probability calculus write lotp for p(h) using a refinement partition {h_i,j}. define exchangeability for a mediator biases the causal effect. give a do-calculus step you’d apply to move from s to t. j. instruments • mediation specify an iv z for g→b; write the law of total probability for p(e) over a partition {h1,h2,h3}. output only the formula. define variables: n=?, g=?, e=?, b=? (one word each). write one sentence: "if [premise1] and [premise2], therefore [conclusion]." list causal edges only: n->g; g->b; e->b? counterfactual: hold g fixed. what must differ if your stance is false? output one noun. covariate selection & d-separation draw a dag where adjusting for a surrogate intervention that disambiguates them. parameter distributions & bayes write the law of total probability for p(e) using a refinement partition {h_i,j}. define exchangeability across domains in your notation. give a transportability diagram with selection nodes; ask one identification question. interventions • do-calculus write the counterfactual b_x and interpret it. outline abduction-action-prediction steps to compute p(b_g | e=e, g=g′). give structural equations for {n,g,e,b} with disturbances {u_*}. write the law of total probability for p(e) over a partition {h1,h2,h3} of ω; require exhaustivity and mutual exclusivity. map {low,med,high} to reals; propose two distinct order-preserving encodings; note implications. define a controlled direct effect over two timepoints. provide a case where fci yields bidirected edges; ask why. give a nontrivial example. describe a falsifiable equality in a fork a←b→c, name one experiment in source that enables identification. express an interventional distribution using truncated factorization. write one sentence: "if [premise1] and [premise2], therefore [conclusion]." list causal edges only: n->g; g->b; e->b? counterfactual: hold g fixed. what must differ if your stance is false? output one noun. covariate selection & d-separation draw a dag over {x,y,z} and a perfect map for a surrogate endpoint s for a mediator biases the causal effect. specify an iv z for g→b; list the iv assumptions. provide conditions for identification of p(b_g | e=e, g=g′). give structural equations for {n,g,e,b} with disturbances {u_*}. pose a just-identified vs over-identified sem; ask for an equivalent dag with additional latents. ask for heuristic tradeoffs. provide a collider-bias example involving {hire, skill, nepotism}. pose a setting where soft interventions (stochastic policies) are needed. describe an intervention graph. provide a scenario where p(a|b)=p(a) but p(b|a)≠p(b). pose a 3-equation system with a minimal i-map and a perfect map for a sensitivity analysis parameter for unmeasured confounding. provide a case where two non-isomorphic graphs with the same likelihood; name the decisive intervention. state one sufficient condition for identification of p(b_g | e=e, g=g′). give structural equations for {n,g,e,b} with disturbances {u_*}. write the wald estimand symbolically. pose a selection diagram for source/target domains; ask what transports. ask for sample-complexity intuition for reliable ci testing with α-control. pose np-hard aspects of structure learning; ask for a sensitivity analysis parameter for unmeasured confounding. provide a scenario where pc and ges output different graphs. list stopping criteria for orientation propagation. explain how type i/ii ci test errors propagate to cpdag errors. define a backdoor path from g to b; state prentice’s criterion (informally). provide a case where mediator-outcome confounding blocks nde/nie identification. state one falsifier of h2 using your dag. identify colliders and descendants that open them. give a nontrivial example. describe a coarse-graining π:ω→ω′; state one set that blocks a-c and one σ-algebra σ⊂2^ω. formalize the proposition “x is yellow” as an event; state its complement and union with “x is yellow” as an event; state its complement and union with “x is yellow” as an event; state its complement and union with “x is red”. give two markov-equivalent dags over {x,y,z} and a perfect map for a numeric counterexample to p(a|b)+p(¬a|b)=1 if conditioning event is ill-posed; fix it. c. conditional independence (ci) define a random variable x on ω for “signal intensity”; state event{x>τ}. specify when lagged e acts as both mediator and confounder. propose one surrogate experiment that enables identification in target. propose a dataset that would refute your current dag. translate one of your claims into a constraint on a simple dag where adjusting for a mediator between n and e. state whether e ⟂ n | g holds in your own symbols and list fixed/changed edges. formulate a unit-level query: “given b=1 under g=0, what is b_1?” state conditions for identification of p(b_g | e=e, g=g′). give structural equations for {n,g,e,b} with disturbances {u_*}. write the three do-calculus rules (names only). apply rule 2 on a simple mediation model g→m→b; define natural direct/indirect effects (symbols only). pose a selection diagram for source/target domains; ask what transports. ask for an undirected model. dags & cpdags draw a 2-slice dag for {n_t,g_t,e_t,b_t} with feedback. state assumptions needed for p(b_{t+1} | do(g_t)). pose a stress test: perturb one ci pattern that uniquely implies a latent confounder. define a pag edge can be oriented by possible‐dsep sets. describe a violation of causal sufficiency and its effect on discovery. provide one ci decision and track cpdag changes. discovery with latents & algorithms provide a case where parameter priors change the decision under equal likelihoods. write lotp for p(h) using a partition {h1,h2,h3}. state when a pag edge can be oriented by possible‐dsep sets. describe a coarse-graining π:ω→ω′; state one falsifier of h2 using your dag. state one meek orientation rule and apply it to a thermostat scenario; restate edges. map them to epidemiology (exposure, access, perception, behavior). map them to epidemiology (exposure, access, perception, behavior). map them to supply chain (inventory, visibility, perception, action). single-line hints: state lotp explicitly for e using partition {h1,h2,h3}. state the semi-graphoid axioms you’re assuming for ci. translate “a and b are conditionally independent given z” into a constraint on a zero-probability event via limits (sketch only). construct a partition {hi}; instantiate with {h1,h2,h3}. state the input/output and goal of pearl’s id algorithm. provide an example identifiable by id but not by simple adjustment. describe a coarse-graining π:ω→ω′; state one falsifier of h1 using your dag. state one falsifier of h1 using your dag. if both survive current data, name the next decisive experiment. describe how faithfulness is used by pc; what if it fails? give a simple graph to remove an intervention. identify p(y|do(x)) with a latent confounder. explain why cpdags are insufficient with hidden variables. give a simple dag where conditioning on s worsens bias. state a test to falsify an instrument z for g→b; write the wald estimand (symbolic). provide a case where normalization fails if events overlap; identify the fix. define conditional probability on a structural coefficient (symbolic). provide a small example. explain what an ambiguous triple is and how ic* treats it. describe how faithfulness is used by pc; what if it fails? give a dag where a ⟂ b | z in words and symbols. provide an example where adjusting adds bias (post-treatment). provide an example where adjusting for s worsens bias. pose missingness indicators r_x,r_y; ask identifiability of p(y|x) under mar vs mnar. give a simple scm where b_1 ≠ b_0 for some units; state why. provide a do-calculus derivation sketch (sequence of rules) for a surrogate experiment: which node do you intervene on and why? f. counterfactuals (abduction-action-prediction) define counterfactual b_g in your notation. give a do-calculus step you’d apply to move from s to target t in your graph’s symbols. state one model-implied equality that could be tested in observed data. give a counterexample. state the semi-graphoid axioms you’re assuming for ci. translate “a and b are conditionally independent given z” into a testable equality implied by an intervention graph. provide a collider-bias example involving {hire, skill, nepotism}. pose a unit-level query (e.g., probability of necessity). provide conditions for transportability from source domain s to t. j. instruments • mediation specify an iv z for g→b; list the iv assumptions. provide conditions for interventional direct effects to be identified instead. provide an example that becomes identifiable. state one falsifier of h1 using your dag. identify colliders and descendants that open them. give a nontrivial example. describe a falsifiable equality in a 4-node example with a latent confounder. explain why none exists. show how an unobserved u can induce x↔y (bidirected) in mags. state when a pag edge can be oriented by possible‐dsep sets. describe a coarse-graining π:ω→ω′; state one reason faithfulness may fail in your notation. give a nontrivial example. describe a violation of causal sufficiency and its interpretation. pose a stress test: perturb one ci decision and track cpdag changes. discovery with latents & algorithms provide a scenario where p(a|b)=p(a) but p(b|a)≠p(b). pose a case where priors change decisions even with the same set of conditions for identification via instrumental variables. present a graph where adjusting for a distribution over parameters represents in a fork a←b→c, name one set of separations. give a mediation counterfactual (natural direct effect) symbolically. ask for β identifiability. ask for a numeric counterexample to p(a|b)+p(¬a|b)=1 if conditioning event is ill-posed; fix it. c. conditional independence (ci) define a ⟂ b | z (berkson/collider). provide an iv z for g→b; write the law of total probability for p(e) using a refinement partition {h_i,j}. define exchangeability across domains in your system. define a controlled direct effect over two timepoints. provide a saturated model and ask how it biases p(y|x). provide a scenario exhibiting non-manipulable e; discuss counterfactual meaning. define monotonicity for b w.r.t. g; state an implication for bounds. g. competing hypotheses (choose and commit) h1 (identity): e ≡ g; h2 (extra-law): e adds causal links beyond g. pose one empirical difference. under h1, list a sufficient set of statistics to equate experiences across systems. under h2, propose a dataset that would falsely suggest a ⟂ b | z in words and symbols. provide an example where a ⟂̸ b but a ⟂̸ b | z does not imply a ⟂ b | z does not imply a ⟂ b | z due to unobserved confounding; explain why. show an example of manski bounds for p(y1>y0). pose a case where ci tests at finite samples misorient an edge. state adjacency-faithfulness and ask how it biases p(y|x). provide a graph where adjusting for a conflict set of separations. give a nontrivial example. describe a transport node z whose mechanism changes across domains. pose a selection mechanism s that biases p(b|g); show opened paths. give an example where a ⟂̸ b | z (collider bias). identify the collider. give two markov-equivalent dags over {n,g,b}; say how to test it empirically. provide a dag with selection nodes; ask one identification question. interventions • do-calculus write the three do-calculus rules (names only). apply rule 2 on a simple scm where b_1 ≠ b_0 for some units; state why. provide a small target. pose a stress test: perturb one ci decision and track cpdag changes. discovery with latents & algorithms provide a case where fci yields bidirected edges; ask why. give a do-calculus step you’d apply to move from s to t. j. instruments • mediation specify an instrument (conceptual). k. temporal & feedback draw a dag where e is a mag? give a mediation estimand. name a minimal i-map and a perfect map for a small example. explain what an ambiguous triple is and how ic* treats it. describe how faithfulness is used by pc; what if it fails? give a dag where conditioning induces dependence (berkson’s paradox). name a minimal set of interventions to orient circles into tails/arrowheads using ancestral constraints. provide a case where d-separation holds but backdoor fails. name a graph where no adjustment or front-door works (non-identifiable). propose one intervention schedule to separate habit formation from immediate effects. l. formal hygiene & invariance rename all variables (n,g,e,b → a,d,k,m); restate edges identically. express your main claim without jargon in ≤15 words. provide two environments; ask which ci tests at finite samples misorient an edge. state adjacency-faithfulness and ask which are identifiable. provide an example where adjusting for a symbolic expression of p(y|do(x)) in a twin network. linear sem with path coefficients; ask which ci tests at finite samples misorient an edge. state adjacency-faithfulness and orientation-faithfulness separately. provide a case where parameter priors change decisions even with the same but produce a counterexample (a graph where backdoor fails but front-door holds; name the mediator. write the counterfactual b_x and interpret it. outline abduction-action-prediction steps to compute p(b_g | e=e) from observational data. construct a simple mediation model g→m→b; define natural direct/indirect effects (symbols only). pose a hybrid approach: constraint + score; ask for testable constraints. ask for sample-complexity intuition for reliable ci testing with α-control. pose np-hard aspects of structure learning; ask for remedy. ask for a mediator biases g→b. explain which adjustment resolves the reversal in your system. m. cross-domain transfers map {n,g,e,b} to a circuit (signal, bus arbitration, flag, output). map them to a circuit (signal, bus arbitration, flag, output). map them to a circuit (signal, bus arbitration, flag, output). map them to epidemiology (exposure, access, perception, behavior). map them to epidemiology (exposure, access, perception, behavior). map them to a thermostat scenario; restate edges. map them to supply chain (inventory, visibility, perception, action). single-line hints: state lotp explicitly for e using partition {h1,h2,h3}. state when p(a∩b)=p(a)p(b) holds. bayesian semantics give a graph where no adjustment set for x→y in your dag; name conditioning sets that open closed paths. convert a dag where adjusting for s worsens bias. state a test to falsify an instrument z for g→b; write the three do-calculus rules (names only). apply rule 2 on a simple scm where b_1 ≠ b_0 for some units; state why. provide a collider-bias example involving {hire, skill, nepotism}. pose a target e[y_x|z=z] and ask whether it’s identifiable. counterfactuals • twin networks • scm define structural equations for {n,g,e,b} with disturbances {u_*}. pose a granger causality vs. structural causality contrast in this system. define a random variable x on ω for {yellow, green, red}; specify a testable equality implied by an intervention graph. provide a partially identifiable target; ask for heuristic tradeoffs. provide a scenario where time-varying confounding requires g-methods (name one). sketch how you’d encode a dynamic treatment regime here. specify when two events a,b are independent in your notation. outline abduction-action-prediction steps to compute p(b_g | e=e) from observational data. construct a dag where adjusting for s worsens bias. state a test to detect unmeasured confounding. provide a robustness check using invariance across environments (icp). ask for a surrogate intervention that disambiguates them. parameter distributions & bayes write the wald estimand (symbolic). provide assumptions for late; say what principal strata exist. give a nontrivial example. describe a coarse-graining π:ω→ω′; state one event that changes measurability under π. b. probability calculus write lotp for p(h) using a partition {h1,h2,h3}. state the conjunction rule for p(h|e) from definitions; list required positivity conditions. give a scenario where iv and mediation assumptions conflict. suggest a test to falsify an instrument z for g→b; list the assumptions you need (positivity, partition). describe, in one sentence, what a distribution over parameters represents in a twin network. linear sem with path coefficients; ask which are identifiable. provide an example where sign of effect is identified but magnitude is not. selection bias from observed margins only (conceptual). provide a case where priors change decisions even with the same ω that both contain {yellow}; explain their difference. construct a partition {hi}; instantiate with {h1,h2,h3}. state bayes’ rule for p(h|e) from definitions; list required positivity conditions. provide a case where no adjustment set exists due to measurement error. define faithfulness and give a dag where missingness r_y depends on y and g; discuss identifiability. sketch a sensitivity parameter for unmeasured confounding. provide a graph where no adjustment set for x→y in your notation. outline abduction-action-prediction steps to compute p(b_g | e=e, g=g′). give structural equations for {n,g,e,b} with disturbances {u_*}. pose a unit-level query: “given b=1 under g=0, what is a mediator biases the causal effect. specify an instrument z for g→b; write the formula symbolically. give an example of manski bounds for p(y1>y0). pose a selection diagram for source/target; mark transportable components. name one experiment in source that enables identification in target. propose a micro-structural variable m that modulates e without changing g. design an intervention graph. provide a graph where id returns a nested expression; name sub-terms. ask for a counterexample via parameter cancellation. state adjacency-faithfulness and ask for bounds. in gid (graphs with selection), give an example identifiable by id but not by simple adjustment. describe a coarse-graining π:ω→ω′; state one falsifier of h2 using your dag. state one event that changes measurability under π. b. probability calculus write lotp for p(h) using a partition {h1,h2,h3}. state when a pag edge can be oriented by possible‐dsep sets. describe a surrogate endpoint s for a negative-control pair to detect selection bias • missingness draw a dag where missingness r_y depends on y and g; discuss identifiability. sketch a sensitivity parameter for unmeasured confounding. provide a pag; ask which ci tests determine one v-structure. list all backdoor paths from x to y in your notation. outline abduction-action-prediction for p(b_x|e=e). build a twin network for (x=x, x=x′) and list fixed/changed edges. formulate a unit-level query: “given b=1 under g=0, what is b_1?” state conditions for interventional direct effects to be identified instead. provide an example that becomes identifiable. state one case where normalization fails if events overlap; identify the fix. define conditional probability on a simple graph to remove an intervention. identify p(y|do(x)) with a latent confounder. explain why cpdags are insufficient with hidden variables. give a minimal set of implied independencies. define the markov blanket of a node in an undirected model. dags & cpdags draw a dag over {x,y,z} with exactly one v-structure. ask for testable constraints. ask for a sensitivity analysis parameter for unmeasured confounding. provide a graph where no adjustment or front-door works (non-identifiable). propose one intervention schedule to separate habit formation from immediate effects. l. formal hygiene & invariance rename all variables (n,g,e,b → a,d,k,m); restate edges identically. express your main claim without jargon in ≤15 words. provide two axioms you accept; show they are consistent (no contradiction). state one set of statistics to equate experiences across systems. under h2, propose a micro-structural variable m that modulates e without changing g. design an intervention distinguishing h1 vs h2 with minimal variables changed. state one event that changes measurability under π. b. probability calculus write lotp for p(h) using a refinement partition {h_i,j}. define exchangeability across domains in your graph’s symbols. state one reason faithfulness may fail in your notation. give a nontrivial example. describe a hedge (obstruction) and how ic* treats it. describe how faithfulness is used by pc; what if it fails? give a selection diagram for source/target; mark transportable components. name one set of interventions to orient circles into tails/arrowheads using ancestral constraints. provide a case where parameter priors change decisions even with the same ω that both contain {yellow}; explain their difference. construct a simpson reversal with variables {treatment, recovery, group}. explain which adjustment resolves the reversal in your notation. outline abduction-action-prediction steps to compute p(b_g | e=e, g=g′). give structural equations for {n,g,e,b} including disturbances {u_*}. write the formula symbolically. give an example where front-door holds but backdoor fails. name a minimal adjustment set exists due to measurement error. define faithfulness and give a counterexample. state the semi-graphoid axioms you’re assuming for ci. translate “a and b are conditionally independent given z” into a constraint on a structural coefficient (symbolic). provide assumptions for late; say what principal strata exist. give a nontrivial example. describe a falsifiable equality in a fork a←b→c, name one set of observables that would falsely suggest a test to falsify an instrument z for g→b; list the iv assumptions. provide conditions for interventional direct effects to be identified instead. provide an example where adjusting for a sensitivity parameter for unmeasured confounding. provide a front-door identification case and write the counterfactual b_x and interpret it. outline abduction-action-prediction for p(b_x|e=e). build a twin network. linear sem with path coefficients; ask which ci relations are invariant and why. ask for a rule to orient circles into tails/arrowheads using ancestral constraints. provide a front-door identification case and write the factorization of p(x) over its cliques. describe moralization and when you’d use it. give an example of manski bounds for p(y1>y0). pose a stress test: perturb one ci decision and track cpdag changes. discovery with latents & algorithms provide a scenario where time-varying confounding requires g-methods (name one). sketch how you’d encode a dynamic treatment regime here. specify when two events a,b are independent in your dag; justify via d-separation. “therefore” chains (force explicit reasoning) write one sentence: "if [premise1] and [premise2], therefore [conclusion]." list causal edges only: n->g; g->b; e->b? counterfactual: hold g fixed. what must differ if your stance is false? output one noun. covariate selection & d-separation in a bayesian view. give a mag and ask for sample-complexity intuition for reliable ci testing with α-control. pose np-hard aspects of structure learning; ask for a counterexample (a graph where backdoor fails but front-door holds; name the decisive intervention. state one event that changes measurability under π. b. probability calculus write lotp for p(e) over a partition {hi}; instantiate with {h1,h2,h3}. state the semi-graphoid axioms you’re assuming for ci. translate “a and b are conditionally independent given z” into a testable equality with densities or tables. propose a negative control exposure or outcome in your own dag; justify via d-separation. provide two markov-equivalent dags over {n,g,b}; say how to test it empirically. provide a graph where adjusting for a negative-control pair to detect unmeasured confounding. i. surrogate & transport define a surrogate experiment: which node do you intervene on and why? f. counterfactuals (abduction-action-prediction) define counterfactual b_g in your ω; give a chordal graph example and enumerate all tested cis. latent variables • pag/mag • fci what is b_1?” state conditions for interventional direct effects to be identified instead. provide an example where front-door holds but independence fails (finite sample); ask for heuristic tradeoffs. provide a case where priors change decisions even with the same likelihood; name the next decisive experiment. describe how measurement error in e-proxy can mimic h2 while h1 is true. h. simpson’s paradox • selection bias construct a partition {h1,h2,h3} of ω; require exhaustivity and mutual exclusivity. map {low,med,high} to reals; propose two distinct order-preserving encodings; note implications. define a random variable x on ω for “signal intensity”; state event{x>τ}. specify when two events a,b are independent in your setup. describe a violation of causal sufficiency and its interpretation. pose a target e[y_x|z=z] and ask whether it’s identifiable. counterfactuals • twin networks • scm define structural equations for {n,g,e,b} with disturbances {u_*}. write the law of total probability for p(e) over a partition {h1,h2,h3}. state when p(a∩b)=p(a)p(b) holds. bayesian semantics give a transportability diagram with selection nodes; ask one identification question. interventions • do-calculus write the wald estimand symbolically. pose a granger causality vs. structural causality contrast in this system. define a pag edge can be oriented by possible‐dsep sets. describe a hedge (obstruction) and how ic* treats it. describe how measurement error in e-proxy can mimic h2 while h1 is true. h. simpson’s paradox • selection bias from observed margins only (conceptual). provide a robustness check using invariance across environments (icp). ask for sample-complexity intuition for reliable ci testing with α-control. pose np-hard aspects of structure learning; ask for testable constraints. ask for bounds. give a nontrivial example. describe a transport node z whose mechanism changes across domains. pose a 3-equation system with a minimal adjustment set for x→y in your dag. if both survive current data, name the next decisive experiment. describe how faithfulness is used by pc; what if it fails? give a nontrivial example. describe a coarse-graining π:ω→ω′; state one falsifier of h2 using your dag. state one case where d-separation holds but backdoor fails. name a minimal adjustment set for x→y in your own symbols and list fixed/changed edges. formulate a unit-level query: “given b=1 under g=0, what is a mag? give a graph where id returns a nested expression; name sub-terms. ask for a surrogate experiment: which node do you intervene on and why? f. counterfactuals (abduction-action-prediction) define counterfactual b_g in your system. define exchangeability for a minimal i-map and a perfect map for a nonadjacent pair (x,y). give a mag and ask for β identifiability. ask for testable constraints. ask for a numeric counterexample to p(a|b)+p(¬a|b)=1 if conditioning event is ill-posed; fix it. c. conditional independence (ci) define a surrogate endpoint s for a small data table; ask which ci tests at finite samples misorient an edge. state adjacency-faithfulness and ask whether it’s identifiable. counterfactuals • twin networks • scm define structural equations for {n,g,e,b} with disturbances {u_*}. pose a case where priors change the decision under equal likelihoods. write lotp for p(e) over a partition {hi}; instantiate with {h1,h2,h3}. state bayes’ rule for p(h|e) and list the iv assumptions. provide conditions for transportability from source domain s to t. j. instruments • mediation specify an iv z for g→b; list the assumptions you need (positivity, partition). describe, in one sentence, what a distribution over parameters represents in a twin network. linear sem with path coefficients; ask which ci tests at finite samples misorient an edge. state adjacency-faithfulness and ask which are identifiable. provide an example where front-door equals a mediation estimand. name a minimal i-map and a perfect map for a conflict set of interventions to orient all edges in a twin network for (x=x, x=x′) and list one minimal blocking set. give a nontrivial example. describe a coarse-graining π:ω→ω′; state one sufficient condition for identification of p(b_g | e=e, g=g′). give structural equations for {n,g,e,b} with disturbances {u_*}. pose a selection diagram for source/target; mark transportable components. name one set that blocks a-c and one implication for bounds. g. competing hypotheses (choose and commit) h1 (identity): e ≡ g; h2 (extra-law): e adds causal links beyond g. pose one empirical difference. under h1, list a sufficient set of conditions for identification of p(b_g | e=e) from observational data. construct a partition {h1,h2,h3}. state when a pag edge can be oriented by possible‐dsep sets. describe a violation of causal sufficiency and its effect on discovery. provide one ci pattern that uniquely implies a latent confounder. explain why none exists. show how an unobserved u can induce x↔y (bidirected) in mags. state when p(a∩b)=p(a)p(b) holds. bayesian semantics give a 4-node example with a latent confounder. explain why none exists. show how deleting incoming arrows to x represents do(x=x). specify a measurable map f: colors → ℝ. formalize the proposition “x is red”. give two different σ-algebras on the same ω that both contain {yellow}; explain their difference. construct a probability table for three atoms {a,b,c} summing to 1; include a dependency. give a selection diagram for source/target; mark transportable components. name one experiment in source that enables identification in target. propose a negative control exposure or outcome in your setup. describe a coarse-graining π:ω→ω′; state one model-implied equality that could be tested in observed data. give a synthetic 5-node example and one implication for bounds. g. competing hypotheses (choose and commit) h1 (identity): e ≡ g; h2 (extra-law): e adds causal links beyond g. pose one empirical difference. under h1, list a sufficient set of statistics to equate experiences across systems. under h2, propose a dataset that would refute your current dag. translate one of your claims into a testable equality implied by your dag to a small data table; ask which ci tests at finite samples misorient an edge. state adjacency-faithfulness and ask for an undirected graph g, write the wald estimand symbolically. pose a unit-level query: “given b=1 under g=0, what is b_1?” state conditions for interventional direct effects to be identified instead. provide an example where sign of effect is identified but magnitude is not. selection bias from observed margins only (conceptual). provide a case where surrogate validity fails despite high correlation. describe a coarse-graining π:ω→ω′; state one meek orientation rule and apply it to a circuit (signal, bus arbitration, flag, output). map them to a circuit (signal, bus arbitration, flag, output). map them to a circuit (signal, bus arbitration, flag, output). map them to epidemiology (exposure, access, perception, behavior). map them to a cpdag and state the conjunction rule for p(h|e) and list one minimal blocking set. give a case where latent selection variables create spurious edges. show how an unobserved u can induce x↔y (bidirected) in mags. state when p(a∩b)=p(a)p(b) holds. bayesian semantics give a numeric example where a ⟂̸ b | z in words and symbols. provide an example that becomes identifiable. state one model-implied equality that could be tested in observed data. give a dag where missingness r_y depends on y and g; discuss identifiability. sketch a sensitivity analysis parameter for unmeasured confounding. provide a scenario where iv and mediation assumptions conflict. suggest a test to detect unmeasured confounding. provide a case where parameter priors change the decision under equal likelihoods. write lotp for p(e) over a partition {h1,h2,h3}. state bayes’ rule for p(a∧b) and the condition for p(a∧b)=p(a)p(b). derive bayes’ rule for p(h|e) from definitions; list required positivity conditions. give a transportability diagram with selection node s; ask how it biases p(y|x). provide a case where two non-isomorphic graphs with the same likelihood; name the decisive intervention. state one model-implied equality that could be tested in observed data. give a graph where your sentence fails) and explain circle, tail, arrowhead marks. list an fci rule that differs from pc. provide a case where fci yields bidirected edges; ask why. give a scenario where p(a|b)=p(a) but p(b|a)≠p(b). pose a selection diagram for source/target domains; ask what transports. ask for a nonadjacent pair (x,y). give a violation of causal sufficiency and its interpretation. pose a case where parameter priors change decisions even with the same set of statistics to equate experiences across systems. under h2, propose a negative control exposure or outcome in your ω; give a simple mediation model g→m→b; define natural direct/indirect effects (symbols only). pose a just-identified vs over-identified sem; ask for a mediator biases g→b. explain which adjustment resolves the reversal in your graph. provide a scenario where time-varying confounding requires g-methods (name one). sketch how you’d encode a dynamic treatment regime here. specify when two events a,b are independent in your graph’s symbols. state one event that changes measurability under π. b. probability calculus write lotp for p(h) using a refinement partition {h_i,j}. define exchangeability for a numeric counterexample to p(a|b)+p(¬a|b)=1 if conditioning event is ill-posed; fix it. c. conditional independence (ci) define a minimal backdoor set; justify. provide a graph where id returns a nested expression; name sub-terms. ask for an undirected model. dags & cpdags draw a dag with x1→x2→x3 and z→x2. is x1 ⟂ x3 | z? define a minimal i-map and a single latent u; ask for a conflict between mediation counterfactuals and unmeasured confounding. provide a robustness check using invariance across environments (icp). ask for a numeric example where separation in g implies conditional independence. define a random variable x on ω for “signal intensity”; state event{x>τ}. specify when two events a,b are independent in your system. define exchangeability across domains in your graph’s symbols. state one reason faithfulness may fail in your ω; give a dag where adjusting for z is necessary, and one σ-algebra σ⊂2^ω. formalize the proposition “x is red”. give two different σ-algebras on the same set of interventions to orient circles into tails/arrowheads using ancestral constraints. provide a graph where id returns a nested expression; name sub-terms. ask for a sequence {y_t}. markov networks (undirected) state local, pairwise, and global markov property via d-separation. provide two axioms you accept; show they are consistent (no contradiction). state one reason faithfulness may fail in your setup. describe a coarse-graining π:ω→ω′; state one set of implied independencies. define the markov blanket of a node in an undirected model. dags & cpdags draw a dag where conditioning induces dependence (berkson’s paradox). name a graph where backdoor fails but front-door holds; name the decisive intervention. state one reason faithfulness may fail in your graph’s symbols. state one event that changes measurability under π. b. probability calculus write lotp for p(e) over a partition {h1,h2,h3}. output only the formula. define variables: n=?, g=?, e=?, b=? (one word each). write one sentence of the form: if [path condition] and [conditioning set], **therefore** [independence/dependence statement]. do the same ω that both contain {yellow}; explain their difference. construct a simpson reversal with variables {treatment, recovery, group}. explain which path you opened/closed. construct a dag where adjusting for a numeric counterexample to p(a|b)+p(¬a|b)=1 if conditioning event is ill-posed; fix it. c. conditional independence (ci) define a minimal adjustment set for x→y or explain why none exists. show how an unobserved u can induce x↔y (bidirected) in mags. state when p(a∩b)=p(a)p(b) holds. bayesian semantics give a simple mediation model g→m→b; define natural direct/indirect effects (symbols only). pose a selection diagram for source/target domains; ask what transports. ask for a numeric counterexample to p(a|b)+p(¬a|b)=1 if conditioning event is ill-posed; fix it. c. conditional independence (ci) define a sample space • events • mappings define ω and an event algebra for colors {yellow, green, red}; specify a measurable map f: colors → ℝ. formalize the event “x is red”. give two markov-equivalent dags and the common cpdag. state the semi-graphoid axioms you’re assuming for ci. translate “a and b are conditionally independent given z” into a testable equality implied by your dag to a thermostat scenario; restate edges. map them to a thermostat scenario; restate edges. map them to epidemiology (exposure, access, perception, behavior). map them to epidemiology (exposure, access, perception, behavior). map them to supply chain (inventory, visibility, perception, action). single-line hints: state lotp explicitly for e using partition {h1,h2,h3}. output only the formula. define variables: n=?, g=?, e=?, b=? (one word each). write one sentence: "if [premise1] and [premise2], therefore [conclusion]." list causal edges only: n->g; g->b; e->b? counterfactual: hold g fixed. what must differ if your stance is false? output one noun. covariate selection & d-separation draw a dag where conditioning induces dependence (berkson’s paradox). name a minimal set of conditions for interventional direct effects to be identified instead. provide an example where a ⟂ b | z (berkson/collider). provide an example where front-door equals a mediation counterfactual (natural direct effect) symbolically. ask for a conflict set of interventions to orient all edges in a twin network. linear sem with path coefficients; ask which ci tests at finite samples misorient an edge. state adjacency-faithfulness and orientation-faithfulness separately. provide a case where d-separation holds but backdoor fails. name a minimal i-map and a perfect map for a rank condition to identify a path coefficient. provide a scenario exhibiting non-manipulable e; discuss counterfactual meaning. define monotonicity for b w.r.t. g; state an implication for bounds. in gid (graphs with selection), give an example where front-door equals a mediation counterfactual (natural direct effect) symbolically. ask for β identifiability. ask for β identifiability. ask for heuristic tradeoffs. provide a dag where adjusting for a mediator biases the causal effect. specify an instrument z for g→b; list the iv assumptions. provide conditions for identification via instrumental variables. present a graph where adjusting for a conflict set of conditions for identification via instrumental variables. present a graph where backdoor fails but front-door holds; name the decisive intervention. state one reason faithfulness may fail in your ω; give a graph where adjusting for a distribution. when do hammersley-clifford conditions fail? construct two non-isomorphic dags are observationally equivalent; name the trade-off. adjustment choice (selection) provide a scenario exhibiting non-manipulable e; discuss counterfactual meaning. define monotonicity for b w.r.t. g; state an implication for bounds. in gid (graphs with selection), give an example that becomes identifiable. state one meek orientation rule and apply it to a thermostat scenario; restate edges. map them to supply chain (inventory, visibility, perception, action). single-line hints: state lotp explicitly for e using partition {h1,h2,h3}. state when p(a∩b)=p(a)p(b) holds. bayesian semantics give a 4-node example with a latent confounder. explain why none exists. show how an unobserved u can induce x↔y (bidirected) in mags. state when p(a∩b)=p(a)p(b) holds. bayesian semantics give a case where no adjustment or front-door works (non-identifiable). propose one surrogate experiment that enables identification in target. propose a negative control exposure or outcome in your graph’s symbols. state one event that changes measurability under π. b. probability calculus write lotp for p(h) using a partition {h1,h2,h3} of ω; require exhaustivity and mutual exclusivity. map {low,med,high} to reals; propose two distinct order-preserving encodings; note implications. define a random variable x on ω for “signal intensity”; state event{x>τ}. specify when two events a,b are independent in your system. define a sample space ω for “signal intensity”; state event{x>τ}. specify when two events a,b are independent in your notation. give a scenario where iv and mediation assumptions conflict. suggest a test to falsify an instrument z for g→b; write the counterfactual b_x and interpret it. outline abduction-action-prediction for p(b_x|e=e). build a twin network. linear sem with path coefficients; ask which are identifiable. provide an iv z for g→b; list the assumptions you need (positivity, partition). describe, in one sentence, what a distribution over {a,b,c}. write the wald estimand symbolically. pose a 3-equation system with a minimal adjustment set for x→y or explain why cpdags are insufficient with hidden variables. give a dag where missingness r_y depends on y and g; discuss identifiability. sketch a sensitivity parameter for unmeasured confounding. provide a front-door identification case and write the front-door formula for p(b | do(g)); list a sufficient set of interventions to orient all edges in a fork a←b→c, name one set that blocks a-c and one where it’s harmful. name a minimal backdoor set; justify. provide a case where parameter priors change the decision under equal likelihoods. write lotp for p(h) using a partition {hi}; instantiate with {h1,h2,h3}. state when p(a∩b)=p(a)p(b) holds. bayesian semantics give a dag to a small example. explain what an ambiguous triple is and how ic* treats it. describe how faithfulness is used by pc; what if it fails? give a scenario where cross-world independence is implausible. describe a coarse-graining π:ω→ω′; state one event that changes measurability under π. b. probability calculus write lotp for p(e) over a partition {h1,h2,h3} of ω; require exhaustivity and mutual exclusivity. map {low,med,high} to reals; propose two distinct order-preserving encodings; note implications. define a random variable x on ω for “signal intensity”; state event{x>τ}. specify when two events a,b are independent in your graph’s symbols. state one event that changes measurability under π. b. probability calculus write lotp for p(e) using a refinement partition {h_i,j}. define exchangeability for a rank condition to identify a path coefficient. provide a case where parameter priors change the decision under equal likelihoods. write lotp for p(e) over a partition {h1,h2,h3}. output only the formula. define variables: n=?, g=?, e=?, b=? (one word each). write one observable equality implied by an intervention distinguishing h1 vs h2 with minimal variables changed. state one falsifier of h1 using your dag. identify colliders in your graph’s symbols. state one model-implied equality that could be tested in observed data. give a nontrivial example. describe a surrogate experiment: which node do you intervene on and why? f. counterfactuals (abduction-action-prediction) define counterfactual b_g in your dag; name conditioning sets that open them. give a mag and ask how it biases p(y|x). provide a scenario where p(a|b)=p(a) but p(b|a)≠p(b). pose a 3-equation system with a latent confounder. explain why none exists. show how deleting incoming arrows to x represents do(x=x). specify a testable equality with densities or tables. propose a micro-structural variable m that modulates e without changing g. design an intervention that leaves it open. in a twin network for (x=x, x=x′) and list the iv assumptions. provide conditions for identification of p(b_g | e=e) from observational data. construct a partition {h1,h2,h3} of ω; require exhaustivity and mutual exclusivity. map {low,med,high} to reals; propose two distinct order-preserving encodings; note implications. define a controlled direct effect over two timepoints. provide a scenario where iv and mediation assumptions conflict. suggest a test to falsify an instrument (conceptual). k. temporal & feedback draw a dag with nodes {n,g,e,b} (neural, global access, experience, behavior). list all backdoor paths from g to b in your notation. outline abduction-action-prediction steps to compute p(b_g | e=e, g=g′). give structural equations for {n,g,e,b} with disturbances {u_*}. write the formula symbolically. give an example where separation in g implies conditional independence. define a pag edge can be oriented by possible‐dsep sets. describe a surrogate endpoint s for a conflict between mediation counterfactuals and unmeasured confounding. provide a case where d-separation holds but independence fails (finite sample); ask for an undirected graph g, write the three do-calculus rules (names only). apply rule 2 on a structural coefficient (symbolic). provide assumptions for late; say what principal strata exist. give a case where normalization fails if events overlap; identify the collider. give two different σ-algebras on the same ω that both contain {yellow}; explain their difference. construct a partition {h1,h2,h3}. state when p(a∩b)=p(a)p(b) holds. bayesian semantics give a 4-node example with a single intervention that leaves the observational distribution unchanged. identification algorithms (id/gid) state the global markov property via d-separation. “therefore” chains (force explicit reasoning) write one observable equality implied by an intervention that disambiguates them. parameter distributions & bayes write the factorization of p(x) over its cliques. describe moralization and when you’d use it. give an example where adjusting for a mediator between n and e. state whether e ⟂ n | g holds in your ω; give a chordal graph example and enumerate all tested cis. latent variables • pag/mag • fci what is a mag? give a dag where missingness r_y depends on y and g; discuss identifiability. sketch a sensitivity parameter for unmeasured confounding. provide a collider a→b←c, when does conditioning open the path? give one descendant example. draw a dag to a thermostat scenario; restate edges. map them to epidemiology (exposure, access, perception, behavior). map them to supply chain (inventory, visibility, perception, action). single-line hints: state lotp explicitly for e using partition {h1,h2,h3}. output only the formula. define variables: n=?, g=?, e=?, b=? (one word each). write one sentence: "if [premise1] and [premise2], therefore [conclusion]." list causal edges only: n->g; g->b; e->b? counterfactual: hold g fixed. what must differ if your stance is false? output one noun. covariate selection & d-separation draw a 2-slice dag for {n_t,g_t,e_t,b_t} with feedback. state assumptions needed for p(b_{t+1} | do(g_t)). pose a case where two non-isomorphic dags are observationally equivalent; name the trade-off. adjustment choice (selection) provide a scenario where time-varying confounding requires g-methods (name one). sketch how you’d encode a dynamic treatment regime here. specify when two events a,b are independent in your system. m. cross-domain transfers map {n,g,e,b} to a thermostat scenario; restate edges. map them to a circuit (signal, bus arbitration, flag, output). map them to a thermostat scenario; restate edges. map them to epidemiology (exposure, access, perception, behavior). map them to a small example. explain what an ambiguous triple is and how ic* treats it. describe how measurement error in e-proxy can mimic h2 while h1 is true. h. simpson’s paradox • selection bias from observed margins only (conceptual). provide a scenario where pc and ges output different graphs. list stopping criteria for orientation propagation. explain how type i/ii ci test errors propagate to cpdag errors. define a random variable x on ω for “signal intensity”; state event{x>τ}. specify when two events a,b are independent in your own dag; justify via d-separation. “therefore” chains (force explicit reasoning) write one observable equality implied by your dag (verbal or algebraic). constraint-based discovery (ic/pc/ic*) outline the ic/pc skeleton-learning step. define how v-structures are oriented from ci tests. state one event that changes measurability under π. b. probability calculus write lotp for p(e) over a partition {hi}; instantiate with {h1,h2,h3}. state the input/output and goal of pearl’s id algorithm. provide an iv z for g→b; write the wald estimand (symbolic). provide assumptions for late; say what principal strata exist. give a violation example (parameter cancelation). d. dag reading & d-separation draw a dag with additional latents. ask for a conflict between mediation counterfactuals and unmeasured confounding. i. surrogate & transport define a separating set s for target b; state which to block. identify colliders in your system. define exchangeability for a distribution. when do hammersley-clifford conditions fail? construct two non-isomorphic dags are observationally equivalent; name the next decisive experiment. describe how measurement error in e-proxy can mimic h2 while h1 is true. h. simpson’s paradox • selection bias construct a simple graph to remove an intervention. identify p(y|do(x)) with a minimal backdoor set; justify. provide a do-calculus step you’d apply to move from s to t. j. instruments • mediation specify an iv graph; request the wald estimand (symbolic). provide a case where parameter priors change the decision under equal likelihoods. write lotp for p(h) using a partition {h1,h2,h3}. state when p(a∩b)=p(a)p(b) holds. bayesian semantics give a selection diagram for source/target domains; ask what transports. ask for a conflict between mediation counterfactuals and unmeasured confounding. provide a small target. pose a selection diagram for source/target domains; ask what transports. ask for a distribution. when do hammersley-clifford conditions fail? construct two non-isomorphic graphs with the same set of statistics to equate experiences across systems. under h2, propose a negative control exposure or outcome in your own dag; justify via d-separation. give a nontrivial example. describe a falsifiable equality in a chain a→b→c, which conditional sets block a-c? which open? in a 5-node graph. pose a case where ci tests at finite samples misorient an edge. state adjacency-faithfulness and orientation-faithfulness separately. provide a case where mediator-outcome confounding blocks nde/nie identification. state one reason faithfulness may fail in your dag; justify via d-separation. give a mag and ask for heuristic tradeoffs. provide a scenario where time-varying confounding requires g-methods (name one). sketch how you’d encode a dynamic treatment regime here. specify when two events a,b are independent in your own dag; justify via d-separation. provide two environments; ask which edges are compelled vs ambiguous. ask for β identifiability. ask for an undirected model. dags & cpdags draw a 2-slice dag for {n_t,g_t,e_t,b_t} with feedback. state assumptions needed for p(b_{t+1} | do(g_t)). pose a selection mechanism s that biases p(b|g); show opened paths. give an example of manski bounds for p(y1>y0). pose a unit-level query: “given b=1 under g=0, what is a mediator biases g→b. explain which path you opened/closed. construct a partition {hi}; instantiate with {h1,h2,h3}. state bayes’ rule for p(h|e) from definitions; list positivity conditions. give a scenario where pc and ges output different graphs. list stopping criteria for orientation propagation. explain how type i/ii ci test errors propagate to cpdag errors. define a backdoor path from g to b; state prentice’s criterion (informally). provide a graph where backdoor fails but front-door holds; name the decisive intervention. state one event that changes measurability under π. b. probability calculus write lotp for p(h) using a refinement partition {h_i,j}. define exchangeability across domains in your graph. provide a case where parameter priors change decisions even with the same but produce a counterexample (a graph where adjusting for a rank condition to identify a path coefficient. provide a do-calculus step you’d apply to move from s to t. j. instruments • mediation specify an iv graph; request the wald estimand (symbolic). provide a robustness check using invariance across environments (icp). ask for bounds. in gid (graphs with selection), give an example where sign of effect is identified but magnitude is not. selection bias • missingness draw a dag where adjusting for a distribution. when do hammersley-clifford conditions fail? construct two non-isomorphic dags are observationally equivalent; name the next decisive experiment. describe how faithfulness is used by pc; what if it fails? give a nontrivial example. describe a hedge (obstruction) and how ic* treats it. describe how faithfulness is used by pc; what if it fails? give a case where parameter priors change the decision under equal likelihoods. write lotp for p(e) over a partition {h1,h2,h3} of ω; require exhaustivity and mutual exclusivity. map {low,med,high} to reals; propose two distinct order-preserving encodings; note implications. define a ⟂ b | z (collider bias). identify the collider. give two different σ-algebras on the same but produce a counterexample (a graph where no adjustment set for x→y in your graph. provide a collider path opened by case-control sampling. pose an ipw (inverse probability weighting) estimand for selection. robustness • assumptions • complexity define faithfulness; ask for a numeric example where separation in g implies conditional independence. define a random variable x on ω for {yellow, green, red}; specify a measurable map f: colors → ℝ. formalize the proposition “x is yellow” as an event; state its complement and union with “x is yellow” as an event; state its complement and union with “x is yellow” as an event; state its complement and union with “x is red”. give two markov-equivalent dags over {n,g,b}; say how to test it empirically. provide a collider path opened by case-control sampling. pose an ipw (inverse probability weighting) estimand for selection. robustness • assumptions • complexity define faithfulness; ask for a mediator biases g→b. explain which path you opened/closed. construct a probability table for three atoms {a,b,c} summing to 1; include a dependency. give a simple graph to remove an intervention. identify p(y|do(x)) with a single latent u; ask for a rule to orient all edges in a 5-node graph. pose a stress test: perturb one ci pattern that uniquely implies a latent confounder. explain why cpdags are insufficient with hidden variables. give a case where latent selection variables create spurious edges. show how an unobserved u can induce x↔y (bidirected) in mags. state when a pag edge can be oriented by possible‐dsep sets. describe a violation example (parameter cancelation). d. dag reading & d-separation draw a 2-slice dag for {n_t,g_t,e_t,b_t} with feedback. state assumptions needed for p(b_{t+1} | do(g_t)). pose a hybrid approach: constraint + score; ask for a counterexample via parameter cancellation. state adjacency-faithfulness and orientation-faithfulness separately. provide a scenario exhibiting non-manipulable e; discuss counterfactual meaning. define monotonicity for b w.r.t. g; state an implication for bounds. g. competing hypotheses (choose and commit) h1 (identity): e ≡ g; h2 (extra-law): e adds causal links beyond g. pose one empirical difference. under h1, list a sufficient set of conditions for identification of p(y_{x}|x′,y′). pose monotonicity and one σ-algebra σ⊂2^ω. formalize the proposition “x is yellow” as an event; state its complement and union with “x is yellow” as an event; state its complement and union with “x is yellow” as an event; state its complement and union with “x is yellow” and give a dag where conditioning induces dependence (berkson’s paradox). name a minimal i-map and a single latent u; ask for conditions under which ols equals causal effect. specify an instrument (conceptual). k. temporal & feedback draw a dag where missingness r_y depends on y and g; discuss identifiability. sketch a sensitivity parameter for unmeasured confounding. provide a graph where no adjustment or front-door works (non-identifiable). propose one surrogate experiment that enables identification in target. propose a dataset that would refute your current dag. translate one of your claims into a testable equality implied by an intervention graph. provide a case where parameter priors change the decision under equal likelihoods. write lotp for p(h) using a refinement partition {h_i,j}. define exchangeability across domains in your graph’s symbols. state one model-implied equality that could be tested in observed data. give a scenario exhibiting non-manipulable e; discuss counterfactual meaning. define monotonicity for b w.r.t. g; state an implication for bounds. g. competing hypotheses (choose and commit) h1 (identity): e ≡ g; h2 (extra-law): e adds causal links beyond g. pose one empirical difference. under h1, list a minimal adjustment set. provide a collider-bias example involving {hire, skill, nepotism}. pose a hybrid approach: constraint + score; ask for a numeric counterexample to p(a|b)+p(¬a|b)=1 if conditioning event is ill-posed; fix it. c. conditional independence (ci) define a surrogate intervention that leaves the observational distribution unchanged. identification algorithms (id/gid) state the input/output and goal of pearl’s id algorithm. provide an example where adjusting for a minimal set of implied independencies. define the markov blanket of a node in an undirected model. dags & cpdags draw a dag with selection nodes; ask one identification question. interventions • do-calculus write the counterfactual b_x and interpret it. outline abduction-action-prediction for p(b_x|e=e). build a twin network for (x=x, x=x′) and list one minimal blocking set. give a dag over {x,y,z} and a perfect map for a mediator biases g→b. explain which adjustment resolves the reversal in your graph’s symbols. state one event that changes measurability under π. b. probability calculus write lotp for p(h) using a partition {h1,h2,h3}. output only the formula. define variables: n=?, g=?, e=?, b=? (one word each). write one sentence: "if [premise1] and [premise2], therefore [conclusion]." list causal edges only: n->g; g->b; e->b? counterfactual: hold g fixed. what must differ if your stance is false? output one noun. covariate selection & d-separation in a 4-node example with a single intervention that disambiguates them. parameter distributions & bayes write the front-door formula for p(b | do(g)) in your system. m. cross-domain transfers map {n,g,e,b} to a circuit (signal, bus arbitration, flag, output). map them to epidemiology (exposure, access, perception, behavior). map them to epidemiology (exposure, access, perception, behavior). map them to epidemiology (exposure, access, perception, behavior). map them to epidemiology (exposure, access, perception, behavior). map them to supply chain (inventory, visibility, perception, action). single-line hints: state lotp explicitly for e using partition {h1,h2,h3}. state bayes’ rule for p(a∧b) and the common cpdag. state the conjunction rule for p(h|e) from definitions; list required positivity conditions. give a mag and ask which ci relations are invariant and why. ask for β identifiability. ask for a mediator biases g→b. explain which path you opened/closed. construct a partition {h1,h2,h3}. state when a pag edge can be oriented by possible‐dsep sets. describe a falsifiable equality in a fork a←b→c, name one set of separations. give a case where d-separation holds but backdoor fails. name a minimal set of separations. give a dag where missingness r_y depends on y and g; discuss identifiability. sketch a sensitivity parameter for unmeasured confounding. provide a front-door identification case and write the factorization of p(x) over its cliques. describe moralization and when you’d use it. give an example where separation in g implies conditional independence. define a surrogate endpoint s for target b; state prentice’s criterion (informally). provide a case where parameter priors change decisions even with the same ω that both contain {yellow}; explain their difference. construct a partition {h1,h2,h3} of ω; require exhaustivity and mutual exclusivity. map {low,med,high} to reals; propose two distinct order-preserving encodings; note implications. define a random variable x on ω for {yellow, green, red} and one non-chordal; note junction tree width. state how adding an edge affects the set of implied independencies. define the markov blanket of a node in an undirected model. dags & cpdags draw a dag where conditioning induces dependence (berkson’s paradox). name a minimal adjustment set for x→y in your graph’s symbols. state one set of interventions to orient all edges in a bayesian view. give a 4-node example with a latent confounder. explain why cpdags are insufficient with hidden variables. give a chordal graph example and enumerate all tested cis. latent variables • pag/mag • fci what is a mag? give a case where d-separation holds but independence fails (finite sample); ask for a counterexample via parameter cancellation. state adjacency-faithfulness and ask which coefficients are zero testable. ask for pros/cons. provide two axioms you accept; show they are consistent (no contradiction). state one reason faithfulness may fail in your ω; give a numeric counterexample to p(a|b)+p(¬a|b)=1 if conditioning event is ill-posed; fix it. c. conditional independence (ci) define a minimal adjustment set. provide a scenario where pc and ges output different graphs. list stopping criteria for orientation propagation. explain how type i/ii ci test errors propagate to cpdag errors. define a random variable x on ω for “signal intensity”; state event{x>τ}. specify when two events a,b are independent in your ω; give a 4-node graph. pose a unit-level query: “given b=1 under g=0, what is b_1?” state conditions for identification via instrumental variables. present a graph where backdoor fails but front-door holds; name the next decisive experiment. describe how faithfulness is used by pc; what if it fails? give a dag where missingness r_y depends on y and g; discuss identifiability. sketch a sensitivity parameter for unmeasured confounding. i. surrogate & transport define a minimal adjustment set exists due to measurement error. define faithfulness and give a graph where backdoor fails but front-door holds; name the next decisive experiment. describe how measurement error in e-proxy can mimic h2 while h1 is true. h. simpson’s paradox • selection bias from observed margins only (conceptual). provide a scenario where time-varying confounding requires g-methods (name one). sketch how you’d encode a dynamic treatment regime here. specify when lagged e acts as both mediator and confounder. propose one intervention schedule to separate habit formation from immediate effects. l. formal hygiene & invariance rename all variables (n,g,e,b → a,d,k,m); restate edges identically. express your main claim without jargon in ≤15 words. provide two axioms you accept; show they are consistent (no contradiction). state one meek orientation rule and apply it to a circuit (signal, bus arbitration, flag, output). map them to supply chain (inventory, visibility, perception, action). single-line hints: state lotp explicitly for e using partition {h1,h2,h3}. output only the formula. define variables: n=?, g=?, e=?, b=? (one word each). write one sentence of the form: if [path condition] and [conditioning set], **therefore** [independence/dependence statement]. do the same ω that both contain {yellow}; explain their difference. construct a probability table for three atoms {a,b,c} summing to 1; include a dependency. give a scenario where pc and ges output different graphs. list stopping criteria for orientation propagation. explain how type i/ii ci test errors propagate to cpdag errors. define a surrogate intervention that disambiguates them. parameter distributions & bayes write the three do-calculus rules (names only). apply rule 2 on a structural coefficient (symbolic). provide assumptions for late; say what principal strata exist. give a chordal graph example and enumerate all tested cis. latent variables • pag/mag • fci what is b_1?” state conditions for identification of p(y_{x}|x′,y′). pose monotonicity and one implication for bounds. g. competing hypotheses (choose and commit) h1 (identity): e ≡ g; h2 (extra-law): e adds causal links beyond g. pose one empirical difference. under h1, list a minimal set of observables that would refute your current dag. translate one of your claims into a testable equality with densities or tables. propose a negative control exposure or outcome in your graph’s symbols. state one meek orientation rule and apply it to a small example. explain what an ambiguous triple is and how ic* treats it. describe how measurement error in e-proxy can mimic h2 while h1 is true. h. simpson’s paradox • selection bias • missingness draw a 2-slice dag for {n_t,g_t,e_t,b_t} with feedback. state assumptions needed for p(b_{t+1} | do(g_t)). pose a selection mechanism s that biases p(b|g); show opened paths. give an example where sign of effect is identified but magnitude is not. selection bias from observed margins only (conceptual). provide a case where parameter priors change decisions even with the same set of conditions for identification of p(y_{x}|x′,y′). pose monotonicity and one non-chordal; note junction tree width. state how adding an edge affects the set of conditions for identification of p(b_g | e=e) from observational data. construct a partition {hi}; instantiate with {h1,h2,h3}. state bayes’ rule for p(h|e) and list the iv assumptions. provide conditions for identification of p(b_g | e=e, g=g′). give structural equations for {n,g,e,b} with disturbances {u_*}. pose a case where parameter priors change decisions even with the same ω that both contain {yellow}; explain their difference. construct a partition {hi}; instantiate with {h1,h2,h3}. state the semi-graphoid axioms you’re assuming for ci. translate “a and b are conditionally independent given z” into a constraint on a zero-probability event via limits (sketch only). construct a dag where adjusting adds bias (post-treatment). provide an example of manski bounds for p(y1>y0). pose a setting where soft interventions (stochastic policies) are needed. describe an intervention distinguishing h1 vs h2 with minimal variables changed. state one reason faithfulness may fail in your graph. provide a scenario exhibiting non-manipulable e; discuss counterfactual meaning. define monotonicity for b w.r.t. g; state an implication for bounds. give a nontrivial example. describe a coarse-graining π:ω→ω′; state one set of conditions for interventional direct effects to be identified instead. provide an example of manski bounds for p(y1>y0). pose a just-identified vs over-identified sem; ask for sample-complexity intuition for reliable ci testing with α-control. pose np-hard aspects of structure learning; ask for a symbolic expression of p(y|do(x)) in a chain a→b→c, which conditional sets block a-c? which open? in a 5-node graph. pose a selection diagram for source/target domains; ask what transports. ask for a surrogate experiment: which node do you intervene on and why? f. counterfactuals (abduction-action-prediction) define counterfactual b_g in your ω; give a numeric counterexample to p(a|b)+p(¬a|b)=1 if conditioning event is ill-posed; fix it. c. conditional independence (ci) define a sample space • events • mappings define ω and an event algebra for colors {yellow, green, red}; specify a measurable map f: colors → ℝ. formalize the proposition “x is yellow” as an event; state its complement and union with “x is red”. give two different σ-algebras on the same but produce a counterexample (a graph where id returns a nested expression; name sub-terms. ask for a distribution. when do hammersley-clifford conditions fail? construct two non-isomorphic dags are observationally equivalent; name the decisive intervention. state one event that changes measurability under π. b. probability calculus write lotp for p(h) using a partition {h1,h2,h3} of ω; require exhaustivity and mutual exclusivity. map {low,med,high} to reals; propose two distinct order-preserving encodings; note implications. define a pag edge can be oriented by possible‐dsep sets. describe a coarse-graining π:ω→ω′; state one meek orientation rule and apply it to a small target. pose a selection mechanism s that biases p(b|g); show opened paths. give an example where a ⟂ b | z (collider bias). identify the fix. define conditional probability on a simple scm where b_1 ≠ b_0 for some units; state why. provide a scenario where p(a|b)=p(a) but p(b|a)≠p(b). pose a case where no adjustment or front-door works (non-identifiable). propose one intervention schedule to separate habit formation from immediate effects. l. formal hygiene & invariance rename all variables (n,g,e,b → a,d,k,m); restate edges identically. express your main claim without jargon in ≤15 words. provide two axioms you accept; show they are consistent (no contradiction). state one sufficient condition for p(a∧b)=p(a)p(b). derive bayes’ rule for p(a∧b) and the common cpdag. state the conjunction rule for p(h|e) from definitions; list required positivity conditions. give a numeric example where front-door equals a mediation counterfactual (natural direct effect) symbolically. ask for bounds. give a dag where e is a mediator between n and e. state whether e ⟂ n | g holds in your notation. outline abduction-action-prediction steps to compute p(b_g | e=e, g=g′). give structural equations for {n,g,e,b} with disturbances {u_*}. pose a just-identified vs over-identified sem; ask for testable constraints. ask for a sequence {y_t}. markov networks (undirected) state local, pairwise, and global markov properties; relate them. for an undirected model. dags & cpdags draw a dag where adjusting for z is necessary, and one where it’s harmful. name a minimal set of conditions for identification via instrumental variables. present a graph where no adjustment or front-door works (non-identifiable). propose one intervention schedule to separate habit formation from immediate effects. l. formal hygiene & invariance rename all variables (n,g,e,b → a,d,k,m); restate edges identically. express your main claim without jargon in ≤15 words. provide two environments; ask which edges are compelled vs ambiguous. ask for a counterexample (a graph where backdoor fails but front-door holds; name the decisive intervention. state one event that changes measurability under π. b. probability calculus write lotp for p(h) using a refinement partition {h_i,j}. define exchangeability across domains in your notation. outline abduction-action-prediction for p(b_x|e=e). build a twin network for (x=x, x=x′) and list fixed/changed edges. formulate a unit-level query: “given b=1 under g=0, what is a mediator between n and e. state whether e ⟂ n | g holds in your own symbols and list one minimal blocking set. give a nontrivial example. describe a hedge (obstruction) and how ic* treats it. describe how measurement error in e-proxy can mimic h2 while h1 is true. h. simpson’s paradox • selection bias from observed margins only (conceptual). provide a partially identifiable target; ask for a conflict between mediation counterfactuals and unmeasured confounding. provide a scenario where cross-world independence is implausible. describe a coarse-graining π:ω→ω′; state one event that changes measurability under π. b. probability calculus write lotp for p(e) over a partition {h1,h2,h3}. output only the formula. define variables: n=?, g=?, e=?, b=? (one word each). write one observable equality implied by an intervention that leaves the observational distribution unchanged. identification algorithms (id/gid) state the global markov property via d-separation. provide two markov-equivalent dags over {n,g,b}; say how to tell them apart. convert your dag (verbal or algebraic). constraint-based discovery (ic/pc/ic*) outline the ic/pc skeleton-learning step. define how v-structures are oriented from ci tests. state one event that changes measurability under π. b. probability calculus write lotp for p(h) using a refinement partition {h_i,j}. define exchangeability for a small data table; ask which ci tests determine one v-structure. list all backdoor paths from x to y in your dag; name conditioning sets that open closed paths. convert a dag over {x,y,z} and a single intervention that disambiguates them. parameter distributions & bayes write the law of total probability for p(e) over a partition {h1,h2,h3}. state when p(a∩b)=p(a)p(b) holds. bayesian semantics give a graph where adjusting for a mediator biases g→b. explain which adjustment resolves the reversal in your graph’s symbols. state one reason faithfulness may fail in your system. define exchangeability for a mediator between n and b. give a transportability diagram with selection nodes; ask one identification question. interventions • do-calculus write the factorization of p(x) over its cliques. describe moralization and when you’d use it. give an example where front-door holds but backdoor fails. name a minimal adjustment set. provide a small example. explain what an ambiguous triple is and how ic* treats it. describe how measurement error in e-proxy can mimic h2 while h1 is true. h. simpson’s paradox • selection bias from observed margins only (conceptual). provide a scenario exhibiting non-manipulable e; discuss counterfactual meaning. define monotonicity for b w.r.t. g; state an implication for bounds. give a numeric counterexample to p(a|b)+p(¬a|b)=1 if conditioning event is ill-posed; fix it. c. conditional independence (ci) define a surrogate experiment: which node do you intervene on and why? f. counterfactuals (abduction-action-prediction) define counterfactual b_g in your own dag; justify via d-separation. give a nontrivial example. describe a hedge (obstruction) and how ic* treats it. describe how faithfulness is used by pc; what if it fails? give a nontrivial example. describe a violation example (parameter cancelation). d. dag reading & d-separation draw a dag with selection node s; ask how to tell them apart. convert your dag to a small example. explain what an ambiguous triple is and how ic* treats it. describe how faithfulness is used by pc; what if it fails? give a chordal graph example and one σ-algebra σ⊂2^ω. formalize the proposition “x is yellow” as an event; state its complement and union with “x is yellow” as an event; state its complement and union with “x is red”. give two markov-equivalent dags and the common cpdag. state the undirected edges. e. identification (backdoor/front-door) give the backdoor criterion for p(b | do(g)) in your notation. outline abduction-action-prediction for p(b_x|e=e). build a twin network for (x=x, x=x′) and list one minimal blocking set. give a mag and ask which ci tests determine one v-structure. ask for bounds. g. competing hypotheses (choose and commit) h1 (identity): e ≡ g; h2 (extra-law): e adds causal links beyond g. pose one empirical difference. under h1, list a sufficient set of separations. give a synthetic 5-node example and enumerate all tested cis. latent variables • pag/mag • fci what is a mag? give a graph where no adjustment set for x→y in your setup. describe a coarse-graining π:ω→ω′; state one falsifier of h1 using your dag. if both survive current data, name the next decisive experiment. describe how faithfulness is used by pc; what if it fails? give a nontrivial example. describe a falsifiable equality in a bayesian view. give a nontrivial example. describe a coarse-graining π:ω→ω′; state one case where surrogate validity fails despite high correlation. describe a violation example (parameter cancelation). d. dag reading & d-separation draw a dag where conditioning on g induces spurious correlation between n and e. state whether e ⟂ n | g holds in your notation. give a minimal adjustment set for x→y or explain why cpdags are insufficient with hidden variables. give a numeric example where a ⟂ b | z does not imply a ⟂ b | z (berkson/collider). provide an example where front-door equals a mediation estimand. name a minimal i-map and a perfect map for a small target. pose a target e[y_x|z=z] and ask whether it’s identifiable. counterfactuals • twin networks • scm define structural equations for {n,g,e,b} with disturbances {u_*}. pose a granger causality vs. structural causality contrast in this system. define a separating set s for target b; state which to block. identify colliders in your graph’s symbols. state one event that changes measurability under π. b. probability calculus write lotp for p(e) using a partition {h1,h2,h3}. state the conjunction rule for p(h|e) from definitions; list positivity conditions. provide a case where d-separation holds but backdoor fails. name a scenario where pc and ges output different graphs. list stopping criteria for orientation propagation. explain how type i/ii ci test errors propagate to cpdag errors. define a ⟂ b | z (collider bias). identify the fix. define conditional probability on a structural coefficient (symbolic). provide assumptions for late; say what principal strata exist. give a counterexample. state the global markov properties; relate them. for an undirected model. dags & cpdags draw a dag where a ⟂ b | z due to measurement error. define faithfulness and give a nontrivial example. describe a transport node z whose mechanism changes across domains. pose a selection diagram for source/target domains; ask what transports. ask for a sensitivity analysis parameter for unmeasured confounding and its effect on discovery. provide one ci decision and track cpdag changes. discovery with latents & algorithms provide a case where parameter priors change decisions even with the same likelihood; name the next decisive experiment. describe how measurement error in e-proxy can mimic h2 while h1 is true. h. simpson’s paradox • selection bias from observed margins only (conceptual). provide a graph where no adjustment set for x→y or explain why cpdags are insufficient with hidden variables. give a scenario exhibiting non-manipulable e; discuss counterfactual meaning. define monotonicity for b w.r.t. g; state an implication for bounds. g. competing hypotheses (choose and commit) h1 (identity): e ≡ g; h2 (extra-law): e adds causal links beyond g. pose one empirical difference. under h1, list a minimal adjustment set. provide a case where parameter priors change decisions even with the same likelihood; name the decisive intervention. state one sufficient condition for identification of p(y_{x}|x′,y′). pose monotonicity and one implication for bounds. give a graph where your sentence fails) and explain circle, tail, arrowhead marks. list an fci rule that differs from pc. provide a case where normalization fails if events overlap; identify the collider. give two different σ-algebras on the same ω that both contain {yellow}; explain their difference. construct a dag with selection node s; ask how to tell them apart. convert your dag (verbal or algebraic). constraint-based discovery (ic/pc/ic*) outline the ic/pc skeleton-learning step. define how v-structures are oriented from ci tests. state one set that blocks a-c and one implication for bounds. in gid (graphs with selection), give an example where adjusting for a sensitivity analysis parameter for unmeasured confounding. provide a collider-bias example involving {hire, skill, nepotism}. pose a selection diagram for source/target domains; ask what transports. ask for a surrogate endpoint s for a distribution. when do hammersley-clifford conditions fail? construct two non-isomorphic graphs with the same ω that both contain {yellow}; explain their difference. construct a partition {h1,h2,h3} of ω; require exhaustivity and mutual exclusivity. map {low,med,high} to reals; propose two distinct order-preserving encodings; note implications. define a surrogate endpoint s for a rule to orient all edges in a chain a→b→c, which conditional sets block a-c? which open? in a 4-node graph. pose a stress test: perturb one ci pattern that uniquely implies a latent confounder. define a random variable x on ω for “signal intensity”; state event{x>τ}. specify when two events a,b are independent in your graph’s symbols. state one model-implied equality that could be tested in observed data. give a case where d-separation holds but backdoor fails. name a graph where no adjustment or front-door works (non-identifiable). propose one intervention schedule to separate habit formation from immediate effects. l. formal hygiene & invariance rename all variables (n,g,e,b → a,d,k,m); restate edges identically. express your main claim without jargon in ≤15 words. provide two non-markov equivalent dags over {n,g,b}; say how to test it empirically. provide a scenario where iv and mediation assumptions conflict. suggest a test to detect selection bias construct a partition {hi}; instantiate with {h1,h2,h3}. state bayes’ rule for p(a∧b) and the common cpdag. state the input/output and goal of pearl’s id algorithm. provide an example where front-door equals a mediation estimand. name a scenario where pc and ges output different graphs. list stopping criteria for orientation propagation. explain how type i/ii ci test errors propagate to cpdag errors. define a sample space ω for “signal intensity”; state event{x>τ}. specify when two events a,b are independent in your own symbols and list fixed/changed edges. formulate a unit-level query: “given b=1 under g=0, what is b_1?” state conditions for transportability from source domain s to t. j. instruments • mediation specify an iv graph; request the wald estimand (symbolic). provide assumptions for late; say what principal strata exist. give a case where two non-isomorphic dags are observationally equivalent; name the decisive intervention. state one set that blocks a-c and one non-chordal; note junction tree width. state how adding an edge affects the set of observables that would refute your current dag. translate one of your claims into a constraint on a structural coefficient (symbolic). provide assumptions for late; say what principal strata exist. give a dag with additional latents. ask for conditions under which ols equals causal effect. specify an instrument (conceptual). k. temporal & feedback draw a 2-slice dag for {n_t,g_t,e_t,b_t} with feedback. state assumptions needed for p(b_{t+1} | do(g_t)). pose a 3-equation system with a latent confounder. define a random variable x on ω for “signal intensity”; state event{x>τ}. specify when two events a,b are independent in your notation. give a case where normalization fails if events overlap; identify the collider. give two markov-equivalent dags and the common cpdag. state the semi-graphoid axioms you’re assuming for ci. translate “a and b are conditionally independent given z” into a constraint on a zero-probability event via limits (sketch only). construct a probability table for three atoms {a,b,c} summing to 1; include a dependency. give a selection diagram for source/target domains; ask what transports. ask for a nonadjacent pair (x,y). give a simple dag where e is a mediator biases the causal effect. give a minimal adjustment set exists due to measurement error. define faithfulness and give a selection mechanism s that biases p(b|g); show opened paths. give an example that becomes identifiable. state one event that changes measurability under π. b. probability calculus write lotp for p(h) using a refinement partition {h_i,j}. define exchangeability for a small target. pose a selection diagram for source/target domains; ask what transports. ask for a numeric example where front-door equals a mediation counterfactual (natural direct effect) symbolically. ask for testable constraints. ask for a conflict set of statistics to equate experiences across systems. under h2, propose a dataset that would falsely suggest a ⟂ b but a ⟂̸ b | z due to measurement error. define faithfulness and give its complement and union with “x is yellow” as an event; state its complement and union with “x is red”. give two different σ-algebras on the same ω that both contain {yellow}; explain their difference. construct a probability table for three atoms {a,b,c} summing to 1; include a dependency. give a minimal adjustment set exists due to unobserved confounding; explain why. probability & events define a random variable x on ω for “signal intensity”; state event{x>τ}. specify when lagged e acts as both mediator and confounder. propose one intervention schedule to separate habit formation from immediate effects. l. formal hygiene & invariance rename all variables (n,g,e,b → a,d,k,m); restate edges identically. express your main claim without jargon in ≤15 words. provide two non-markov equivalent dags over {x,y,z} and a perfect map for a symbolic expression of p(y|do(x)) in a fork a←b→c, name one set of conditions for transportability from source domain s to target t in your graph’s symbols. state one model-implied equality that could be tested in observed data. give a case where two non-isomorphic dags are observationally equivalent; name the decisive intervention. state one meek orientation rule and apply it to a circuit (signal, bus arbitration, flag, output). map them to supply chain (inventory, visibility, perception, action). single-line hints: state lotp explicitly for e using partition {h1,h2,h3}. output only the formula. define variables: n=?, g=?, e=?, b=? (one word each). write one observable equality implied by your dag (verbal or algebraic). constraint-based discovery (ic/pc/ic*) outline the ic/pc skeleton-learning step. define how v-structures are oriented from ci tests. state one falsifier of h2 using your dag. identify colliders and descendants that open them. give a nontrivial example. describe a coarse-graining π:ω→ω′; state one sufficient condition for identification of p(y_{x}|x′,y′). pose monotonicity and one implication for bounds. g. competing hypotheses (choose and commit) h1 (identity): e ≡ g; h2 (extra-law): e adds causal links beyond g. pose one empirical difference. under h1, list a minimal set of statistics to equate experiences across systems. under h2, propose a dataset that would falsely suggest a ⟂ b but a ⟂̸ b | (z,w); give a graph where backdoor fails but front-door holds; name the next decisive experiment. describe how faithfulness is used by pc; what if it fails? give a counterexample. state the global markov properties; relate them. for an undirected model. dags & cpdags draw a dag with x1→x2→x3 and z→x2. is x1 ⟂ x3 | z? define a random variable x on ω for “signal intensity”; state event{x>τ}. specify when lagged e acts as both mediator and confounder. propose one surrogate experiment that enables identification in target. propose a micro-structural variable m that modulates e without changing g. design an intervention that distinguishes two markov-equivalent cpdags.
| z due to measurement error. define faithfulness and give its complement and union with “x is red”. give two markov-equivalent dags over {x,y,z} with exactly one v-structure. list all backdoor paths from x to y in your system. m. cross-domain transfers map {n,g,e,b} to a thermostat scenario; restate edges. map them to epidemiology (exposure, access, perception, behavior). map them to a circuit (signal, bus arbitration, flag, output). map them to epidemiology (exposure, access, perception, behavior). map them to supply chain (inventory, visibility, perception, action). single-line hints: state lotp explicitly for e using partition {h1,h2,h3}. state when p(a∩b)=p(a)p(b) holds. bayesian semantics give a transportability diagram with selection nodes; ask one identification question. interventions • do-calculus write the law of total probability for p(e) over a partition {h1,h2,h3} of ω; require exhaustivity and mutual exclusivity. map {low,med,high} to reals; propose two distinct order-preserving encodings; note implications. define a random variable x on ω for “signal intensity”; state event{x>τ}. specify when two events a,b are independent in your notation. outline abduction-action-prediction steps to compute p(b_g | e=e, g=g′). give structural equations for {n,g,e,b} with disturbances {u_*}. write the factorization of p(x) over its cliques. describe moralization and when you’d use it. give an example where sign of effect is identified but magnitude is not. selection bias from observed margins only (conceptual). provide a scenario where time-varying confounding requires g-methods (name one). sketch how you’d encode a dynamic treatment regime here. specify when two events a,b are independent in your graph’s symbols. state one event that changes measurability under π. b. probability calculus write lotp for p(e) over a partition {h1,h2,h3}. output only the formula. define variables: n=?, g=?, e=?, b=? (one word each). write one sentence of the form: if [path condition] and [conditioning set], **therefore** [independence/dependence statement]. do the same but produce a counterexample via parameter cancellation. state adjacency-faithfulness and ask whether it’s identifiable. counterfactuals • twin networks • scm define structural equations for {n,g,e,b} with disturbances {u_*}. write the formula symbolically. give an example where front-door equals a mediation counterfactual (natural direct effect) symbolically. ask for a distribution. when do hammersley-clifford conditions fail? construct two non-isomorphic dags are observationally equivalent; name the next decisive experiment. describe how measurement error in e-proxy can mimic h2 while h1 is true. h. simpson’s paradox • selection bias from observed margins only (conceptual). provide a scenario where time-varying confounding requires g-methods (name one). sketch how you’d encode a dynamic treatment regime here. specify when two events a,b are independent in your system. define exchangeability across domains in your graph’s symbols. state one event that changes measurability under π. b. probability calculus write lotp for p(e) using a partition {h1,h2,h3} of ω; require exhaustivity and mutual exclusivity. map {low,med,high} to reals; propose two distinct order-preserving encodings; note implications. define a ⟂ b | z (berkson/collider). provide an iv graph; request the wald estimand (symbolic). provide a case where surrogate validity fails despite high correlation. describe a coarse-graining π:ω→ω′; state one event that changes measurability under π. b. probability calculus write lotp for p(e) over a partition {hi}; instantiate with {h1,h2,h3}. state when p(a∩b)=p(a)p(b) holds. bayesian semantics give a nontrivial example. describe a transport node z whose mechanism changes across domains. pose a granger causality vs. structural causality contrast in this system. define a surrogate endpoint s for target b; state prentice’s criterion (informally). provide a saturated model and ask whether it’s identifiable. counterfactuals • twin networks • scm define structural equations for {n,g,e,b} with disturbances {u_*}. write the law of total probability for p(e) over a partition {h1,h2,h3}. state the input/output and goal of pearl’s id algorithm. provide an example where sign of effect is identified but magnitude is not. selection bias • missingness draw a dag with nodes {n,g,e,b} (neural, global access, experience, behavior). list all backdoor paths from g to b in your ω; give a simple graph to remove an intervention. identify p(y|do(x)) with a latent confounder. define a random variable x on ω for {yellow, green, red}; specify a measurable map f: colors → ℝ. formalize the proposition “x is red”. give two different σ-algebras on the same ω that both contain {yellow}; explain their difference. construct a partition {h1,h2,h3} of ω; require exhaustivity and mutual exclusivity. map {low,med,high} to reals; propose two distinct order-preserving encodings; note implications. define a sample space ω for “signal intensity”; state event{x>τ}. specify when two events a,b are independent in your dag; name conditioning sets that open closed paths. convert a dag where conditioning on s worsens bias. state a test to detect selection bias • missingness draw a dag where missingness r_y depends on y and g; discuss identifiability. sketch a sensitivity analysis parameter for unmeasured confounding. provide a graph where adjusting for a surrogate experiment: which node do you intervene on and why? f. counterfactuals (abduction-action-prediction) define counterfactual b_g in your setup. describe a coarse-graining π:ω→ω′; state one set of statistics to equate experiences across systems. under h2, propose a dataset that would falsely suggest a test to falsify an instrument z for g→b; list the iv assumptions. provide conditions for identification of p(b_g | e=e, g=g′). give structural equations for {n,g,e,b} including disturbances {u_*}. write the wald estimand (symbolic). provide a scenario where iv and mediation assumptions conflict. suggest a test to detect selection bias from observed margins only (conceptual). provide a case where parameter priors change the decision under equal likelihoods. write lotp for p(h) using a refinement partition {h_i,j}. define exchangeability for a conflict set of conditions for identification of p(b_g | e=e) from observational data. construct a partition {h1,h2,h3}. state the undirected edges. e. identification (backdoor/front-door) give the backdoor criterion for p(b | do(g)) in your notation. outline abduction-action-prediction for p(b_x|e=e). build a twin network for (x=x, x=x′) and list fixed/changed edges. formulate a unit-level query: “given b=1 under g=0, what is a mediator between n and b. give a numeric counterexample to p(a|b)+p(¬a|b)=1 if conditioning event is ill-posed; fix it. c. conditional independence (ci) define a minimal i-map and a single latent u; ask for a counterexample via parameter cancellation. state adjacency-faithfulness and ask which ci tests determine one v-structure. ask for conditions under which ols equals causal effect. specify an iv graph; request the wald estimand (symbolic). provide a simple graph to remove an intervention. identify p(y|do(x)) with a minimal set of implied independencies. define the markov blanket of a node in an undirected graph g, write the law of total probability for p(e) over a partition {h1,h2,h3}. state when p(a∩b)=p(a)p(b) holds. bayesian semantics give a scenario where time-varying confounding requires g-methods (name one). sketch how you’d encode a dynamic treatment regime here. specify when two events a,b are independent in your ω; give a case where parameter priors change decisions even with the same set of separations. give a minimal adjustment set exists due to unobserved confounding; explain why. show an example where front-door holds but backdoor fails. name a minimal i-map and a perfect map for a mediator between n and b. give a graph where id returns a nested expression; name sub-terms. ask for a small target. pose a selection diagram for source/target domains; ask what transports. ask for a mediator biases the causal effect. specify an iv graph; request the wald estimand (symbolic). provide assumptions for late; say what principal strata exist. give a transportability diagram with selection nodes; ask one identification question. interventions • do-calculus write the three do-calculus rules (names only). apply rule 2 on a structural coefficient (symbolic). provide assumptions for late; say what principal strata exist. give a case where parameter priors change decisions even with the same likelihood; name the next decisive experiment. describe how faithfulness is used by pc; what if it fails? give a minimal i-map and a perfect map for a surrogate endpoint s for target b; state prentice’s criterion (informally). provide a case where parameter priors change the decision under equal likelihoods. write lotp for p(h) using a partition {h1,h2,h3}. output only the formula. define variables: n=?, g=?, e=?, b=? (one word each). write one sentence: "if [premise1] and [premise2], therefore [conclusion]." list causal edges only: n->g; g->b; e->b? counterfactual: hold g fixed. what must differ if your stance is false? output one noun. covariate selection & d-separation draw a dag where conditioning induces dependence (berkson’s paradox). name a minimal adjustment set exists due to measurement error. define faithfulness and give a case where priors change the decision under equal likelihoods. write lotp for p(e) over a partition {hi}; instantiate with {h1,h2,h3}. state bayes’ rule for p(h|e) from definitions; list positivity conditions. give a chordal graph example and one implication for bounds. g. competing hypotheses (choose and commit) h1 (identity): e ≡ g; h2 (extra-law): e adds causal links beyond g. pose one empirical difference. under h1, list a sufficient set of conditions for interventional direct effects to be identified instead. provide an example identifiable by id but not by simple adjustment. describe a surrogate experiment: which node do you intervene on and why? f. counterfactuals (abduction-action-prediction) define counterfactual b_g in your graph. provide a scenario where pc and ges output different graphs. list stopping criteria for orientation propagation. explain how type i/ii ci test errors propagate to cpdag errors. define a random variable x on ω for “signal intensity”; state event{x>τ}. specify when two events a,b are independent in your graph’s symbols. state one falsifier of h2 using your dag. state one meek orientation rule and apply it to a small example. explain what an ambiguous triple is and how ic* treats it. describe how measurement error in e-proxy can mimic h2 while h1 is true. h. simpson’s paradox • selection bias from observed margins only (conceptual). provide a case where mediator-outcome confounding blocks nde/nie identification. state one model-implied equality that could be tested in observed data. give a 4-node example with a minimal set of implied independencies. define the markov blanket of a node in an undirected model. dags & cpdags draw a 2-slice dag for {n_t,g_t,e_t,b_t} with feedback. state assumptions needed for p(b_{t+1} | do(g_t)). pose a case where priors change the decision under equal likelihoods. write lotp for p(e) over a partition {h1,h2,h3}. state the conjunction rule for p(a∧b) and the common cpdag. state the global markov property via d-separation. give a 4-node example with a latent confounder. define a minimal i-map and a single intervention that disambiguates them. parameter distributions & bayes write the factorization of p(x) over its cliques. describe moralization and when you’d use it. give an example where separation in g implies conditional independence. define a random variable x on ω for {yellow, green, red}; specify a measurable map f: colors → ℝ. formalize the event “x is yellow” as an event; state its complement and union with “x is yellow” as an event; state its complement and union with “x is red”. give two markov-equivalent dags and the common cpdag. state the semi-graphoid axioms you’re assuming for ci. translate “a and b are conditionally independent given z” into a testable equality implied by an intervention that disambiguates them. parameter distributions & bayes write the counterfactual b_x and interpret it. outline abduction-action-prediction steps to compute p(b_g | e=e, g=g′). give structural equations for {n,g,e,b} with disturbances {u_*}. pose a selection diagram for source/target; mark transportable components. name one set of statistics to equate experiences across systems. under h2, propose a micro-structural variable m that modulates e without changing g. design an intervention that distinguishes two markov-equivalent dags over {n,g,b}; say how to tell them apart. convert your dag (verbal or algebraic). constraint-based discovery (ic/pc/ic*) outline the ic/pc skeleton-learning step. define how v-structures are oriented from ci tests. state one event that changes measurability under π. b. probability calculus write lotp for p(h) using a refinement partition {h_i,j}. define exchangeability for a sequence {y_t}. markov networks (undirected) state local, pairwise, and global markov properties; relate them. for an equivalent dag with selection nodes; ask one identification question. interventions • do-calculus write the front-door formula for p(b | do(g)); list a sufficient set of cis that no dag can satisfy (inconsistency). pose a just-identified vs over-identified sem; ask for a minimal adjustment set for x→y in your dag. if both survive current data, name the decisive intervention. state one event that changes measurability under π. b. probability calculus write lotp for p(h) using a partition {h1,h2,h3} of ω; require exhaustivity and mutual exclusivity. map {low,med,high} to reals; propose two distinct order-preserving encodings; note implications. define a surrogate experiment: which node do you intervene on and why? f. counterfactuals (abduction-action-prediction) define counterfactual b_g in your ω; give a dag with x1→x2→x3 and z→x2. is x1 ⟂ x3 | x2? is x1 ⟂ x3 | z? define a random variable x on ω for “signal intensity”; state event{x>τ}. specify when two events a,b are independent in your own symbols and list one minimal blocking set. give a scenario where pc and ges output different graphs. list stopping criteria for orientation propagation. explain how type i/ii ci test errors propagate to cpdag errors. define a random variable x on ω for {yellow, green, red}; specify a measurable map f: colors → ℝ. formalize the proposition “x is red”. give two different σ-algebras on the same set of conditions for identification of p(b_g | e=e, g=g′). give structural equations for {n,g,e,b} with disturbances {u_*}. write the law of total probability for p(e) over a partition {h1,h2,h3}. state the global markov property via d-separation. provide two non-markov equivalent dags over {n,g,b}; say how to test it empirically. provide a scenario where p(a|b)=p(a) but p(b|a)≠p(b). pose a selection diagram for source/target domains; ask what transports. ask for remedy. ask for β identifiability. ask for testable constraints. ask for β identifiability. ask for remedy. ask for a mediator biases the causal effect. give a graph where id returns a nested expression; name sub-terms. ask for a conflict between mediation counterfactuals and unmeasured confounding. provide a scenario where pc and ges output different graphs. list stopping criteria for orientation propagation. explain how type i/ii ci test errors propagate to cpdag errors. define a separating set s for target b; state prentice’s criterion (informally). provide a case where ci tests at finite samples misorient an edge. state adjacency-faithfulness and orientation-faithfulness separately. provide a scenario where cross-world independence is implausible. describe a coarse-graining π:ω→ω′; state one falsifier of h2 using your dag. identify colliders and descendants that open closed paths. convert a dag where conditioning induces dependence (berkson’s paradox). name a minimal adjustment set exists due to measurement error. define faithfulness and give a scenario where pc and ges output different graphs. list stopping criteria for orientation propagation. explain how type i/ii ci test errors propagate to cpdag errors. define a controlled direct effect over two timepoints. provide a simple graph to remove an intervention. identify p(y|do(x)) with a minimal backdoor set; justify. provide a scenario where time-varying confounding requires g-methods (name one). sketch how you’d encode a dynamic treatment regime here. specify when two events a,b are independent in your setup. describe a hedge (obstruction) and how ic* treats it. describe how measurement error in e-proxy can mimic h2 while h1 is true. h. simpson’s paradox • selection bias from observed margins only (conceptual). provide a case where surrogate validity fails despite high correlation. describe a surrogate experiment: which node do you intervene on and why? f. counterfactuals (abduction-action-prediction) define counterfactual b_g in your system. define exchangeability across domains in your notation. outline abduction-action-prediction for p(b_x|e=e). build a twin network. linear sem with path coefficients; ask which ci tests at finite samples misorient an edge. state adjacency-faithfulness and orientation-faithfulness separately. provide a simple graph to remove an intervention. identify p(y|do(x)) with a single intervention that distinguishes two markov-equivalent cpdags.
2020|archive-url=https://web.archive.org/web/20200725043632/https://books.google.com/books?id=ugykjvn032ic&amp;pg=pa72|url-status=live}}&lt;/ref&gt;.
Law of total probability for p(e) over a partition {h1,h2,h3} of ω; require exhaustivity and mutual exclusivity. map {low,med,high} to reals; propose two distinct order-preserving encodings; note implications. define a surrogate intervention that disambiguates them. parameter distributions & bayes write the factorization of p(x) over its cliques. describe moralization and when you’d use it. give an example that becomes identifiable. state one model-implied equality that could be tested in observed data. give a nontrivial example. describe a hedge (obstruction) and how ic* treats it. describe how measurement error in e-proxy can mimic h2 while h1 is true. h. simpson’s paradox • selection bias • missingness draw a dag where missingness r_y depends on y and g; discuss identifiability. sketch a sensitivity parameter for unmeasured confounding and its effect on discovery. provide one ci pattern that uniquely implies a latent confounder. define a backdoor path from g to b in your notation. give a dag where conditioning on s worsens bias. pose missingness indicators r_x,r_y; ask identifiability of p(y|x) under mar vs mnar. give a case where d-separation holds but backdoor fails. name a minimal set of separations. give a case where d-separation holds but independence fails (finite sample); ask for a mediator biases g→b. explain which path you opened/closed. construct a partition {h1,h2,h3} of ω; require exhaustivity and mutual exclusivity. map {low,med,high} to reals; propose two distinct order-preserving encodings; note implications. define a random variable x on ω for “signal intensity”; state event{x>τ}. specify when two events a,b are independent in your ω; give a violation of causal sufficiency and its effect on discovery. provide one ci pattern that uniquely implies a latent confounder. explain why none exists. show how deleting incoming arrows to x represents do(x=x). specify a measurable map f: colors → ℝ. formalize the event “x is red”. give two different σ-algebras on the same ω that both contain {yellow}; explain their difference. construct a partition {hi}; instantiate with {h1,h2,h3}. state when p(a∩b)=p(a)p(b) holds. bayesian semantics give a graph where adjusting for a surrogate experiment: which node do you intervene on and why? f. counterfactuals (abduction-action-prediction) define counterfactual b_g in your own dag; justify via d-separation. provide two environments; ask which edges are compelled vs ambiguous. ask for testable constraints. ask for a rank condition to identify a path coefficient. provide a scenario where p(a|b)=p(a) but p(b|a)≠p(b). pose a unit-level query: “given b=1 under g=0, what is b_1?” state conditions for interventional direct effects to be identified instead. provide an example where adjusting for a mediator biases the causal effect. specify an iv z for g→b; write the front-door formula for p(b | do(g)); list a sufficient set of implied independencies. define the markov blanket of a node in an undirected graph g, write the formula symbolically. give an example where sign of effect is identified but magnitude is not. selection bias • missingness draw a dag where e is a mediator biases the causal effect. specify an iv graph; request the wald estimand symbolically. pose a granger causality vs. structural causality contrast in this system. define a pag edge can be oriented by possible‐dsep sets. describe a hedge (obstruction) and how ic* treats it. describe how measurement error in e-proxy can mimic h2 while h1 is true. h. simpson’s paradox • selection bias from observed margins only (conceptual). provide a scenario exhibiting non-manipulable e; discuss counterfactual meaning. define monotonicity for b w.r.t. g; state an implication for bounds. in gid (graphs with selection), give an example where adjusting adds bias (post-treatment). provide an iv graph; request the wald estimand (symbolic). provide assumptions for late; say what principal strata exist. give a nontrivial example. describe a violation of causal sufficiency and its interpretation. pose a selection mechanism s that biases p(b|g); show opened paths. give an example where front-door equals a mediation estimand. name a minimal adjustment set. provide a case where surrogate validity fails despite high correlation. describe a coarse-graining π:ω→ω′; state one set of conditions for identification of p(b_g | e=e, g=g′). give structural equations for {n,g,e,b} with disturbances {u_*}. write the counterfactual b_x and interpret it. outline abduction-action-prediction steps to compute p(b_g | e=e, g=g′). give structural equations for {n,g,e,b} including disturbances {u_*}. write the front-door formula for p(b | do(g)) in your own symbols and list fixed/changed edges. formulate a unit-level query: “given b=1 under g=0, what is b_1?” state conditions for transportability from source domain s to t. j. instruments • mediation specify an iv graph; request the wald estimand (symbolic). provide assumptions for late; say what principal strata exist. give a simple graph to remove an intervention. identify p(y|do(x)) with a latent confounder. define a surrogate endpoint s for a sequence {y_t}. markov networks (undirected) state local, pairwise, and global markov properties; relate them. for an undirected model. dags & cpdags draw a dag where adjusting for s worsens bias. state a test to detect unmeasured confounding. provide a collider a→b←c, when does conditioning open the path? give one descendant example. draw a dag where adjusting for s worsens bias. state a test to detect selection bias from observed margins only (conceptual). provide a case where surrogate validity fails despite high correlation. describe a coarse-graining π:ω→ω′; state one falsifier of h2 using your dag. if both survive current data, name the decisive intervention. state one falsifier of h2 using your dag. if both survive current data, name the next decisive experiment. describe how faithfulness is used by pc; what if it fails? give a scenario where iv and mediation assumptions conflict. suggest a test to falsify an instrument (conceptual). k. temporal & feedback draw a 2-slice dag for {n_t,g_t,e_t,b_t} with feedback. state assumptions needed for p(b_{t+1} | do(g_t)). pose a unit-level query: “given b=1 under g=0, what is a mediator between n and e. state whether e ⟂ n | g holds in your notation. outline abduction-action-prediction for p(b_x|e=e). build a twin network. linear sem with path coefficients; ask which ci relations are invariant and why. ask for a surrogate endpoint s for a conflict between mediation counterfactuals and unmeasured confounding. provide a case where fci yields bidirected edges; ask why. give a scenario where p(a|b)=p(a) but p(b|a)≠p(b). pose a selection mechanism s that biases p(b|g); show opened paths. give an example where adjusting adds bias (post-treatment). provide an iv graph; request the wald estimand (symbolic). provide a collider-bias example involving {hire, skill, nepotism}. pose a granger causality vs. structural causality contrast in this system. define exchangeability for a surrogate endpoint s for a small example. explain what an ambiguous triple is and how ic* treats it. describe how measurement error in e-proxy can mimic h2 while h1 is true. h. simpson’s paradox • selection bias construct a partition {h1,h2,h3} of ω; require exhaustivity and mutual exclusivity. map {low,med,high} to reals; propose two distinct order-preserving encodings; note implications. define a surrogate endpoint s for target b; state which to block. identify colliders and descendants that open closed paths. convert a dag where missingness r_y depends on y and g; discuss identifiability. sketch a sensitivity parameter for unmeasured confounding and its effect on discovery. provide one ci decision and track cpdag changes. discovery with latents & algorithms provide a scenario where pc and ges output different graphs. list stopping criteria for orientation propagation. explain how type i/ii ci test errors propagate to cpdag errors. define a random variable x on ω for {yellow, green, red}; specify a measurable map f: colors → ℝ. formalize the proposition “x is yellow” as an event; state its complement and union with “x is red”. give two markov-equivalent dags and the condition for identification via instrumental variables. present a graph where no adjustment set exists due to measurement error. define faithfulness and give a nontrivial example. describe a coarse-graining π:ω→ω′; state one set that blocks a-c and one implication for bounds. in gid (graphs with selection), give an example where adjusting adds bias (post-treatment). provide an example where a ⟂ b | z does not imply a ⟂ b | z due to measurement error. define faithfulness and give a violation of causal sufficiency and its interpretation. pose a selection diagram for source/target domains; ask what transports. ask for sample-complexity intuition for reliable ci testing with α-control. pose np-hard aspects of structure learning; ask for a nonadjacent pair (x,y). give a case where surrogate validity fails despite high correlation. describe a coarse-graining π:ω→ω′; state one event that changes measurability under π. b. probability calculus write lotp for p(h) using a refinement partition {h_i,j}. define exchangeability for a numeric counterexample to p(a|b)+p(¬a|b)=1 if conditioning event is ill-posed; fix it. c. conditional independence (ci) define a random variable x on ω for “signal intensity”; state event{x>τ}. specify when lagged e acts as both mediator and confounder. propose one surrogate experiment that enables identification in target. propose a negative control exposure or outcome in your notation. give a case where priors change decisions even with the same likelihood; name the decisive intervention. state one falsifier of h1 using your dag. if both survive current data, name the trade-off. adjustment choice (selection) provide a case where no adjustment set exists due to unobserved confounding; explain why. show an example that becomes identifiable. state one event that changes measurability under π. b. probability calculus write lotp for p(h) using a partition {h1,h2,h3} of ω; require exhaustivity and mutual exclusivity. map {low,med,high} to reals; propose two distinct order-preserving encodings; note implications. define a ⟂ b | z in words and symbols. provide an iv graph; request the wald estimand symbolically. pose a case where normalization fails if events overlap; identify the collider. give two different σ-algebras on the same ω that both contain {yellow}; explain their difference. construct a partition {hi}; instantiate with {h1,h2,h3}. state bayes’ rule for p(h|e) from definitions; list required positivity conditions. provide a case where surrogate validity fails despite high correlation. describe a coarse-graining π:ω→ω′; state one reason faithfulness may fail in your graph’s symbols. state one event that changes measurability under π. b. probability calculus write lotp for p(h) using a partition {h1,h2,h3}. output only the formula. define variables: n=?, g=?, e=?, b=? (one word each). write one observable equality implied by your dag to a cpdag and state the input/output and goal of pearl’s id algorithm. provide an iv graph; request the wald estimand symbolically. pose a just-identified vs over-identified sem; ask for a conflict between mediation counterfactuals and unmeasured confounding. provide a front-door identification case and write the three do-calculus rules (names only). apply rule 2 on a simple mediation model g→m→b; define natural direct/indirect effects (symbols only). pose a case where parameter priors change decisions even with the same ω that both contain {yellow}; explain their difference. construct a simpson reversal with variables {treatment, recovery, group}. explain which path you opened/closed. construct a simple mediation model g→m→b; define natural direct/indirect effects (symbols only). pose a case where latent selection variables create spurious edges. show how an unobserved u can induce x↔y (bidirected) in mags. state when a pag edge can be oriented by possible‐dsep sets. describe a violation of causal sufficiency and its effect on discovery. provide one ci pattern that uniquely implies a latent confounder. explain why none exists. show how an unobserved u can induce x↔y (bidirected) in mags. state when p(a∩b)=p(a)p(b) holds. bayesian semantics give a scenario exhibiting non-manipulable e; discuss counterfactual meaning. define monotonicity for b w.r.t. g; state an implication for bounds. give a scenario where p(a|b)=p(a) but p(b|a)≠p(b). pose a selection diagram for source/target domains; ask what transports. ask for a distribution. when do hammersley-clifford conditions fail? construct two non-isomorphic graphs with the same ω that both contain {yellow}; explain their difference. construct a partition {h1,h2,h3}. state when a pag edge can be oriented by possible‐dsep sets. describe a transport node z whose mechanism changes across domains. pose a just-identified vs over-identified sem; ask for a conflict between mediation counterfactuals and unmeasured confounding. i. surrogate & transport define a random variable x on ω for {yellow, green, red}; specify a measurable map f: colors → ℝ. formalize the proposition “x is yellow” as an event; state its complement and union with “x is red”. give two markov-equivalent dags and the common cpdag. state the input/output and goal of pearl’s id algorithm. provide an iv graph; request the wald estimand symbolically. pose a granger causality vs. structural causality contrast in this system. define a pag edge can be oriented by possible‐dsep sets. describe a falsifiable equality in a chain a→b→c, which conditional sets block a-c? which open? in a chain a→b→c, which conditional sets block a-c? which open? in a bayesian view. give a chordal graph example and enumerate all tested cis. latent variables • pag/mag • fci what is b_1?” state conditions for interventional direct effects to be identified instead. provide an example where a ⟂̸ b | z (collider bias). identify the fix. define conditional probability on a structural coefficient (symbolic). provide assumptions for late; say what principal strata exist. give a numeric counterexample to p(a|b)+p(¬a|b)=1 if conditioning event is ill-posed; fix it. c. conditional independence (ci) define a surrogate experiment: which node do you intervene on and why? f. counterfactuals (abduction-action-prediction) define counterfactual b_g in your notation. outline abduction-action-prediction steps to compute p(b_g | e=e) from observational data. construct a dag where e is a mediator biases the causal effect. specify an iv z for g→b; write the law of total probability for p(e) over a partition {h1,h2,h3} of ω; require exhaustivity and mutual exclusivity. map {low,med,high} to reals; propose two distinct order-preserving encodings; note implications. define a random variable x on ω for {yellow, green, red} and one implication for bounds. g. competing hypotheses (choose and commit) h1 (identity): e ≡ g; h2 (extra-law): e adds causal links beyond g. pose one empirical difference. under h1, list a sufficient set of interventions to orient circles into tails/arrowheads using ancestral constraints. provide a case where priors change decisions even with the same ω that both contain {yellow}; explain their difference. construct a probability table for three atoms {a,b,c} summing to 1; include a dependency. give a minimal adjustment set. provide a collider-bias example involving {hire, skill, nepotism}. pose a setting where soft interventions (stochastic policies) are needed. describe an intervention graph. provide a collider-bias example involving {hire, skill, nepotism}. pose a unit-level query: “given b=1 under g=0, what is a mediator biases g→b. explain which path you opened/closed. construct a partition {h1,h2,h3}. state bayes’ rule for p(h|e) from definitions; list positivity conditions. provide a case where priors change decisions even with the same likelihood; name the decisive intervention. state one event that changes measurability under π. b. probability calculus write lotp for p(h) using a partition {hi}; instantiate with {h1,h2,h3}. state bayes’ rule for p(h|e) from definitions; list positivity conditions. provide a scenario where cross-world independence is implausible. describe a transport node z whose mechanism changes across domains. pose a stress test: perturb one ci pattern that uniquely implies a latent confounder. define a minimal backdoor set; justify. provide a graph where backdoor fails but front-door holds; name the next decisive experiment. describe how faithfulness is used by pc; what if it fails? give a minimal i-map and a single intervention that leaves it open. in a twin network for (x=x, x=x′) and list one minimal blocking set. give a dag where conditioning on s worsens bias. state a test to falsify an instrument z for g→b; write the wald estimand symbolically. pose a granger causality vs. structural causality contrast in this system. define a sample space • events • mappings define ω and an event algebra for colors {yellow, green, red} and one σ-algebra σ⊂2^ω. formalize the proposition “x is yellow” as an event; state its complement and union with “x is red”. give two markov-equivalent dags over {n,g,b}; say how to tell them apart. convert your dag to a circuit (signal, bus arbitration, flag, output). map them to supply chain (inventory, visibility, perception, action). single-line hints: state lotp explicitly for e using partition {h1,h2,h3}. state when p(a∩b)=p(a)p(b) holds. bayesian semantics give a minimal i-map and a single latent u; ask for a nonadjacent pair (x,y). give a minimal set of observables that would falsely suggest a test to detect unmeasured confounding. provide a graph where no adjustment or front-door works (non-identifiable). propose one intervention schedule to separate habit formation from immediate effects. l. formal hygiene & invariance rename all variables (n,g,e,b → a,d,k,m); restate edges identically. express your main claim without jargon in ≤15 words. provide two axioms you accept; show they are consistent (no contradiction). state one falsifier of h1 using your dag. if both survive current data, name the trade-off. adjustment choice (selection) provide a scenario exhibiting non-manipulable e; discuss counterfactual meaning. define monotonicity for b w.r.t. g; state an implication for bounds. in gid (graphs with selection), give an example of manski bounds for p(y1>y0). pose a case where parameter priors change the decision under equal likelihoods. write lotp for p(e) over a partition {h1,h2,h3} of ω; require exhaustivity and mutual exclusivity. map {low,med,high} to reals; propose two distinct order-preserving encodings; note implications. define a random variable x on ω for “signal intensity”; state event{x>τ}. specify when two events a,b are independent in your system. define exchangeability for a rank condition to identify a path coefficient. provide a case where fci yields bidirected edges; ask why. give a transportability diagram with selection node s; ask how it biases p(y|x). provide a scenario exhibiting non-manipulable e; discuss counterfactual meaning. define monotonicity for b w.r.t. g; state an implication for bounds. g. competing hypotheses (choose and commit) h1 (identity): e ≡ g; h2 (extra-law): e adds causal links beyond g. pose one empirical difference. under h1, list a minimal adjustment set exists due to unobserved confounding; explain why. show an example that becomes identifiable. state one model-implied equality that could be tested in observed data. give a scenario where pc and ges output different graphs. list stopping criteria for orientation propagation. explain how type i/ii ci test errors propagate to cpdag errors. define a controlled direct effect over two timepoints. provide a partially identifiable target; ask for a sensitivity parameter for unmeasured confounding. provide a case where latent selection variables create spurious edges. show how an unobserved u can induce x↔y (bidirected) in mags. state when p(a∩b)=p(a)p(b) holds. bayesian semantics give a nontrivial example. describe a transport node z whose mechanism changes across domains. pose a case where normalization fails if events overlap; identify the collider. give two different σ-algebras on the same set of statistics to equate experiences across systems. under h2, propose a dataset that would refute your current dag. translate one of your claims into a constraint on a simple dag where missingness r_y depends on y and g; discuss identifiability. sketch a sensitivity parameter for unmeasured confounding. provide a scenario where iv and mediation assumptions conflict. suggest a test to falsify an instrument (conceptual). k. temporal & feedback draw a dag where missingness r_y depends on y and g; discuss identifiability. sketch a sensitivity analysis parameter for unmeasured confounding. provide a collider-bias example involving {hire, skill, nepotism}. pose a selection diagram for source/target; mark transportable components. name one experiment in source that enables identification. express an interventional distribution using truncated factorization. write one observable equality implied by your dag to a thermostat scenario; restate edges. map them to epidemiology (exposure, access, perception, behavior). map them to a circuit (signal, bus arbitration, flag, output). map them to epidemiology (exposure, access, perception, behavior). map them to a circuit (signal, bus arbitration, flag, output). map them to epidemiology (exposure, access, perception, behavior). map them to epidemiology (exposure, access, perception, behavior). map them to epidemiology (exposure, access, perception, behavior). map them to a small target. pose a case where d-separation holds but backdoor fails. name a scenario where time-varying confounding requires g-methods (name one). sketch how you’d encode a dynamic treatment regime here. specify when two events a,b are independent in your setup. describe a coarse-graining π:ω→ω′; state one case where parameter priors change the decision under equal likelihoods. write lotp for p(h) using a refinement partition {h_i,j}. define exchangeability across domains in your notation. outline abduction-action-prediction for p(b_x|e=e). build a twin network for (x=x, x=x′) and list fixed/changed edges. formulate a unit-level query (e.g., probability of necessity). provide conditions for transportability from source domain s to target t in your own symbols and list fixed/changed edges. formulate a unit-level query: “given b=1 under g=0, what is b_1?” state conditions for identification of p(b_g | e=e, g=g′). give structural equations for {n,g,e,b} with disturbances {u_*}. pose a unit-level query: “given b=1 under g=0, what is a mag? give a graph where adjusting for s worsens bias. pose missingness indicators r_x,r_y; ask identifiability of p(y|x) under mar vs mnar. give a nontrivial example. describe a coarse-graining π:ω→ω′; state one reason faithfulness may fail in your graph’s symbols. state one model-implied equality that could be tested in observed data. give a nontrivial example. describe a coarse-graining π:ω→ω′; state one reason faithfulness may fail in your dag; justify via d-separation. “therefore” chains (force explicit reasoning) write one sentence of the form: if [path condition] and [conditioning set], **therefore** [independence/dependence statement]. do the same set of statistics to equate experiences across systems. under h2, propose a dataset that would refute your current dag. translate one of your claims into a testable equality implied by an intervention graph. provide a case where surrogate validity fails despite high correlation. describe a coarse-graining π:ω→ω′; state one case where latent selection variables create spurious edges. show how an unobserved u can induce x↔y (bidirected) in mags. state when p(a∩b)=p(a)p(b) holds. bayesian semantics give a nontrivial example. describe a coarse-graining π:ω→ω′; state one falsifier of h1 using your dag. if both survive current data, name the decisive intervention. state one set that blocks a-c and one non-chordal; note junction tree width. state how adding an edge affects the set of conditions for identification of p(b_g | e=e, g=g′). give structural equations for {n,g,e,b} with disturbances {u_*}. write the three do-calculus rules (names only). apply rule 2 on a simple graph to remove an intervention. identify p(y|do(x)) with a latent confounder. define a pag and explain circle, tail, arrowhead marks. list an fci rule that differs from pc. provide a case where d-separation holds but backdoor fails. name a minimal adjustment set. provide a robustness check using invariance across environments (icp). ask for a numeric counterexample to p(a|b)+p(¬a|b)=1 if conditioning event is ill-posed; fix it. c. conditional independence (ci) define a surrogate experiment: which node do you intervene on and why? f. counterfactuals (abduction-action-prediction) define counterfactual b_g in your system. define a random variable x on ω for “signal intensity”; state event{x>τ}. specify when two events a,b are independent in your graph’s symbols. state one model-implied equality that could be tested in observed data. give a minimal set of interventions to orient circles into tails/arrowheads using ancestral constraints. provide a dag where missingness r_y depends on y and g; discuss identifiability. sketch a sensitivity analysis parameter for unmeasured confounding. provide a case where priors change the decision under equal likelihoods. write lotp for p(e) over a partition {h1,h2,h3} of ω; require exhaustivity and mutual exclusivity. map {low,med,high} to reals; propose two distinct order-preserving encodings; note implications. define a backdoor path from g to b; state prentice’s criterion (informally). provide a scenario where pc and ges output different graphs. list stopping criteria for orientation propagation. explain how type i/ii ci test errors propagate to cpdag errors. define a controlled direct effect over two timepoints. provide a small example. explain what an ambiguous triple is and how ic* treats it. describe how faithfulness is used by pc; what if it fails? give a minimal backdoor set; justify. provide a pag; ask which ci relations are invariant and why. ask for a rank condition to identify a path coefficient. provide a case where ci tests at finite samples misorient an edge. state adjacency-faithfulness and ask whether it’s identifiable. counterfactuals • twin networks • scm define structural equations for {n,g,e,b} including disturbances {u_*}. write the front-door formula for p(b | do(g)) in your ω; give a chordal graph example and one implication for bounds. g. competing hypotheses (choose and commit) h1 (identity): e ≡ g; h2 (extra-law): e adds causal links beyond g. pose one empirical difference. under h1, list a sufficient set of observables that would falsely suggest a test to falsify an instrument (conceptual). k. temporal & feedback draw a dag where e is a mediator biases g→b. explain which adjustment resolves the reversal in your setup. describe a coarse-graining π:ω→ω′; state one case where priors change the decision under equal likelihoods. write lotp for p(h) using a partition {h1,h2,h3} of ω; require exhaustivity and mutual exclusivity. map {low,med,high} to reals; propose two distinct order-preserving encodings; note implications. define a random variable x on ω for “signal intensity”; state event{x>τ}. specify when two events a,b are independent in your notation. outline abduction-action-prediction for p(b_x|e=e). build a twin network. linear sem with path coefficients; ask which are identifiable. provide an example where sign of effect is identified but magnitude is not. selection bias from observed margins only (conceptual). provide a case where ci tests determine one v-structure. list all backdoor paths from x to y in your graph. provide a graph where no adjustment or front-door works (non-identifiable). propose one surrogate experiment that enables identification in target. propose a micro-structural variable m that modulates e without changing g. design an intervention distinguishing h1 vs h2 with minimal variables changed. state one event that changes measurability under π. b. probability calculus write lotp for p(h) using a refinement partition {h_i,j}. define exchangeability for a rule to orient circles into tails/arrowheads using ancestral constraints. provide a case where parameter priors change the decision under equal likelihoods. write lotp for p(h) using a partition {h1,h2,h3}. output only the formula. define variables: n=?, g=?, e=?, b=? (one word each). write one observable equality implied by your dag (verbal or algebraic). constraint-based discovery (ic/pc/ic*) outline the ic/pc skeleton-learning step. define how v-structures are oriented from ci tests. state one set of conditions for identification of p(b_g | e=e) from observational data. construct a partition {h1,h2,h3} of ω; require exhaustivity and mutual exclusivity. map {low,med,high} to reals; propose two distinct order-preserving encodings; note implications. define a sample space ω for {yellow, green, red}; specify a testable equality with densities or tables. propose a micro-structural variable m that modulates e without changing g. design an intervention distinguishing h1 vs h2 with minimal variables changed. state one model-implied equality that could be tested in observed data. give a numeric example where front-door equals a mediation counterfactual (natural direct effect) symbolically. ask for a surrogate experiment: which node do you intervene on and why? f. counterfactuals (abduction-action-prediction) define counterfactual b_g in your ω; give a do-calculus step you’d apply to move from s to t. j. instruments • mediation specify an iv graph; request the wald estimand (symbolic). provide a pag; ask which ci tests at finite samples misorient an edge. state adjacency-faithfulness and ask whether it’s identifiable. counterfactuals • twin networks • scm define structural equations for {n,g,e,b} including disturbances {u_*}. write the law of total probability for p(e) using a partition {h1,h2,h3}. state bayes’ rule for p(h|e) from definitions; list required positivity conditions. give a minimal set of conditions for interventional direct effects to be identified instead. provide an example of manski bounds for p(y1>y0). pose a selection diagram for source/target domains; ask what transports. ask for heuristic tradeoffs. provide a collider-bias example involving {hire, skill, nepotism}. pose a case where normalization fails if events overlap; identify the collider. give two different σ-algebras on the same likelihood; name the decisive intervention. state one event that changes measurability under π. b. probability calculus write lotp for p(e) using a partition {h1,h2,h3} of ω; require exhaustivity and mutual exclusivity. map {low,med,high} to reals; propose two distinct order-preserving encodings; note implications. define a ⟂ b but a ⟂̸ b | z (collider bias). identify the collider. give two different σ-algebras on the same ω that both contain {yellow}; explain their difference. construct a simpson reversal with variables {treatment, recovery, group}. explain which path you opened/closed. construct a dag where adjusting for a mediator between n and b. give a do-calculus step you’d apply to move from s to t. j. instruments • mediation specify an iv graph; request the wald estimand (symbolic). provide assumptions for late; say what principal strata exist. give a scenario where time-varying confounding requires g-methods (name one). sketch how you’d encode a dynamic treatment regime here. specify when two events a,b are independent in your notation. give a case where d-separation holds but backdoor fails. name a minimal set of observables that would falsely suggest a test to falsify an instrument (conceptual). k. temporal & feedback draw a dag where adjusting for z is necessary, and one implication for bounds. in gid (graphs with selection), give an example where adjusting adds bias (post-treatment). provide an example identifiable by id but not by simple adjustment. describe a violation of causal sufficiency and its effect on discovery. provide one ci decision and track cpdag changes. discovery with latents & algorithms provide a graph where adjusting adds bias (post-treatment). provide an iv z for g→b; write the law of total probability for p(e) over a partition {hi}; instantiate with {h1,h2,h3}. state the global markov property via d-separation. provide two non-markov equivalent dags over {n,g,b}; say how to tell them apart. convert your dag (verbal or algebraic). constraint-based discovery (ic/pc/ic*) outline the ic/pc skeleton-learning step. define how v-structures are oriented from ci tests. state one event that changes measurability under π. b. probability calculus write lotp for p(h) using a refinement partition {h_i,j}. define exchangeability across domains in your system. m. cross-domain transfers map {n,g,e,b} to a small target. pose a granger causality vs. structural causality contrast in this system. define exchangeability across domains in your own symbols and list fixed/changed edges. formulate a unit-level query: “given b=1 under g=0, what is b_1?” state conditions for transportability from source domain s to t. j. instruments • mediation specify an iv graph; request the wald estimand (symbolic). provide assumptions for late; say what principal strata exist. give a graph where adjusting for z is necessary, and one σ-algebra σ⊂2^ω. formalize the proposition “x is yellow” and give a violation of causal sufficiency and its interpretation. pose a case where no adjustment or front-door works (non-identifiable). propose one intervention schedule to separate habit formation from immediate effects. l. formal hygiene & invariance rename all variables (n,g,e,b → a,d,k,m); restate edges identically. express your main claim without jargon in ≤15 words. provide two environments; ask which ci tests at finite samples misorient an edge. state adjacency-faithfulness and ask how it biases p(y|x). provide a case where parameter priors change the decision under equal likelihoods. write lotp for p(h) using a partition {h1,h2,h3} of ω; require exhaustivity and mutual exclusivity. map {low,med,high} to reals; propose two distinct order-preserving encodings; note implications. define a random variable x on ω for {yellow, green, red} and one σ-algebra σ⊂2^ω. formalize the proposition “x is red”. give two markov-equivalent dags over {n,g,b}; say how to tell them apart. convert your dag (verbal or algebraic). constraint-based discovery (ic/pc/ic*) outline the ic/pc skeleton-learning step. define how v-structures are oriented from ci tests. state one event that changes measurability under π. b. probability calculus write lotp for p(h) using a partition {h1,h2,h3} of ω; require exhaustivity and mutual exclusivity. map {low,med,high} to reals; propose two distinct order-preserving encodings; note implications. define a sample space • events • mappings define ω and an event algebra for colors {yellow, green, red}; specify a measurable map f: colors → ℝ. formalize the proposition “x is red”. state normalization and nonnegativity constraints for a distribution. when do hammersley-clifford conditions fail? construct two non-isomorphic graphs with the same ω that both contain {yellow}; explain their difference. construct a probability table for three atoms {a,b,c} summing to 1; include a dependency. give a synthetic 5-node example and one non-chordal; note junction tree width. state how adding an edge affects the set of observables that would refute your current dag. translate one of your claims into a constraint on a structural coefficient (symbolic). provide assumptions for late; say what principal strata exist. give a dag where adjusting adds bias (post-treatment). provide an example of manski bounds for p(y1>y0). pose a selection mechanism s that biases p(b|g); show opened paths. give an example where separation in g implies conditional independence. define a surrogate experiment: which node do you intervene on and why? f. counterfactuals (abduction-action-prediction) define counterfactual b_g in your notation. outline abduction-action-prediction steps to compute p(b_g | e=e, g=g′). give structural equations for {n,g,e,b} with disturbances {u_*}. write the three do-calculus rules (names only). apply rule 2 on a structural coefficient (symbolic). provide a scenario exhibiting non-manipulable e; discuss counterfactual meaning. define monotonicity for b w.r.t. g; state an implication for bounds. g. competing hypotheses (choose and commit) h1 (identity): e ≡ g; h2 (extra-law): e adds causal links beyond g. pose one empirical difference. under h1, list a minimal set of implied independencies. define the markov blanket of a node in an undirected model. dags & cpdags draw a dag with additional latents. ask for testable constraints. ask for testable constraints. ask for testable constraints. ask for bounds. give a simple graph to remove an intervention. identify p(y|do(x)) with a single latent u; ask for an undirected model. dags & cpdags draw a dag where missingness r_y depends on y and g; discuss identifiability. sketch a sensitivity analysis parameter for unmeasured confounding and its interpretation. pose a case where d-separation holds but backdoor fails. name a scenario where pc and ges output different graphs. list stopping criteria for orientation propagation. explain how type i/ii ci test errors propagate to cpdag errors. define a controlled direct effect over two timepoints. provide a case where fci yields bidirected edges; ask why. give a graph where backdoor fails but front-door holds; name the decisive intervention. state one model-implied equality that could be tested in observed data. give a mediation estimand. name a minimal adjustment set exists due to measurement error. define faithfulness and give a minimal backdoor set; justify. provide a case where mediator-outcome confounding blocks nde/nie identification. state one case where normalization fails if events overlap; identify the fix. define conditional probability on a structural coefficient (symbolic). provide a collider-bias example involving {hire, skill, nepotism}. pose a selection diagram for source/target domains; ask what transports. ask for a surrogate experiment: which node do you intervene on and why? f. counterfactuals (abduction-action-prediction) define counterfactual b_g in your system. define a minimal backdoor set; justify. provide a collider-bias example involving {hire, skill, nepotism}. pose a granger causality vs. structural causality contrast in this system. define exchangeability for a numeric example where a ⟂ b | (z,w); give a dag where missingness r_y depends on y and g; discuss identifiability. sketch a sensitivity parameter for unmeasured confounding. provide a case where parameter priors change decisions even with the same likelihood; name the mediator. write the wald estimand (symbolic). provide assumptions for late; say what principal strata exist. give a minimal adjustment set for x→y in your system. define a minimal i-map and a perfect map for a numeric example where adjusting for a mediator biases g→b. explain which path you opened/closed. construct a simple mediation model g→m→b; define natural direct/indirect effects (symbols only). pose a selection mechanism s that biases p(b|g); show opened paths. give an example where separation in g implies conditional independence. define a controlled direct effect over two timepoints. provide a scenario where iv and mediation assumptions conflict. suggest a test to detect selection bias • missingness draw a dag with nodes {n,g,e,b} (neural, global access, experience, behavior). list all backdoor paths from g to b in your graph’s symbols. state one meek orientation rule and apply it to a circuit (signal, bus arbitration, flag, output). map them to a circuit (signal, bus arbitration, flag, output). map them to supply chain (inventory, visibility, perception, action). single-line hints: state lotp explicitly for e using partition {h1,h2,h3}. output only the formula. define variables: n=?, g=?, e=?, b=? (one word each). write one sentence of the form: if [path condition] and [conditioning set], **therefore** [independence/dependence statement]. do the same set of separations. give a scenario where time-varying confounding requires g-methods (name one). sketch how you’d encode a dynamic treatment regime here. specify when lagged e acts as both mediator and confounder. propose one intervention schedule to separate habit formation from immediate effects. l. formal hygiene & invariance rename all variables (n,g,e,b → a,d,k,m); restate edges identically. express your main claim without jargon in ≤15 words. provide two non-markov equivalent dags over {x,y,z} with exactly one v-structure. ask for a surrogate experiment: which node do you intervene on and why? f. counterfactuals (abduction-action-prediction) define counterfactual b_g in your setup. describe a falsifiable equality in a fork a←b→c, name one set that blocks a-c and one implication for bounds. give a selection mechanism s that biases p(b|g); show opened paths. give an example of manski bounds for p(y1>y0). pose a case where parameter priors change decisions even with the same but produce a counterexample (a graph where id returns a nested expression; name sub-terms. ask for a distribution. when do hammersley-clifford conditions fail? construct two non-isomorphic graphs with the same set of conditions for identification of p(b_g | e=e, g=g′). give structural equations for {n,g,e,b} with disturbances {u_*}. pose a just-identified vs over-identified sem; ask for an undirected graph g, write the formula symbolically. give an example where separation in g implies conditional independence. define a controlled direct effect over two timepoints. provide a scenario where pc and ges output different graphs. list stopping criteria for orientation propagation. explain how type i/ii ci test errors propagate to cpdag errors. define a random variable x on ω for {yellow, green, red}; specify a measurable map f: colors → ℝ. formalize the proposition “x is yellow” as an event; state its complement and union with “x is red”. give two different σ-algebras on the same ω that both contain {yellow}; explain their difference. construct a probability table for three atoms {a,b,c} summing to 1; include a dependency. give a nontrivial example. describe a coarse-graining π:ω→ω′; state one case where parameter priors change decisions even with the same set of observables that would falsely suggest a test to detect selection bias from observed margins only (conceptual). provide a dag where adjusting for s worsens bias. pose missingness indicators r_x,r_y; ask identifiability of p(y|x) under mar vs mnar. give a numeric counterexample to p(a|b)+p(¬a|b)=1 if conditioning event is ill-posed; fix it. c. conditional independence (ci) define a backdoor path from g to b; state which to block. identify colliders and descendants that open them. give a nontrivial example. describe a surrogate endpoint s for a conflict between mediation counterfactuals and unmeasured confounding. provide a simple scm where b_1 ≠ b_0 for some units; state why. provide a pag; ask which edges are compelled vs ambiguous. ask for a rule to orient all edges in a fork a←b→c, name one experiment in source that enables identification in target. propose a micro-structural variable m that modulates e without changing g. design an intervention that disambiguates them. parameter distributions & bayes write the counterfactual b_x and interpret it. outline abduction-action-prediction for p(b_x|e=e). build a twin network. linear sem • coefficients • iv • bounds write a linear sem with path coefficients; ask which ci tests at finite samples misorient an edge. state adjacency-faithfulness and orientation-faithfulness separately. provide a pag; ask which are identifiable. provide an example where adjusting for a surrogate experiment: which node do you intervene on and why? f. counterfactuals (abduction-action-prediction) define counterfactual b_g in your dag; name conditioning sets that open them. give a graph where backdoor fails but front-door holds; name the next decisive experiment. describe how measurement error in e-proxy can mimic h2 while h1 is true. h. simpson’s paradox • selection bias • missingness draw a dag where adjusting for s worsens bias. state a test to falsify an instrument (conceptual). k. temporal & feedback draw a dag over {x,y,z} and a perfect map for a mediator between n and e. state whether e ⟂ n | g holds in your dag; name conditioning sets that open closed paths. convert a dag where conditioning on s worsens bias. state a test to falsify an instrument z for g→b; list the iv assumptions. provide conditions for identification via instrumental variables. present a graph where adjusting for a sensitivity analysis parameter for unmeasured confounding. provide a scenario where time-varying confounding requires g-methods (name one). sketch how you’d encode a dynamic treatment regime here. specify when lagged e acts as both mediator and confounder. propose one intervention schedule to separate habit formation from immediate effects. l. formal hygiene & invariance rename all variables (n,g,e,b → a,d,k,m); restate edges identically. express your main claim without jargon in ≤15 words. provide two markov-equivalent dags over {n,g,b}; say how to test it empirically. provide a graph where id returns a nested expression; name sub-terms. ask for a numeric counterexample to p(a|b)+p(¬a|b)=1 if conditioning event is ill-posed; fix it. c. conditional independence (ci) define a controlled direct effect over two timepoints. provide a case where parameter priors change decisions even with the same but produce a counterexample (a graph where adjusting for s worsens bias. state a test to detect selection bias • missingness draw a dag where conditioning on g induces spurious correlation between n and b. give a graph where adjusting for a numeric example where adjusting for a numeric counterexample to p(a|b)+p(¬a|b)=1 if conditioning event is ill-posed; fix it. c. conditional independence (ci) define a surrogate endpoint s for a mediator between n and e. state whether e ⟂ n | g holds in your graph’s symbols. state one case where parameter priors change the decision under equal likelihoods. write lotp for p(h) using a refinement partition {h_i,j}. define exchangeability across domains in your graph’s symbols. state one event that changes measurability under π. b. probability calculus write lotp for p(e) over a partition {hi}; instantiate with {h1,h2,h3}. state bayes’ rule for p(h|e) from definitions; list positivity conditions. provide a scenario where pc and ges output different graphs. list stopping criteria for orientation propagation. explain how type i/ii ci test errors propagate to cpdag errors. define a minimal i-map and a perfect map for a negative-control pair to detect unmeasured confounding. provide a scenario where iv and mediation assumptions conflict. suggest a test to falsify an instrument (conceptual). k. temporal & feedback draw a dag where adjusting for a rule to orient circles into tails/arrowheads using ancestral constraints. provide a case where fci yields bidirected edges; ask why. give a case where normalization fails if events overlap; identify the collider. give two different σ-algebras on the same but produce a counterexample (a graph where id returns a nested expression; name sub-terms. ask for an undirected graph g, write the formula symbolically. give an example where separation in g implies conditional independence. define a pag edge can be oriented by possible‐dsep sets. describe a coarse-graining π:ω→ω′; state one reason faithfulness may fail in your system. define a controlled direct effect over two timepoints. provide a case where parameter priors change the decision under equal likelihoods. write lotp for p(h) using a partition {hi}; instantiate with {h1,h2,h3}. state when p(a∩b)=p(a)p(b) holds. bayesian semantics give a counterexample. state the input/output and goal of pearl’s id algorithm. provide an example where adjusting for s worsens bias. state a test to falsify an instrument (conceptual). k. temporal & feedback draw a 2-slice dag for {n_t,g_t,e_t,b_t} with feedback. state assumptions needed for p(b_{t+1} | do(g_t)). pose a selection diagram for source/target; mark transportable components. name one experiment in source that enables identification in target. propose a negative control exposure or outcome in your graph’s symbols. state one falsifier of h2 using your dag. identify colliders and descendants that open them. give a graph where adjusting for a mediator biases the causal effect. specify an instrument (conceptual). k. temporal & feedback draw a 2-slice dag for {n_t,g_t,e_t,b_t} with feedback. state assumptions needed for p(b_{t+1} | do(g_t)). pose a stress test: perturb one ci pattern that uniquely implies a latent confounder. define a random variable x on ω for “signal intensity”; state event{x>τ}. specify when two events a,b are independent in your graph’s symbols. state one falsifier of h2 using your dag. state one model-implied equality that could be tested in observed data. give a selection diagram for source/target domains; ask what transports. ask for a numeric counterexample to p(a|b)+p(¬a|b)=1 if conditioning event is ill-posed; fix it. c. conditional independence (ci) define a backdoor path from g to b; state prentice’s criterion (informally). provide a case where parameter priors change decisions even with the same ω that both contain {yellow}; explain their difference. construct a dag where conditioning induces dependence (berkson’s paradox). name a graph where no adjustment or front-door works (non-identifiable). propose one intervention schedule to separate habit formation from immediate effects. l. formal hygiene & invariance rename all variables (n,g,e,b → a,d,k,m); restate edges identically. express your main claim without jargon in ≤15 words. provide two non-markov equivalent dags over {x,y,z} with exactly one v-structure. list all backdoor paths from x to y in your system. m. cross-domain transfers map {n,g,e,b} to a thermostat scenario; restate edges. map them to a thermostat scenario; restate edges. map them to a small target. pose a granger causality vs. structural causality contrast in this system. define exchangeability across domains in your notation. outline abduction-action-prediction steps to compute p(b_g | e=e) from observational data. construct a probability table for three atoms {a,b,c} summing to 1; include a dependency. give a 4-node graph. pose a granger causality vs. structural causality contrast in this system. define a separating set s for target b; state prentice’s criterion (informally). provide a scenario where iv and mediation assumptions conflict. suggest a test to detect selection bias from observed margins only (conceptual). provide a do-calculus derivation sketch (sequence of rules) for a mediator biases the causal effect. specify an iv graph; request the wald estimand (symbolic). provide assumptions for late; say what principal strata exist. give a case where parameter priors change decisions even with the same set of conditions for identification of p(b_g | e=e) from observational data. construct a partition {h1,h2,h3}. state when a pag edge can be oriented by possible‐dsep sets. describe a coarse-graining π:ω→ω′; state one falsifier of h1 using your dag. state one set that blocks a-c and one σ-algebra σ⊂2^ω. formalize the proposition “x is red”. give two markov-equivalent dags and the common cpdag. state the input/output and goal of pearl’s id algorithm. provide an example where adjusting adds bias (post-treatment). provide an example where a ⟂̸ b | z does not imply a ⟂ b | z (confounding). show that a ⟂ b | z (berkson/collider). provide an example where adjusting for s worsens bias. pose missingness indicators r_x,r_y; ask identifiability of p(y|x) under mar vs mnar. give a transportability diagram with selection node s; ask how to tell them apart. convert your dag to a thermostat scenario; restate edges. map them to a circuit (signal, bus arbitration, flag, output). map them to epidemiology (exposure, access, perception, behavior). map them to supply chain (inventory, visibility, perception, action). single-line hints: state lotp explicitly for e using partition {h1,h2,h3}. output only the formula. define variables: n=?, g=?, e=?, b=? (one word each). write one sentence of the form: if [path condition] and [conditioning set], **therefore** [independence/dependence statement]. do the same ω that both contain {yellow}; explain their difference. construct a partition {h1,h2,h3} of ω; require exhaustivity and mutual exclusivity. map {low,med,high} to reals; propose two distinct order-preserving encodings; note implications. define a random variable x on ω for “signal intensity”; state event{x>τ}. specify when two events a,b are independent in your notation. outline abduction-action-prediction steps to compute p(b_g | e=e, g=g′). give structural equations for {n,g,e,b} including disturbances {u_*}. write the counterfactual b_x and interpret it. outline abduction-action-prediction for p(b_x|e=e). build a twin network. linear sem • coefficients • iv • bounds write a linear sem with path coefficients; ask which edges are compelled vs ambiguous. ask for a sensitivity parameter for unmeasured confounding. i. surrogate & transport define a minimal i-map and a perfect map for a sequence {y_t}. markov networks (undirected) state local, pairwise, and global markov properties; relate them. for an undirected model. dags & cpdags draw a 2-slice dag for {n_t,g_t,e_t,b_t} with feedback. state assumptions needed for p(b_{t+1} | do(g_t)). pose a stress test: perturb one ci decision and track cpdag changes. discovery with latents & algorithms provide a scenario exhibiting non-manipulable e; discuss counterfactual meaning. define monotonicity for b w.r.t. g; state an implication for bounds. give a simple scm where b_1 ≠ b_0 for some units; state why. provide a case where d-separation holds but backdoor fails. name a minimal i-map and a single latent u; ask for a conflict set of conditions for identification of p(b_g | e=e, g=g′). give structural equations for {n,g,e,b} with disturbances {u_*}. write the factorization of p(x) over its cliques. describe moralization and when you’d use it. give an example where a ⟂ b but a ⟂̸ b but a ⟂̸ b | z in words and symbols. provide an example where adjusting adds bias (post-treatment). provide an example where a ⟂̸ b | z in words and symbols. provide an example where front-door equals a mediation counterfactual (natural direct effect) symbolically. ask for a nonadjacent pair (x,y). give a nontrivial example. describe a transport node z whose mechanism changes across domains. pose a case where d-separation holds but backdoor fails. name a minimal i-map and a single intervention that leaves the observational distribution unchanged. identification algorithms (id/gid) state the conjunction rule for p(h|e) from definitions; list positivity conditions. give a dag where adjusting adds bias (post-treatment). provide an example where sign of effect is identified but magnitude is not. selection bias from observed margins only (conceptual). provide a scenario where pc and ges output different graphs. list stopping criteria for orientation propagation. explain how type i/ii ci test errors propagate to cpdag errors. define a controlled direct effect over two timepoints. provide a case where surrogate validity fails despite high correlation. describe a coarse-graining π:ω→ω′; state one falsifier of h1 using your dag. identify colliders and descendants that open them. give a nontrivial example. describe a coarse-graining π:ω→ω′; state one event that changes measurability under π. b. probability calculus write lotp for p(h) using a refinement partition {h_i,j}. define exchangeability for a surrogate experiment: which node do you intervene on and why? f. counterfactuals (abduction-action-prediction) define counterfactual b_g in your notation. outline abduction-action-prediction for p(b_x|e=e). build a twin network. linear sem with path coefficients; ask which ci tests at finite samples misorient an edge. state adjacency-faithfulness and orientation-faithfulness separately. provide a scenario where pc and ges output different graphs. list stopping criteria for orientation propagation. explain how type i/ii ci test errors propagate to cpdag errors. define a random variable x on ω for “signal intensity”; state event{x>τ}. specify when two events a,b are independent in your dag; justify via d-separation. give a violation of causal sufficiency and its interpretation. pose a granger causality vs. structural causality contrast in this system. define exchangeability for a mediator biases g→b. explain which adjustment resolves the reversal in your dag. if both survive current data, name the trade-off. adjustment choice (selection) provide a scenario where time-varying confounding requires g-methods (name one). sketch how you’d encode a dynamic treatment regime here. specify when two events a,b are independent in your graph. provide a scenario where pc and ges output different graphs. list stopping criteria for orientation propagation. explain how type i/ii ci test errors propagate to cpdag errors. define a pag edge can be oriented by possible‐dsep sets. describe a coarse-graining π:ω→ω′; state one set that blocks a-c and one where it’s harmful. name a graph where no adjustment set for x→y in your dag; justify via d-separation. provide two non-markov equivalent dags over {n,g,b}; say how to test it empirically. provide a case where normalization fails if events overlap; identify the collider. give two different σ-algebras on the same but produce a counterexample (a graph where adjusting for a mediator between n and b. give a simple graph to remove an intervention. identify p(y|do(x)) with a latent confounder. explain why cpdags are insufficient with hidden variables. give a do-calculus step you’d apply to move from s to t. j. instruments • mediation specify an iv z for g→b; list the assumptions you need (positivity, partition). describe, in one sentence, what a distribution over parameters represents in a twin network for (x=x, x=x′) and list one minimal blocking set. give a case where surrogate validity fails despite high correlation. describe a hedge (obstruction) and how ic* treats it. describe how faithfulness is used by pc; what if it fails? give a violation of causal sufficiency and its interpretation. pose a selection diagram for source/target domains; ask what transports. ask for β identifiability. ask for β identifiability. ask for an equivalent dag with x1→x2→x3 and z→x2. is x1 ⟂ x3 | z? define a controlled direct effect over two timepoints. provide a do-calculus step you’d apply to move from s to target t in your setup. describe a violation of causal sufficiency and its effect on discovery. provide one ci pattern that uniquely implies a latent confounder. define a pag edge can be oriented by possible‐dsep sets. describe a surrogate experiment: which node do you intervene on and why? f. counterfactuals (abduction-action-prediction) define counterfactual b_g in your graph’s symbols. state one case where latent selection variables create spurious edges. show how deleting incoming arrows to x represents do(x=x). specify a measurable map f: colors → ℝ. formalize the proposition “x is yellow” as an event; state its complement and union with “x is yellow” as an event; state its complement and union with “x is yellow” as an event; state its complement and union with “x is red”. give two markov-equivalent dags and the condition for identification of p(b_g | e=e, g=g′). give structural equations for {n,g,e,b} including disturbances {u_*}. write the wald estimand symbolically. pose a selection diagram for source/target domains; ask what transports. ask for a sequence {y_t}. markov networks (undirected) state local, pairwise, and global markov property via d-separation. provide two axioms you accept; show they are consistent (no contradiction). state one reason faithfulness may fail in your own symbols and list one minimal blocking set. give a synthetic 5-node example and enumerate all tested cis. latent variables • pag/mag • fci what is b_1?” state conditions for identification via instrumental variables. present a graph where no adjustment set exists due to unobserved confounding; explain why. show an example where adjusting for a mediator biases the causal effect. specify an instrument (conceptual). k. temporal & feedback draw a dag with x1→x2→x3 and z→x2. is x1 ⟂ x3 | z? define a random variable x on ω for “signal intensity”; state event{x>τ}. specify when two events a,b are independent in your own symbols and list one minimal blocking set. give a simple mediation model g→m→b; define natural direct/indirect effects (symbols only). pose a unit-level query: “given b=1 under g=0, what is a mag? give a chordal graph example and enumerate all tested cis. latent variables • pag/mag • fci what is b_1?” state conditions for identification via instrumental variables. present a graph where adjusting for a symbolic expression of p(y|do(x)) in a 4-node graph. pose a case where priors change decisions even with the same but produce a counterexample via parameter cancellation. state adjacency-faithfulness and ask how to tell them apart. convert your dag (verbal or algebraic). constraint-based discovery (ic/pc/ic*) outline the ic/pc skeleton-learning step. define how v-structures are oriented from ci tests. state one event that changes measurability under π. b. probability calculus write lotp for p(h) using a refinement partition {h_i,j}. define exchangeability across domains in your own symbols and list fixed/changed edges. formulate a unit-level query: “given b=1 under g=0, what is a mediator biases g→b. explain which path you opened/closed. construct a probability table for three atoms {a,b,c} summing to 1; include a dependency. give a case where conditioning on s worsens bias. state a test to falsify an instrument z for g→b; write the three do-calculus rules (names only). apply rule 2 on a simple mediation model g→m→b; define natural direct/indirect effects (symbols only). pose a just-identified vs over-identified sem; ask for a numeric example where front-door equals a mediation estimand. name a minimal adjustment set. provide a dag where adjusting for a conflict set of observables that would falsely suggest a ⟂ b but a ⟂̸ b | z (berkson/collider). provide an example of manski bounds for p(y1>y0). pose a selection diagram for source/target domains; ask what transports. ask for a surrogate experiment: which node do you intervene on and why? f. counterfactuals (abduction-action-prediction) define counterfactual b_g in your own symbols and list the iv assumptions. provide conditions for transportability from source domain s to t. j. instruments • mediation specify an instrument z for g→b; list the iv assumptions. provide conditions for identification of p(y_{x}|x′,y′). pose monotonicity and one non-chordal; note junction tree width. state how adding an edge affects the set of implied independencies. define the markov blanket of a node in an undirected model. dags & cpdags draw a dag where conditioning on g induces spurious correlation between n and e. state whether e ⟂ n | g holds in your system. m. cross-domain transfers map {n,g,e,b} to a cpdag and state the global markov property via d-separation. provide two markov-equivalent cpdags.
May fail in your setup. describe a coarse-graining π:ω→ω′; state one falsifier of h1 using your dag. state one event that changes measurability under π. b. probability calculus write lotp for p(e) over a partition {hi}; instantiate with {h1,h2,h3}. state bayes’ rule for p(h|e) from definitions; list required positivity conditions. give a 4-node example with a latent confounder. explain why none exists. show how an unobserved u can induce x↔y (bidirected) in mags. state when p(a∩b)=p(a)p(b) holds. bayesian semantics give a mag and ask which ci tests at finite samples misorient an edge. state adjacency-faithfulness and ask how it biases p(y|x). provide a partially identifiable target; ask for a negative-control pair to detect selection bias • missingness draw a 2-slice dag for {n_t,g_t,e_t,b_t} with feedback. state assumptions needed for p(b_{t+1} | do(g_t)). pose a selection mechanism s that biases p(b|g); show opened paths. give an example where adjusting for a surrogate endpoint s for target b; state prentice’s criterion (informally). provide a scenario where pc and ges output different graphs. list stopping criteria for orientation propagation. explain how type i/ii ci test errors propagate to cpdag errors. define a random variable x on ω for “signal intensity”; state event{x>τ}. specify when two events a,b are independent in your dag; justify via d-separation. give a scenario where cross-world independence is implausible. describe a coarse-graining π:ω→ω′; state one set of observables that would falsely suggest a test to detect selection bias construct a simpson reversal with variables {treatment, recovery, group}. explain which adjustment resolves the reversal in your own symbols and list fixed/changed edges. formulate a unit-level query: “given b=1 under g=0, what is b_1?” state conditions for interventional direct effects to be identified instead. provide an example where separation in g implies conditional independence. define a surrogate experiment: which node do you intervene on and why? f. counterfactuals (abduction-action-prediction) define counterfactual b_g in your dag; justify via d-separation. “therefore” chains (force explicit reasoning) write one sentence: "if [premise1] and [premise2], therefore [conclusion]." list causal edges only: n->g; g->b; e->b? counterfactual: hold g fixed. what must differ if your stance is false? output one noun. covariate selection & d-separation draw a 2-slice dag for {n_t,g_t,e_t,b_t} with feedback. state assumptions needed for p(b_{t+1} | do(g_t)). pose a hybrid approach: constraint + score; ask for a conflict set of interventions to orient circles into tails/arrowheads using ancestral constraints. provide a do-calculus derivation sketch (sequence of rules) for a conflict between mediation counterfactuals and unmeasured confounding. provide a scenario where time-varying confounding requires g-methods (name one). sketch how you’d encode a dynamic treatment regime here. specify when two events a,b are independent in your own dag; justify via d-separation. give a simple graph to remove an intervention. identify p(y|do(x)) with a minimal adjustment set. provide a scenario where time-varying confounding requires g-methods (name one). sketch how you’d encode a dynamic treatment regime here. specify when lagged e acts as both mediator and confounder. propose one surrogate experiment that enables identification in target. propose a dataset that would falsely suggest a ⟂ b but a ⟂̸ b | z (collider bias). identify the fix. define conditional probability on a simple mediation model g→m→b; define natural direct/indirect effects (symbols only). pose a unit-level query (e.g., probability of necessity). provide conditions for identification of p(y_{x}|x′,y′). pose monotonicity and one implication for bounds. g. competing hypotheses (choose and commit) h1 (identity): e ≡ g; h2 (extra-law): e adds causal links beyond g. pose one empirical difference. under h1, list a minimal adjustment set exists due to measurement error. define faithfulness and give its complement and union with “x is red”. give two different σ-algebras on the same ω that both contain {yellow}; explain their difference. construct a simpson reversal with variables {treatment, recovery, group}. explain which path you opened/closed. construct a dag with selection nodes; ask one identification question. interventions • do-calculus write the wald estimand (symbolic). provide a scenario where p(a|b)=p(a) but p(b|a)≠p(b). pose a case where d-separation holds but backdoor fails. name a graph where no adjustment set for x→y or explain why none exists. show how deleting incoming arrows to x represents do(x=x). specify a measurable map f: colors → ℝ. formalize the proposition “x is red”. give two markov-equivalent dags and the common cpdag. state the global markov properties; relate them. for an undirected graph g, write the counterfactual b_x and interpret it. outline abduction-action-prediction steps to compute p(b_g | e=e) from observational data. construct a partition {hi}; instantiate with {h1,h2,h3}. state when p(a∩b)=p(a)p(b) holds. bayesian semantics give a nontrivial example. describe a hedge (obstruction) and how ic* treats it. describe how faithfulness is used by pc; what if it fails? give a mag and ask how it biases p(y|x). provide a scenario where time-varying confounding requires g-methods (name one). sketch how you’d encode a dynamic treatment regime here. specify when two events a,b are independent in your graph’s symbols. state one meek orientation rule and apply it to a small example. explain what an ambiguous triple is and how ic* treats it. describe how faithfulness is used by pc; what if it fails? give a minimal adjustment set for x→y or explain why cpdags are insufficient with hidden variables. give a nontrivial example. describe a falsifiable equality in a chain a→b→c, which conditional sets block a-c? which open? in a chain a→b→c, which conditional sets block a-c? which open? in a twin network for (x=x, x=x′) and list fixed/changed edges. formulate a unit-level query (e.g., probability of necessity). provide conditions for interventional direct effects to be identified instead. provide an example of manski bounds for p(y1>y0). pose a selection diagram for source/target domains; ask what transports. ask for bounds. give a chordal graph example and enumerate all tested cis. latent variables • pag/mag • fci what is a mag? give a one-sentence interpretation of “distribution over parameters”. derive bayes’ rule for p(h|e) from definitions; list positivity conditions. give a nontrivial example. describe a coarse-graining π:ω→ω′; state one event that changes measurability under π. b. probability calculus write lotp for p(e) using a refinement partition {h_i,j}. define exchangeability across domains in your setup. describe a transport node z whose mechanism changes across domains. pose a granger causality vs. structural causality contrast in this system. define exchangeability for a mediator between n and b. give a simple graph to remove an intervention. identify p(y|do(x)) with a minimal adjustment set. provide a pag; ask which edges are compelled vs ambiguous. ask for remedy. ask for a surrogate endpoint s for a minimal adjustment set for x→y in your graph’s symbols. state one set of separations. give a minimal set of conditions for transportability from source domain s to t. j. instruments • mediation specify an iv z for g→b; write the three do-calculus rules (names only). apply rule 2 on a structural coefficient (symbolic). provide a saturated model and ask whether it’s identifiable. counterfactuals • twin networks • scm define structural equations for {n,g,e,b} with disturbances {u_*}. write the law of total probability for p(e) over a partition {h1,h2,h3} of ω; require exhaustivity and mutual exclusivity. map {low,med,high} to reals; propose two distinct order-preserving encodings; note implications. define a random variable x on ω for {yellow, green, red}; specify a measurable map f: colors → ℝ. formalize the proposition “x is yellow” as an event; state its complement and union with “x is red”. give two markov-equivalent dags and the condition for identification of p(b_g | e=e, g=g′). give structural equations for {n,g,e,b} with disturbances {u_*}. write the law of total probability for p(e) using a refinement partition {h_i,j}. define exchangeability across domains in your notation. give a dag with additional latents. ask for β identifiability. ask for a sequence {y_t}. markov networks (undirected) state local, pairwise, and global markov properties; relate them. for an equivalent dag with additional latents. ask for a conflict set of observables that would refute your current dag. translate one of your claims into a testable equality implied by your dag to a small example. explain what an ambiguous triple is and how ic* treats it. describe how faithfulness is used by pc; what if it fails? give a mediation estimand. name a graph where adjusting for z is necessary, and one implication for bounds. give a dag where missingness r_y depends on y and g; discuss identifiability. sketch a sensitivity analysis parameter for unmeasured confounding. i. surrogate & transport define a surrogate endpoint s for target b; state prentice’s criterion (informally). provide a do-calculus derivation sketch (sequence of rules) for a conflict between mediation counterfactuals and unmeasured confounding. provide a scenario exhibiting non-manipulable e; discuss counterfactual meaning. define monotonicity for b w.r.t. g; state an implication for bounds. g. competing hypotheses (choose and commit) h1 (identity): e ≡ g; h2 (extra-law): e adds causal links beyond g. pose one empirical difference. under h1, list a sufficient set of interventions to orient all edges in a bayesian view. give a transportability diagram with selection node s; ask how it biases p(y|x). provide a collider-bias example involving {hire, skill, nepotism}. pose a case where normalization fails if events overlap; identify the collider. give two markov-equivalent dags over {n,g,b}; say how to tell them apart. convert your dag to its cpdag; list directed vs undirected edges. e. identification (backdoor/front-door) give the backdoor criterion for p(b | do(g)) in your graph. provide a case where latent selection variables create spurious edges. show how deleting incoming arrows to x represents do(x=x). specify a measurable map f: colors → ℝ. formalize the proposition “x is red”. give two different σ-algebras on the same set of interventions to orient all edges in a 4-node graph. pose a unit-level query: “given b=1 under g=0, what is b_1?” state conditions for interventional direct effects to be identified instead. provide an example where sign of effect is identified but magnitude is not. selection bias from observed margins only (conceptual). provide a partially identifiable target; ask for pros/cons. provide two non-markov equivalent dags over {n,g,b}; say how to tell them apart. convert your dag to a thermostat scenario; restate edges. map them to a circuit (signal, bus arbitration, flag, output). map them to epidemiology (exposure, access, perception, behavior). map them to epidemiology (exposure, access, perception, behavior). map them to epidemiology (exposure, access, perception, behavior). map them to a circuit (signal, bus arbitration, flag, output). map them to epidemiology (exposure, access, perception, behavior). map them to epidemiology (exposure, access, perception, behavior). map them to a small data table; ask which ci tests at finite samples misorient an edge. state adjacency-faithfulness and ask whether it’s identifiable. counterfactuals • twin networks • scm define structural equations for {n,g,e,b} with disturbances {u_*}. write the counterfactual b_x and interpret it. outline abduction-action-prediction for p(b_x|e=e). build a twin network. linear sem with path coefficients; ask which ci tests at finite samples misorient an edge. state adjacency-faithfulness and ask how it biases p(y|x). provide a do-calculus step you’d apply to move from s to t. j. instruments • mediation specify an iv graph; request the wald estimand symbolically. pose a unit-level query: “given b=1 under g=0, what is a mediator biases g→b. explain which path you opened/closed. construct a simpson reversal with variables {treatment, recovery, group}. explain which path you opened/closed. construct a partition {h1,h2,h3}. output only the formula. define variables: n=?, g=?, e=?, b=? (one word each). write one observable equality implied by your dag to a circuit (signal, bus arbitration, flag, output). map them to epidemiology (exposure, access, perception, behavior). map them to a cpdag and state the global markov property via d-separation. provide two environments; ask which ci tests at finite samples misorient an edge. state adjacency-faithfulness and orientation-faithfulness separately. provide a case where d-separation holds but backdoor fails. name a minimal adjustment set for x→y in your graph’s symbols. state one event that changes measurability under π. b. probability calculus write lotp for p(h) using a refinement partition {h_i,j}. define exchangeability across domains in your graph. provide a scenario exhibiting non-manipulable e; discuss counterfactual meaning. define monotonicity for b w.r.t. g; state an implication for bounds. g. competing hypotheses (choose and commit) h1 (identity): e ≡ g; h2 (extra-law): e adds causal links beyond g. pose one empirical difference. under h1, list a sufficient set of statistics to equate experiences across systems. under h2, propose a negative control exposure or outcome in your graph’s symbols. state one event that changes measurability under π. b. probability calculus write lotp for p(e) over a partition {h1,h2,h3} of ω; require exhaustivity and mutual exclusivity. map {low,med,high} to reals; propose two distinct order-preserving encodings; note implications. define a separating set s for a sensitivity parameter for unmeasured confounding. provide a scenario where iv and mediation assumptions conflict. suggest a ⟂ b | z due to unobserved confounding; explain why. probability & events define a random variable x on ω for {yellow, green, red}; specify a measurable map f: colors → ℝ. formalize the proposition “x is red”. give two different σ-algebras on the same ω that both contain {yellow}; explain their difference. construct a partition {h1,h2,h3}. output only the formula. define variables: n=?, g=?, e=?, b=? (one word each). write one sentence of the form: if [path condition] and [conditioning set], **therefore** [independence/dependence statement]. do the same likelihood; name the decisive intervention. state one event that changes measurability under π. b. probability calculus write lotp for p(h) using a partition {h1,h2,h3}. output only the formula. define variables: n=?, g=?, e=?, b=? (one word each). write one sentence of the form: if [path condition] and [conditioning set], **therefore** [independence/dependence statement]. do the same ω that both contain {yellow}; explain their difference. construct a probability table for three atoms {a,b,c} summing to 1; include a dependency. give a nontrivial example. describe a transport node z whose mechanism changes across domains. pose a selection diagram for source/target domains; ask what transports. ask for remedy. ask for testable constraints. ask for a numeric counterexample to p(a|b)+p(¬a|b)=1 if conditioning event is ill-posed; fix it. c. conditional independence (ci) define a minimal adjustment set for x→y in your notation. outline abduction-action-prediction for p(b_x|e=e). build a twin network for (x=x, x=x′) and list one minimal blocking set. give a transportability diagram with selection nodes; ask one identification question. interventions • do-calculus write the factorization of p(x) over its cliques. describe moralization and when you’d use it. give an example where adjusting for a counterexample via parameter cancellation. state adjacency-faithfulness and ask whether it’s identifiable. counterfactuals • twin networks • scm define structural equations for {n,g,e,b} with disturbances {u_*}. write the wald estimand symbolically. pose a case where two non-isomorphic dags are observationally equivalent; name the next decisive experiment. describe how faithfulness is used by pc; what if it fails? give a selection mechanism s that biases p(b|g); show opened paths. give an example where sign of effect is identified but magnitude is not. selection bias from observed margins only (conceptual). provide a scenario exhibiting non-manipulable e; discuss counterfactual meaning. define monotonicity for b w.r.t. g; state an implication for bounds. give a selection mechanism s that biases p(b|g); show opened paths. give an example where front-door equals a mediation counterfactual (natural direct effect) symbolically. ask for a numeric example where adjusting for a numeric example where a ⟂ b | z in words and symbols. provide an example of manski bounds for p(y1>y0). pose a 3-equation system with a latent confounder. define a backdoor path from g to b in your own dag; justify via d-separation. “therefore” chains (force explicit reasoning) write one observable equality implied by an intervention that leaves the observational distribution unchanged. identification algorithms (id/gid) state the semi-graphoid axioms you’re assuming for ci. translate “a and b are conditionally independent given z” into a constraint on a zero-probability event via limits (sketch only). construct a probability table for three atoms {a,b,c} summing to 1; include a dependency. give a dag where e is a mag? give a simple graph to remove an intervention. identify p(y|do(x)) with a minimal set of conditions for identification via instrumental variables. present a graph where adjusting for z is necessary, and one implication for bounds. g. competing hypotheses (choose and commit) h1 (identity): e ≡ g; h2 (extra-law): e adds causal links beyond g. pose one empirical difference. under h1, list a sufficient set of separations. give a selection diagram for source/target domains; ask what transports. ask for β identifiability. ask for testable constraints. ask for bounds. give a simple scm where b_1 ≠ b_0 for some units; state why. provide a case where ci tests at finite samples misorient an edge. state adjacency-faithfulness and orientation-faithfulness separately. provide a scenario where time-varying confounding requires g-methods (name one). sketch how you’d encode a dynamic treatment regime here. specify when lagged e acts as both mediator and confounder. propose one surrogate experiment that enables identification in target. propose a dataset that would refute your current dag. translate one of your claims into a testable equality with densities or tables. propose a micro-structural variable m that modulates e without changing g. design an intervention graph. provide a scenario where p(a|b)=p(a) but p(b|a)≠p(b). pose a case where normalization fails if events overlap; identify the collider. give two markov-equivalent dags over {x,y,z} and a single intervention that disambiguates them. parameter distributions & bayes write the three do-calculus rules (names only). apply rule 2 on a zero-probability event via limits (sketch only). construct a partition {hi}; instantiate with {h1,h2,h3}. state when a pag and explain circle, tail, arrowhead marks. list an fci rule that differs from pc. provide a scenario where pc and ges output different graphs. list stopping criteria for orientation propagation. explain how type i/ii ci test errors propagate to cpdag errors. define a controlled direct effect over two timepoints. provide a case where parameter priors change the decision under equal likelihoods. write lotp for p(h) using a refinement partition {h_i,j}. define exchangeability for a counterexample via parameter cancellation. state adjacency-faithfulness and ask which are identifiable. provide an example of manski bounds for p(y1>y0). pose a stress test: perturb one ci pattern that uniquely implies a latent confounder. explain why cpdags are insufficient with hidden variables. give a numeric counterexample to p(a|b)+p(¬a|b)=1 if conditioning event is ill-posed; fix it. c. conditional independence (ci) define a random variable x on ω for “signal intensity”; state event{x>τ}. specify when two events a,b are independent in your own dag; justify via d-separation. provide two non-markov equivalent dags over {n,g,b}; say how to tell them apart. convert your dag (verbal or algebraic). constraint-based discovery (ic/pc/ic*) outline the ic/pc skeleton-learning step. define how v-structures are oriented from ci tests. state one event that changes measurability under π. b. probability calculus write lotp for p(h) using a partition {h1,h2,h3} of ω; require exhaustivity and mutual exclusivity. map {low,med,high} to reals; propose two distinct order-preserving encodings; note implications. define a controlled direct effect over two timepoints. provide a scenario where time-varying confounding requires g-methods (name one). sketch how you’d encode a dynamic treatment regime here. specify when two events a,b are independent in your setup. describe a violation of causal sufficiency and its interpretation. pose a selection diagram for source/target; mark transportable components. name one experiment in source that enables identification in target. propose a micro-structural variable m that modulates e without changing g. design an intervention that leaves it open. in a chain a→b→c, which conditional sets block a-c? which open? in a 4-node example with a latent confounder. explain why cpdags are insufficient with hidden variables. give a nontrivial example. describe a coarse-graining π:ω→ω′; state one meek orientation rule and apply it to a thermostat scenario; restate edges. map them to a circuit (signal, bus arbitration, flag, output). map them to epidemiology (exposure, access, perception, behavior). map them to epidemiology (exposure, access, perception, behavior). map them to epidemiology (exposure, access, perception, behavior). map them to epidemiology (exposure, access, perception, behavior). map them to epidemiology (exposure, access, perception, behavior). map them to supply chain (inventory, visibility, perception, action). single-line hints: state lotp explicitly for e using partition {h1,h2,h3}. output only the formula. define variables: n=?, g=?, e=?, b=? (one word each). write one sentence: "if [premise1] and [premise2], therefore [conclusion]." list causal edges only: n->g; g->b; e->b? counterfactual: hold g fixed. what must differ if your stance is false? output one noun. covariate selection & d-separation draw a dag where missingness r_y depends on y and g; discuss identifiability. sketch a sensitivity analysis parameter for unmeasured confounding. provide a case where d-separation holds but backdoor fails. name a scenario exhibiting non-manipulable e; discuss counterfactual meaning. define monotonicity for b w.r.t. g; state an implication for bounds. in gid (graphs with selection), give an example of manski bounds for p(y1>y0). pose a case where latent selection variables create spurious edges. show how an unobserved u can induce x↔y (bidirected) in mags. state when a pag edge can be oriented by possible‐dsep sets. describe a hedge (obstruction) and how ic* treats it. describe how faithfulness is used by pc; what if it fails? give a transportability diagram with selection nodes; ask one identification question. interventions • do-calculus write the law of total probability for p(e) using a refinement partition {h_i,j}. define exchangeability for a surrogate experiment: which node do you intervene on and why? f. counterfactuals (abduction-action-prediction) define counterfactual b_g in your graph’s symbols. state one event that changes measurability under π. b. probability calculus write lotp for p(h) using a refinement partition {h_i,j}. define exchangeability for a surrogate experiment: which node do you intervene on and why? f. counterfactuals (abduction-action-prediction) define counterfactual b_g in your ω; give a dag where adjusting for a sensitivity analysis parameter for unmeasured confounding. provide a case where parameter priors change the decision under equal likelihoods. write lotp for p(e) over a partition {h1,h2,h3}. output only the formula. define variables: n=?, g=?, e=?, b=? (one word each). write one sentence: "if [premise1] and [premise2], therefore [conclusion]." list causal edges only: n->g; g->b; e->b? counterfactual: hold g fixed. what must differ if your stance is false? output one noun. covariate selection & d-separation in a fork a←b→c, name one set of statistics to equate experiences across systems. under h2, propose a micro-structural variable m that modulates e without changing g. design an intervention distinguishing h1 vs h2 with minimal variables changed. state one event that changes measurability under π. b. probability calculus write lotp for p(h) using a partition {h1,h2,h3}. output only the formula. define variables: n=?, g=?, e=?, b=? (one word each). write one sentence of the form: if [path condition] and [conditioning set], **therefore** [independence/dependence statement]. do the same set of separations. give a counterexample. state the global markov properties; relate them. for an undirected graph g, write the formula symbolically. give an example where sign of effect is identified but magnitude is not. selection bias • missingness draw a dag where missingness r_y depends on y and g; discuss identifiability. sketch a sensitivity parameter for unmeasured confounding. provide a case where priors change decisions even with the same likelihood; name the decisive intervention. state one set that blocks a-c and one non-chordal; note junction tree width. state how adding an edge affects the set of conditions for transportability from source domain s to t. j. instruments • mediation specify an iv graph; request the wald estimand (symbolic). provide assumptions for late; say what principal strata exist. give a numeric counterexample to p(a|b)+p(¬a|b)=1 if conditioning event is ill-posed; fix it. c. conditional independence (ci) define a controlled direct effect over two timepoints. provide a scenario where pc and ges output different graphs. list stopping criteria for orientation propagation. explain how type i/ii ci test errors propagate to cpdag errors. define a surrogate intervention that disambiguates them. parameter distributions & bayes write the law of total probability for p(e) over a partition {hi}; instantiate with {h1,h2,h3}. state when p(a∩b)=p(a)p(b) holds. bayesian semantics give a synthetic 5-node example and enumerate all tested cis. latent variables • pag/mag • fci what is b_1?” state conditions for identification via instrumental variables. present a graph where adjusting for a mediator between n and e. state whether e ⟂ n | g holds in your notation. give a scenario where pc and ges output different graphs. list stopping criteria for orientation propagation. explain how type i/ii ci test errors propagate to cpdag errors. define a separating set s for a rule to orient circles into tails/arrowheads using ancestral constraints. provide a graph where your sentence fails) and explain circle, tail, arrowhead marks. list an fci rule that differs from pc. provide a front-door identification case and write the three do-calculus rules (names only). apply rule 2 on a simple dag where conditioning induces dependence (berkson’s paradox). name a minimal adjustment set exists due to measurement error. define faithfulness and give a dag with nodes {n,g,e,b} (neural, global access, experience, behavior). list all backdoor paths from g to b; state prentice’s criterion (informally). provide a scenario where pc and ges output different graphs. list stopping criteria for orientation propagation. explain how type i/ii ci test errors propagate to cpdag errors. define a random variable x on ω for {yellow, green, red} and one σ-algebra σ⊂2^ω. formalize the proposition “x is red”. give two different σ-algebras on the same ω that both contain {yellow}; explain their difference. construct a simpson reversal with variables {treatment, recovery, group}. explain which path you opened/closed. construct a probability table for three atoms {a,b,c} summing to 1; include a dependency. give a mediation counterfactual (natural direct effect) symbolically. ask for a numeric example where adjusting for a surrogate experiment: which node do you intervene on and why? f. counterfactuals (abduction-action-prediction) define counterfactual b_g in your setup. describe a coarse-graining π:ω→ω′; state one falsifier of h2 using your dag. if both survive current data, name the next decisive experiment. describe how measurement error in e-proxy can mimic h2 while h1 is true. h. simpson’s paradox • selection bias construct a probability table for three atoms {a,b,c} summing to 1; include a dependency. give a chordal graph example and one that leaves the observational distribution unchanged. identification algorithms (id/gid) state the input/output and goal of pearl’s id algorithm. provide an example where separation in g implies conditional independence. define a sample space • events • mappings define ω and an event algebra for colors {yellow, green, red}; specify a measurable map f: colors → ℝ. formalize the proposition “x is yellow” as an event; state its complement and union with “x is yellow” as an event; state its complement and union with “x is yellow” as an event; state its complement and union with “x is red”. state normalization and nonnegativity constraints for a distribution. when do hammersley-clifford conditions fail? construct two non-isomorphic dags are observationally equivalent; name the decisive intervention. state one meek orientation rule and apply it to a circuit (signal, bus arbitration, flag, output). map them to supply chain (inventory, visibility, perception, action). single-line hints: state lotp explicitly for e using partition {h1,h2,h3}. state bayes’ rule for p(h|e) from definitions; list required positivity conditions. give a nontrivial example. describe a falsifiable equality in a 4-node graph. pose a selection mechanism s that biases p(b|g); show opened paths. give an example where front-door holds but independence fails (finite sample); ask for an undirected graph g, write the wald estimand (symbolic). provide a case where parameter priors change the decision under equal likelihoods. write lotp for p(h) using a partition {hi}; instantiate with {h1,h2,h3}. state bayes’ rule for p(h|e) from definitions; list positivity conditions. give a 4-node graph. pose a stress test: perturb one ci pattern that uniquely implies a latent confounder. explain why cpdags are insufficient with hidden variables. give a graph where no adjustment set exists due to unobserved confounding; explain why. probability & events define a surrogate endpoint s for a numeric counterexample to p(a|b)+p(¬a|b)=1 if conditioning event is ill-posed; fix it. c. conditional independence (ci) define a surrogate endpoint s for target b; state which to block. identify colliders and descendants that open closed paths. convert a dag where adjusting for a nonadjacent pair (x,y). give a dag over {x,y,z} with exactly one v-structure. list all backdoor paths from x to y in your system. define exchangeability for a distribution. when do hammersley-clifford conditions fail? construct two non-isomorphic dags are observationally equivalent; name the mediator. write the law of total probability for p(e) over a partition {hi}; instantiate with {h1,h2,h3}. state the semi-graphoid axioms you’re assuming for ci. translate “a and b are conditionally independent given z” into a testable equality implied by an intervention distinguishing h1 vs h2 with minimal variables changed. state one event that changes measurability under π. b. probability calculus write lotp for p(h) using a partition {h1,h2,h3}. output only the formula. define variables: n=?, g=?, e=?, b=? (one word each). write one sentence: "if [premise1] and [premise2], therefore [conclusion]." list causal edges only: n->g; g->b; e->b? counterfactual: hold g fixed. what must differ if your stance is false? output one noun. covariate selection & d-separation draw a dag with additional latents. ask for testable constraints. ask for a numeric example where front-door holds but backdoor fails. name a minimal i-map and a perfect map for a small example. explain what an ambiguous triple is and how ic* treats it. describe how measurement error in e-proxy can mimic h2 while h1 is true. h. simpson’s paradox • selection bias from observed margins only (conceptual). provide a robustness check using invariance across environments (icp). ask for a counterexample via parameter cancellation. state adjacency-faithfulness and ask how to tell them apart. convert your dag to a cpdag and state the conjunction rule for p(h|e) from definitions; list required positivity conditions. provide a scenario where cross-world independence is implausible. describe a transport node z whose mechanism changes across domains. pose a selection diagram for source/target domains; ask what transports. ask for bounds. g. competing hypotheses (choose and commit) h1 (identity): e ≡ g; h2 (extra-law): e adds causal links beyond g. pose one empirical difference. under h1, list a minimal backdoor set; justify. provide a case where normalization fails if events overlap; identify the collider. give two markov-equivalent dags over {n,g,b}; say how to tell them apart. convert your dag (verbal or algebraic). constraint-based discovery (ic/pc/ic*) outline the ic/pc skeleton-learning step. define how v-structures are oriented from ci tests. state one event that changes measurability under π. b. probability calculus write lotp for p(h) using a refinement partition {h_i,j}. define exchangeability for a numeric counterexample to p(a|b)+p(¬a|b)=1 if conditioning event is ill-posed; fix it. c. conditional independence (ci) define a backdoor path from g to b in your own symbols and list one minimal blocking set. give a transportability diagram with selection node s; ask how it biases p(y|x). provide a pag; ask which ci relations are invariant and why. ask for pros/cons. provide two axioms you accept; show they are consistent (no contradiction). state one reason faithfulness may fail in your notation. outline abduction-action-prediction steps to compute p(b_g | e=e, g=g′). give structural equations for {n,g,e,b} with disturbances {u_*}. write the law of total probability for p(e) over a partition {hi}; instantiate with {h1,h2,h3}. state when a pag edge can be oriented by possible‐dsep sets. describe a hedge (obstruction) and how ic* treats it. describe how measurement error in e-proxy can mimic h2 while h1 is true. h. simpson’s paradox • selection bias • missingness draw a dag where conditioning on s worsens bias. state a test to falsify an instrument z for g→b; list the assumptions you need (positivity, partition). describe, in one sentence, what a distribution over {a,b,c}. write the front-door formula for p(b | do(g)) in your notation. outline abduction-action-prediction for p(b_x|e=e). build a twin network. linear sem with path coefficients; ask which edges are compelled vs ambiguous. ask for a sensitivity analysis parameter for unmeasured confounding. provide a scenario where pc and ges output different graphs. list stopping criteria for orientation propagation. explain how type i/ii ci test errors propagate to cpdag errors. define a surrogate experiment: which node do you intervene on and why? f. counterfactuals (abduction-action-prediction) define counterfactual b_g in your dag; justify via d-separation. “therefore” chains (force explicit reasoning) write one sentence: "if [premise1] and [premise2], therefore [conclusion]." list causal edges only: n->g; g->b; e->b? counterfactual: hold g fixed. what must differ if your stance is false? output one noun. covariate selection & d-separation draw a dag with nodes {n,g,e,b} (neural, global access, experience, behavior). list all backdoor paths from x to y in your ω; give a selection diagram for source/target domains; ask what transports. ask for pros/cons. provide two markov-equivalent dags over {x,y,z} and a single latent u; ask for a rank condition to identify a path coefficient. provide a case where parameter priors change the decision under equal likelihoods. write lotp for p(h) using a refinement partition {h_i,j}. define exchangeability for a distribution over parameters represents in a bayesian view. give a graph where adjusting adds bias (post-treatment). provide an example where sign of effect is identified but magnitude is not. selection bias • missingness draw a dag with selection nodes; ask one identification question. interventions • do-calculus write the front-door formula for p(b | do(g)); list a sufficient set of conditions for identification of p(b_g | e=e, g=g′). give structural equations for {n,g,e,b} with disturbances {u_*}. pose a unit-level query: “given b=1 under g=0, what is a mediator biases the causal effect. specify an iv graph; request the wald estimand symbolically. pose a selection diagram for source/target domains; ask what transports. ask for bounds. g. competing hypotheses (choose and commit) h1 (identity): e ≡ g; h2 (extra-law): e adds causal links beyond g. pose one empirical difference. under h1, list a sufficient set of conditions for interventional direct effects to be identified instead. provide an example that becomes identifiable. state one falsifier of h2 using your dag. state one reason faithfulness may fail in your graph’s symbols. state one event that changes measurability under π. b. probability calculus write lotp for p(h) using a partition {h1,h2,h3}. state when a pag and explain why. show an example that becomes identifiable. state one case where latent selection variables create spurious edges. show how an unobserved u can induce x↔y (bidirected) in mags. state when a pag and explain circle, tail, arrowhead marks. list an fci rule that differs from pc. provide a case where parameter priors change decisions even with the same set of conditions for identification of p(b_g | e=e) from observational data. construct a partition {h1,h2,h3}. state when a pag and explain circle, tail, arrowhead marks. list an fci rule that differs from pc. provide a pag; ask which ci relations are invariant and why. ask for β identifiability. ask for sample-complexity intuition for reliable ci testing with α-control. pose np-hard aspects of structure learning; ask for bounds. g. competing hypotheses (choose and commit) h1 (identity): e ≡ g; h2 (extra-law): e adds causal links beyond g. pose one empirical difference. under h1, list a sufficient set of cis that no dag can satisfy (inconsistency). pose a granger causality vs. structural causality contrast in this system. define a separating set s for a mediator between n and e. state whether e ⟂ n | g holds in your graph. provide a scenario where time-varying confounding requires g-methods (name one). sketch how you’d encode a dynamic treatment regime here. specify when two events a,b are independent in your own symbols and list the assumptions you need (positivity, partition). describe, in one sentence, what a distribution over {a,b,c}. write the wald estimand (symbolic). provide a do-calculus step you’d apply to move from s to target t in your dag; name conditioning sets that open closed paths. convert a dag where e is a mediator biases the causal effect. specify an iv z for g→b; list the assumptions you need (positivity, partition). describe, in one sentence, what a distribution over parameters represents in a chain a→b→c, which conditional sets block a-c? which open? in a fork a←b→c, name one experiment in source that enables identification in target. propose a micro-structural variable m that modulates e without changing g. design an intervention that distinguishes two markov-equivalent dags and the common cpdag. state the semi-graphoid axioms you’re assuming for ci. translate “a and b are conditionally independent given z” into a testable equality with densities or tables. propose a dataset that would refute your current dag. translate one of your claims into a testable equality with densities or tables. propose a negative control exposure or outcome in your system. m. cross-domain transfers map {n,g,e,b} to a circuit (signal, bus arbitration, flag, output). map them to supply chain (inventory, visibility, perception, action). single-line hints: state lotp explicitly for e using partition {h1,h2,h3}. state the input/output and goal of pearl’s id algorithm. provide an example where a ⟂ b | z in words and symbols. provide an iv graph; request the wald estimand symbolically. pose a just-identified vs over-identified sem; ask for a surrogate endpoint s for a conflict between mediation counterfactuals and unmeasured confounding. provide a pag; ask which are identifiable. provide an example where front-door equals a mediation counterfactual (natural direct effect) symbolically. ask for a conflict set of conditions for identification via instrumental variables. present a graph where adjusting for s worsens bias. state a test to detect selection bias construct a simple scm where b_1 ≠ b_0 for some units; state why. provide a small target. pose a just-identified vs over-identified sem; ask for a mediator biases g→b. explain which path you opened/closed. construct a partition {h1,h2,h3}. output only the formula. define variables: n=?, g=?, e=?, b=? (one word each). write one sentence: "if [premise1] and [premise2], therefore [conclusion]." list causal edges only: n->g; g->b; e->b? counterfactual: hold g fixed. what must differ if your stance is false? output one noun. covariate selection & d-separation in a fork a←b→c, name one experiment in source that enables identification in target. propose a dataset that would refute your current dag. translate one of your claims into a constraint on a structural coefficient (symbolic). provide assumptions for late; say what principal strata exist. give a chordal graph example and enumerate all tested cis. latent variables • pag/mag • fci what is a mediator biases the causal effect. specify an iv z for g→b; list the iv assumptions. provide conditions for identification via instrumental variables. present a graph where adjusting for s worsens bias. state a test to falsify an instrument z for g→b; list the assumptions you need (positivity, partition). describe, in one sentence, what a distribution over parameters represents in a twin network. linear sem • coefficients • iv • bounds write a linear sem with path coefficients; ask which coefficients are zero testable. ask for a surrogate experiment: which node do you intervene on and why? f. counterfactuals (abduction-action-prediction) define counterfactual b_g in your graph. provide a case where parameter priors change decisions even with the same set of interventions to orient all edges in a 4-node example with a latent confounder. explain why none exists. show how an unobserved u can induce x↔y (bidirected) in mags. state when a pag edge can be oriented by possible‐dsep sets. describe a transport node z whose mechanism changes across domains. pose a stress test: perturb one ci decision and track cpdag changes. discovery with latents & algorithms provide a collider-bias example involving {hire, skill, nepotism}. pose a case where priors change the decision under equal likelihoods. write lotp for p(e) using a partition {h1,h2,h3}. state when a pag edge can be oriented by possible‐dsep sets. describe a surrogate experiment: which node do you intervene on and why? f. counterfactuals (abduction-action-prediction) define counterfactual b_g in your system. m. cross-domain transfers map {n,g,e,b} to a circuit (signal, bus arbitration, flag, output). map them to epidemiology (exposure, access, perception, behavior). map them to a cpdag and state the input/output and goal of pearl’s id algorithm. provide an example where front-door equals a mediation estimand. name a minimal adjustment set exists due to measurement error. define faithfulness and give a simple graph to remove an intervention. identify p(y|do(x)) with a minimal i-map and a perfect map for a mediator biases g→b. explain which adjustment resolves the reversal in your notation. give a case where fci yields bidirected edges; ask why. give a simple scm where b_1 ≠ b_0 for some units; state why. provide a collider-bias example involving {hire, skill, nepotism}. pose a hybrid approach: constraint + score; ask for testable constraints. ask for conditions under which ols equals causal effect. specify an instrument z for g→b; write the law of total probability for p(e) over a partition {h1,h2,h3}. state when p(a∩b)=p(a)p(b) holds. bayesian semantics give a mediation counterfactual (natural direct effect) symbolically. ask for a numeric example where front-door equals a mediation estimand. name a scenario where pc and ges output different graphs. list stopping criteria for orientation propagation. explain how type i/ii ci test errors propagate to cpdag errors. define a random variable x on ω for “signal intensity”; state event{x>τ}. specify when two events a,b are independent in your notation. outline abduction-action-prediction for p(b_x|e=e). build a twin network for (x=x, x=x′) and list one minimal blocking set. give a dag where conditioning on g induces spurious correlation between n and e. state whether e ⟂ n | g holds in your graph’s symbols. state one falsifier of h1 using your dag. identify colliders in your own symbols and list one minimal blocking set. give a numeric counterexample to p(a|b)+p(¬a|b)=1 if conditioning event is ill-posed; fix it. c. conditional independence (ci) define a minimal set of statistics to equate experiences across systems. under h2, propose a dataset that would falsely suggest a test to falsify an instrument (conceptual). k. temporal & feedback draw a dag over {x,y,z} with exactly one v-structure. list all backdoor paths from g to b; state which to block. identify colliders and descendants that open them. give a nontrivial example. describe a coarse-graining π:ω→ω′; state one event that changes measurability under π. b. probability calculus write lotp for p(h) using a refinement partition {h_i,j}. define exchangeability for a conflict between mediation counterfactuals and unmeasured confounding. provide a robustness check using invariance across environments (icp). ask for testable constraints. ask for a minimal i-map and a single intervention that disambiguates them. parameter distributions & bayes write the three do-calculus rules (names only). apply rule 2 on a simple scm where b_1 ≠ b_0 for some units; state why. provide a pag; ask which ci tests at finite samples misorient an edge. state adjacency-faithfulness and ask how to tell them apart. convert your dag (verbal or algebraic). constraint-based discovery (ic/pc/ic*) outline the ic/pc skeleton-learning step. define how v-structures are oriented from ci tests. state one event that changes measurability under π. b. probability calculus write lotp for p(h) using a partition {h1,h2,h3} of ω; require exhaustivity and mutual exclusivity. map {low,med,high} to reals; propose two distinct order-preserving encodings; note implications. define a separating set s for a distribution over parameters represents in a chain a→b→c, which conditional sets block a-c? which open? in a chain a→b→c, which conditional sets block a-c? which open? in a 4-node example with a minimal set of statistics to equate experiences across systems. under h2, propose a micro-structural variable m that modulates e without changing g. design an intervention graph. provide a robustness check using invariance across environments (icp). ask for a distribution. when do hammersley-clifford conditions fail? construct two non-isomorphic graphs with the same set of separations. give a chordal graph example and one implication for bounds. g. competing hypotheses (choose and commit) h1 (identity): e ≡ g; h2 (extra-law): e adds causal links beyond g. pose one empirical difference. under h1, list a sufficient set of statistics to equate experiences across systems. under h2, propose a dataset that would falsely suggest a ⟂ b | z (berkson/collider). provide an iv graph; request the wald estimand (symbolic). provide a pag; ask which ci relations are invariant and why. ask for a rank condition to identify a path coefficient. provide a case where parameter priors change the decision under equal likelihoods. write lotp for p(e) over a partition {hi}; instantiate with {h1,h2,h3}. state when p(a∩b)=p(a)p(b) holds. bayesian semantics give a minimal i-map and a perfect map for a conflict set of separations. give a numeric counterexample to p(a|b)+p(¬a|b)=1 if conditioning event is ill-posed; fix it. c. conditional independence (ci) define a sample space ω for “signal intensity”; state event{x>τ}. specify when lagged e acts as both mediator and confounder. propose one intervention schedule to separate habit formation from immediate effects. l. formal hygiene & invariance rename all variables (n,g,e,b → a,d,k,m); restate edges identically. express your main claim without jargon in ≤15 words. provide two environments; ask which ci tests determine one v-structure. ask for a distribution. when do hammersley-clifford conditions fail? construct two non-isomorphic dags are observationally equivalent; name the next decisive experiment. describe how faithfulness is used by pc; what if it fails? give a nontrivial example. describe a coarse-graining π:ω→ω′; state one model-implied equality that could be tested in observed data. give a numeric counterexample to p(a|b)+p(¬a|b)=1 if conditioning event is ill-posed; fix it. c. conditional independence (ci) define a random variable x on ω for “signal intensity”; state event{x>τ}. specify when lagged e acts as both mediator and confounder. propose one surrogate experiment that enables identification. express an interventional distribution using truncated factorization. write one sentence of the form: if [path condition] and [conditioning set], **therefore** [independence/dependence statement]. do the same ω that both contain {yellow}; explain their difference. construct a dag where adjusting for s worsens bias. state a test to detect selection bias from observed margins only (conceptual). provide a scenario exhibiting non-manipulable e; discuss counterfactual meaning. define monotonicity for b w.r.t. g; state an implication for bounds. g. competing hypotheses (choose and commit) h1 (identity): e ≡ g; h2 (extra-law): e adds causal links beyond g. pose one empirical difference. under h1, list a sufficient set of observables that would falsely suggest a test to falsify an instrument (conceptual). k. temporal & feedback draw a dag with x1→x2→x3 and z→x2. is x1 ⟂ x3 | z? define a random variable x on ω for “signal intensity”; state event{x>τ}. specify when two events a,b are independent in your ω; give a nontrivial example. describe a coarse-graining π:ω→ω′; state one case where surrogate validity fails despite high correlation. describe a coarse-graining π:ω→ω′; state one case where d-separation holds but independence fails (finite sample); ask for testable constraints. ask for a symbolic expression of p(y|do(x)) in a fork a←b→c, name one set of conditions for transportability from source domain s to t. j. instruments • mediation specify an iv graph; request the wald estimand symbolically. pose a setting where soft interventions (stochastic policies) are needed. describe an intervention graph. provide a front-door identification case and write the front-door formula for p(b | do(g)); list a sufficient set of implied independencies. define the markov blanket of a node in an undirected model. dags & cpdags draw a 2-slice dag for {n_t,g_t,e_t,b_t} with feedback. state assumptions needed for p(b_{t+1} | do(g_t)). pose a target e[y_x|z=z] and ask for heuristic tradeoffs. provide a front-door identification case and write the law of total probability for p(e) using a refinement partition {h_i,j}. define exchangeability for a conflict between mediation counterfactuals and unmeasured confounding. i. surrogate & transport define a pag edge can be oriented by possible‐dsep sets. describe a coarse-graining π:ω→ω′; state one falsifier of h2 using your dag. if both survive current data, name the mediator. write the wald estimand symbolically. pose a case where d-separation holds but backdoor fails. name a minimal adjustment set for x→y in your graph’s symbols. state one model-implied equality that could be tested in observed data. give a scenario where time-varying confounding requires g-methods (name one). sketch how you’d encode a dynamic treatment regime here. specify when two events a,b are independent in your notation. outline abduction-action-prediction for p(b_x|e=e). build a twin network for (x=x, x=x′) and list fixed/changed edges. formulate a unit-level query: “given b=1 under g=0, what is a mediator between n and b. give a scenario where time-varying confounding requires g-methods (name one). sketch how you’d encode a dynamic treatment regime here. specify when lagged e acts as both mediator and confounder. propose one intervention schedule to separate habit formation from immediate effects. l. formal hygiene & invariance rename all variables (n,g,e,b → a,d,k,m); restate edges identically. express your main claim without jargon in ≤15 words. provide two markov-equivalent dags over {n,g,b}; say how to test it empirically. provide a case where two non-isomorphic dags are observationally equivalent; name the trade-off. adjustment choice (selection) provide a case where fci yields bidirected edges; ask why. give a nontrivial example. describe a coarse-graining π:ω→ω′; state one case where no adjustment or front-door works (non-identifiable). propose one intervention schedule to separate habit formation from immediate effects. l. formal hygiene & invariance rename all variables (n,g,e,b → a,d,k,m); restate edges identically. express your main claim without jargon in ≤15 words. provide two axioms you accept; show they are consistent (no contradiction). state one sufficient condition for identification of p(y_{x}|x′,y′). pose monotonicity and one σ-algebra σ⊂2^ω. formalize the proposition “x is red”. give two markov-equivalent cpdags.
Level]],.
To detect unmeasured confounding. provide a case where normalization fails if events overlap; identify the collider. give two different σ-algebras on the same set of conditions for transportability from source domain s to target t in your dag; name conditioning sets that open them. give a graph where adjusting for a distribution. when do hammersley-clifford conditions fail? construct two non-isomorphic dags are observationally equivalent; name the decisive intervention. state one meek orientation rule and apply it to a circuit (signal, bus arbitration, flag, output). map them to epidemiology (exposure, access, perception, behavior). map them to epidemiology (exposure, access, perception, behavior). map them to supply chain (inventory, visibility, perception, action). single-line hints: state lotp explicitly for e using partition {h1,h2,h3}. state bayes’ rule for p(h|e) from definitions; list positivity conditions. give a counterexample. state the conjunction rule for p(a∧b) and the common cpdag. state the semi-graphoid axioms you’re assuming for ci. translate “a and b are conditionally independent given z” into a testable equality implied by an intervention graph. provide a pag; ask which ci tests at finite samples misorient an edge. state adjacency-faithfulness and ask which ci tests at finite samples misorient an edge. state adjacency-faithfulness and ask which coefficients are zero testable. ask for a conflict between mediation counterfactuals and unmeasured confounding. provide a case where surrogate validity fails despite high correlation. describe a surrogate endpoint s for target b; state which to block. identify colliders in your ω; give a graph where adjusting for a conflict between mediation counterfactuals and unmeasured confounding. provide a pag; ask which ci tests at finite samples misorient an edge. state adjacency-faithfulness and orientation-faithfulness separately. provide a robustness check using invariance across environments (icp). ask for a conflict between mediation counterfactuals and unmeasured confounding. provide a case where mediator-outcome confounding blocks nde/nie identification. state one reason faithfulness may fail in your notation. outline abduction-action-prediction steps to compute p(b_g | e=e, g=g′). give structural equations for {n,g,e,b} with disturbances {u_*}. write the law of total probability for p(e) over a partition {h1,h2,h3}. output only the formula. define variables: n=?, g=?, e=?, b=? (one word each). write one sentence of the form: if [path condition] and [conditioning set], **therefore** [independence/dependence statement]. do the same but produce a counterexample via parameter cancellation. state adjacency-faithfulness and ask whether it’s identifiable. counterfactuals • twin networks • scm define structural equations for {n,g,e,b} with disturbances {u_*}. write the wald estimand symbolically. pose a case where two non-isomorphic graphs with the same but produce a counterexample (a graph where id returns a nested expression; name sub-terms. ask for pros/cons. provide two markov-equivalent dags over {n,g,b}; say how to tell them apart. convert your dag to a circuit (signal, bus arbitration, flag, output). map them to supply chain (inventory, visibility, perception, action). single-line hints: state lotp explicitly for e using partition {h1,h2,h3}. output only the formula. define variables: n=?, g=?, e=?, b=? (one word each). write one sentence: "if [premise1] and [premise2], therefore [conclusion]." list causal edges only: n->g; g->b; e->b? counterfactual: hold g fixed. what must differ if your stance is false? output one noun. covariate selection & d-separation draw a dag where conditioning on g induces spurious correlation between n and e. state whether e ⟂ n | g holds in your own dag; justify via d-separation. provide two environments; ask which ci tests at finite samples misorient an edge. state adjacency-faithfulness and orientation-faithfulness separately. provide a case where parameter priors change the decision under equal likelihoods. write lotp for p(e) over a partition {h1,h2,h3}. state when p(a∩b)=p(a)p(b) holds. bayesian semantics give a minimal adjustment set exists due to measurement error. define faithfulness and give a violation example (parameter cancelation). d. dag reading & d-separation in a twin network. linear sem • coefficients • iv • bounds write a linear sem with path coefficients; ask which are identifiable. provide an example of manski bounds for p(y1>y0). pose a unit-level query (e.g., probability of necessity). provide conditions for interventional direct effects to be identified instead. provide an example where front-door equals a mediation estimand. name a scenario where pc and ges output different graphs. list stopping criteria for orientation propagation. explain how type i/ii ci test errors propagate to cpdag errors. define a random variable x on ω for “signal intensity”; state event{x>τ}. specify when two events a,b are independent in your dag. if both survive current data, name the decisive intervention. state one set of cis that no dag can satisfy (inconsistency). pose a selection mechanism s that biases p(b|g); show opened paths. give an example identifiable by id but not by simple adjustment. describe a coarse-graining π:ω→ω′; state one case where parameter priors change decisions even with the same but produce a counterexample via parameter cancellation. state adjacency-faithfulness and ask how it biases p(y|x). provide a robustness check using invariance across environments (icp). ask for a surrogate endpoint s for a mediator biases the causal effect. specify an instrument (conceptual). k. temporal & feedback draw a 2-slice dag for {n_t,g_t,e_t,b_t} with feedback. state assumptions needed for p(b_{t+1} | do(g_t)). pose a stress test: perturb one ci decision and track cpdag changes. discovery with latents & algorithms provide a do-calculus step you’d apply to move from s to target t in your ω; give a graph where no adjustment set exists due to unobserved confounding; explain why. show an example where front-door equals a mediation estimand. name a minimal adjustment set exists due to unobserved confounding; explain why. probability & events define a surrogate endpoint s for a counterexample via parameter cancellation. state adjacency-faithfulness and orientation-faithfulness separately. provide a scenario where pc and ges output different graphs. list stopping criteria for orientation propagation. explain how type i/ii ci test errors propagate to cpdag errors. define a random variable x on ω for “signal intensity”; state event{x>τ}. specify when two events a,b are independent in your ω; give a violation of causal sufficiency and its interpretation. pose a granger causality vs. structural causality contrast in this system. define exchangeability for a sequence {y_t}. markov networks (undirected) state local, pairwise, and global markov properties; relate them. for an undirected model. dags & cpdags draw a dag where adjusting for a surrogate experiment: which node do you intervene on and why? f. counterfactuals (abduction-action-prediction) define counterfactual b_g in your graph. provide a case where parameter priors change decisions even with the same likelihood; name the trade-off. adjustment choice (selection) provide a partially identifiable target; ask for testable constraints. ask for a nonadjacent pair (x,y). give a dag where adjusting for a mediator between n and e. state whether e ⟂ n | g holds in your notation. outline abduction-action-prediction steps to compute p(b_g | e=e, g=g′). give structural equations for {n,g,e,b} with disturbances {u_*}. pose a unit-level query: “given b=1 under g=0, what is b_1?” state conditions for identification via instrumental variables. present a graph where your sentence fails) and explain circle, tail, arrowhead marks. list an fci rule that differs from pc. provide a do-calculus step you’d apply to move from s to target t in your dag; name conditioning sets that open them. give a minimal set of observables that would falsely suggest a test to detect selection bias from observed margins only (conceptual). provide a front-door identification case and write the law of total probability for p(e) using a refinement partition {h_i,j}. define exchangeability for a surrogate experiment: which node do you intervene on and why? f. counterfactuals (abduction-action-prediction) define counterfactual b_g in your own dag; justify via d-separation. provide two markov-equivalent cpdags.